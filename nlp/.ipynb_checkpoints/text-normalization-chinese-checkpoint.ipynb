{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Normalization (Chinese)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `text_normalizer_zh.py`\n",
    "- Including functions for:\n",
    "    - word-seg chinese texts\n",
    "    - clean up texts by removing duplicate spaces and line breaks\n",
    "    - remove incompatible weird characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "#from nltk.corpus import wordnet\n",
    "#import collections\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from bs4 import BeautifulSoup\n",
    "import requests \n",
    "import pandas as pd\n",
    "import text_normalizer_zh as tnz\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load text_normalizer_zh.py\n",
    "import unicodedata\n",
    "import re\n",
    "#from nltk.corpus import wordnet\n",
    "#import collections\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from bs4 import BeautifulSoup\n",
    "import requests \n",
    "import pandas as pd\n",
    "\n",
    "## Normalize unicode characters\n",
    "def remove_weird_chars(text):\n",
    "#     ```\n",
    "#     (NFKD) will apply the compatibility decomposition, i.e. \n",
    "#     replace all compatibility characters with their equivalents. \n",
    "#     ```\n",
    "    text = unicodedata.normalize('NFKD', text).encode('utf-8', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text\n",
    "\n",
    "\n",
    "## Remove duplicate spaces\n",
    "def remove_extra_linebreaks(text):\n",
    "    lines = text.split(r'\\n+')\n",
    "    return '\\n'.join([re.sub(r'[\\s]+',' ', l).strip() for l in lines if len(l)!=0])\n",
    "\n",
    "\n",
    "def remove_extra_spaces(text):\n",
    "    return re.sub(\"\\\\s+\",\" \", text).strip()\n",
    "\n",
    "import jieba\n",
    "jieba.set_dictionary('../../../RepositoryData/data/jiaba/dict.txt.jiebatw.txt')\n",
    "\n",
    "## Word Segmentation\n",
    "def seg(text, return_list = False):\n",
    "    text_seg = jieba.cut(text)\n",
    "    if return_list:\n",
    "        out = [w for w in text_seg]\n",
    "    else:\n",
    "        out = ' '.join(text_seg)\n",
    "    return out\n",
    "\n",
    "\n",
    "def remove_symbols(text):\n",
    "    text = re.sub('[\\u0021-\\u002f\\u003a-\\u0040\\u005b-\\u0060\\u007b-\\u007e\\u00a1-\\u00bf\\u2000-\\u206f\\u2013-\\u204a\\u20a0-\\u20bf\\u2100-\\u214f\\u2150-\\u218b\\u2190-\\u21ff\\u2200-\\u22ff\\u2300-\\u23ff\\u2460-\\u24ff\\u2500-\\u257f\\u2580-\\u259f\\u25a0-\\u25ff\\u2600-\\u26ff\\u2e00-\\u2e7f\\u3000-\\u303f\\ufe50-\\ufe6f\\ufe30-\\ufe4f\\ufe10-\\ufe1f\\uff00-\\uffef─◆╱]+','',text)\n",
    "    return text\n",
    "\n",
    "def remove_numbers(text):\n",
    "    return re.sub('\\\\d+',\"\", text)\n",
    "\n",
    "def remove_alphabets(text):\n",
    "    return re.sub('[a-zA-Z]+','', text)\n",
    "\n",
    "def normalize_corpus(corpus, is_remove_extra_linebreaks=True,\n",
    "                    is_remove_weird_chars=True,\n",
    "                    is_seg=True,\n",
    "                    is_remove_symbols=True,\n",
    "                    is_remove_numbers=True,\n",
    "                    is_remove_alphabets=True,\n",
    "                    is_return_list = False):\n",
    "    \n",
    "    normalized_corpus = []\n",
    "    # normalize each document in the corpus\n",
    "    for doc in corpus:\n",
    "        \n",
    "        if is_remove_extra_linebreaks:\n",
    "            doc = remove_extra_linebreaks(doc)\n",
    "            \n",
    "        if is_remove_weird_chars:\n",
    "            doc = remove_weird_chars(doc)\n",
    "           \n",
    "        if is_seg:\n",
    "            doc=seg(doc, is_return_list)\n",
    "            \n",
    "        if is_remove_symbols:\n",
    "            doc=remove_symbols(doc)\n",
    "            \n",
    "        if is_remove_alphabets:\n",
    "            doc=remove_alphabets(doc)\n",
    "            \n",
    "        if is_remove_numbers:\n",
    "            doc=remove_numbers(doc)\n",
    "            \n",
    "        normalized_corpus.append(remove_extra_spaces(doc))\n",
    "        \n",
    "    return normalized_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract an Article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Grab the first article from Google news for demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['（中央社記者葉素萍台北11日電）今天是台灣女孩節，也是國際女童節。總統蔡英文今天在臉書貼文指出，過去國慶禮賓人員被稱為「金釵」，但從2016年她的就職典禮開始，就已經稱他們為「禮賓人員」，而且男女各半，做一樣的事情；她也希望「不要再叫金釵」。', '蔡總統今天透過臉書表示，今年國慶，大家可能都有看到穿著制服的「禮賓人員」，在國慶的各種場合，擔任服務貴賓的工作。', '她說，過去，大家都叫他們為「金釵」，但是從2016年她的就職典禮開始，就已經稱他們為「禮賓人員」，而且男女各半，做一樣的事情。他們有的人會多國語言、會急救，都是受過專業訓練的禮賓接待人員。', '蔡總統指出，在國慶大會上，也看到許多國軍英勇的女性，像是憲兵指揮部快速反應連12名騎乘重機登場的女兵，令人印象深刻。', '她表示，今天是台灣女孩節，也是國際女童節。社會中，每個女孩、女性都有自己的專業、興趣與樣貌。當大家說「民主台灣，自信前行」時，她也期待台灣的女孩、女性，都能活在更好的世代，更平等的社會；祝福所有的女孩，能成為自己喜歡的自己、成為與眾不同的自己。她特別標註「不要再叫金釵」。', '另外，蔡總統稍早也透過自己的IG官方帳號貼文指出，2020年，因為一場疫情，讓台灣人民更團結。這期間口罩扮演了不可或缺的防疫角色；今年國慶，特別推出了國慶紀念版的口罩，上面豐富的色彩，象徵台灣的多元文化。', ' 2020年，因為一場疫情，讓台灣人民更團結。這期間口罩扮演了不可或缺的防疫角色。 今年國慶，我們特別推出了國慶紀念版的口罩，上面豐富的色彩，也象徵台灣的多元文化。 有很多朋友留言或私訊問哪裡拿得到？我現在就要抽出20位IG的朋友，將國慶口罩送給你們，謝謝大家團結防疫，讓台灣自信前行💪 🌟抽獎辦法🌟 1、追蹤我的帳號 @tsai_ingwen  2、在貼文底下留言 #團結台灣自信前行  🌟活動時間🌟 此刻起至台灣時間10/12（一）23:59為止。我們將抽出20位幸運得主並於10/13（二）中午公布。  中獎的幸運得主，我們會在限時動態中tag你的帳號，接著請幸運得主私訊姓名和地址， 我們會把獎品寄給你💌 #國慶 #口罩', ' 蔡英文（@tsai_ingwen）分享的貼文 於 PDT 2020 年 10月 月 10 日 下午 6:58 張貼', '她說，有很多朋友留言或私訊問哪裡拿得到，她要抽出20名IG的朋友，送出國慶口罩，謝謝大家團結防疫，讓台灣自信前行；蔡總統說，只要追蹤她的帳號@tsai_ingwen，並在貼文底下留言#團結台灣自信前行，活動期間到10月12日晚間11時59分為止，將抽出20名幸運得主並於10月13日中午公布。（編輯：蘇志宗）1091011', '本網站之文字、圖片及影音，非經授權，不得轉載、公開播送或公開傳輸及利用。']\n"
     ]
    }
   ],
   "source": [
    "url = 'https://news.google.com/topics/CAAqJQgKIh9DQkFTRVFvSUwyMHZNRFptTXpJU0JYcG9MVlJYS0FBUAE?hl=zh-TW&gl=TW&ceid=TW%3Azh-Hant'\n",
    "r = requests.get(url)\n",
    "web_content = r.text\n",
    "soup = BeautifulSoup(web_content,'lxml')\n",
    "title = soup.find_all('a', class_='DY5T1d')\n",
    "first_art_link = title[0]['href'].replace('.','https://news.google.com',1)\n",
    "\n",
    "#print(first_art_link)\n",
    "art_request = requests.get(first_art_link)\n",
    "art_request.encoding='utf8'\n",
    "soup_art = BeautifulSoup(art_request.text,'lxml')\n",
    "\n",
    "art_content = soup_art.find_all('p')\n",
    "art_texts = [p.text for p in art_content]\n",
    "print(art_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Normalized results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['中央社 記者 葉素萍 台北 日電 今天 是 台灣 女孩 節 也 是 國際 女童 節 總統 蔡英文 今天 在 臉書貼文 指出 過去 國慶 禮賓 人員 被 稱為 金釵 但 從 年 她 的 就職 典禮 開始 就 已經 稱 他們 為 禮賓 人員 而且 男女 各半 做 一樣 的 事情 她 也 希望 不要 再 叫 金釵 蔡 總統 今天 透過 臉書 表示 今年 國慶 大家 可能 都 有 看到 穿著 制服 的 禮賓 人員 在 國慶 的 各種 場合 擔任 服務 貴賓 的 工作 她 說 過去 大家 都 叫 他們 為 金釵 但是 從 年 她 的 就職 典禮 開始 就 已經 稱 他們 為 禮賓 人員 而且 男女 各半 做 一樣 的 事情 他們 有 的 人會 多國 語言 會 急救 都 是 受過 專業 訓練 的 禮賓 接待 人員 蔡 總統 指出 在 國慶 大會 上 也 看到 許多 國軍 英勇 的 女性 像 是 憲兵 指揮部 快速 反應 連 名 騎乘 重機 登場 的 女兵 令 人 印象 深刻 她 表示 今天 是 台灣 女孩 節 也 是 國際 女童 節 社會 中 每個 女孩 女性 都 有 自己 的 專業 興趣 與 樣貌 當 大家 說 民主 台灣 自信 前行 時 她 也 期待 台灣 的 女孩 女性 都 能活 在 更 好 的 世代 更 平等 的 社會 祝福 所有 的 女孩 能 成為 自己 喜歡 的 自己 成為 與眾不同 的 自己 她 特別 標註 不要 再 叫 金釵 另外 蔡 總統 稍早 也 透過 自己 的 官方 帳號 貼文 指出 年 因為 一場 疫情 讓 台灣 人民 更 團結 這 期間 口罩 扮演 了 不可或缺 的 防疫 角色 今年 國慶 特別 推出 了 國慶 紀念版 的 口罩 上面 豐富 的 色彩 象徵 台灣 的 多元 文化 年 因為 一場 疫情 讓 台灣 人民 更 團結 這 期間 口罩 扮演 了 不可或缺 的 防疫 角色 今年 國慶 我們 特別 推出 了 國慶 紀念版 的 口罩 上面 豐富 的 色彩 也 象徵 台灣 的 多元 文化 有 很多 朋友 留言 或 私訊 問 哪裡 拿得到 我 現在 就 要 抽出 位 的 朋友 將 國慶 口罩 送給 你們 謝謝 大家 團結 防疫 讓 台灣 自信 前行 💪 🌟 抽獎 辦法 🌟 追蹤 我 的 帳號 在 貼文 底下 留言 團結 台灣 自信 前行 🌟 活動 時間 🌟 此刻 起至 台灣 時間 一 為止 我們 將 抽出 位 幸運 得主 並 於 二 中午 公布 中獎 的 幸運 得主 我們 會 在 限時 動態 中 你 的 帳號 接著 請 幸運 得主 私訊 姓名 和 地址 我們 會 把 獎品 寄給 你 💌 國慶 口罩 蔡英文 分享 的 貼文 於 年 月 月 日 下午 張貼 她 說 有 很多 朋友 留言 或 私訊 問 哪裡 拿得到 她 要 抽出 名 的 朋友 送出 國慶 口罩 謝謝 大家 團結 防疫 讓 台灣 自信 前行 蔡 總統 說 只要 追蹤 她 的 帳號 並在 貼文 底下 留言 團結 台灣 自信 前行 活動 期間 到 月 日 晚間 時 分 為止 將 抽出 名 幸運 得主 並 於 月 日 中午 公布 編輯 蘇志 宗 本 網站 之 文字 圖片 及 影音 非經 授權 不得 轉載 公開 播送 或 公開 傳輸 及 利用']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tnz.normalize_corpus([' '.join(art_texts)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-notes",
   "language": "python",
   "name": "python-notes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
