{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEMO_DATA_ROOT = \"../../../RepositoryData/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Efficient ways to summarize the semantics of massive collections of documents\n",
    "- Three general methods:\n",
    "    - Keyphrase extraction\n",
    "    - Topic modeling\n",
    "    - Document summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyphrase Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- N-grams\n",
    "- Collocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "import text_normalizer as tn\n",
    "import nltk\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading corpus, Alice in the Wonderland."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load corpus\n",
    "alice = gutenberg.sents(fileids='carroll-alice.txt')\n",
    "# concatenate each word token of a sentence\n",
    "alice = [' '.join(ts) for ts in alice]\n",
    "# normalize text\n",
    "# `filter()` removes tokens that are False after normalization\n",
    "norm_alice = list(filter(None, \n",
    "                         tn.normalize_corpus(alice, text_lemmatization=False))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare raw texts vs, noramlized texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Alice ' s Adventures in Wonderland by Lewis Carroll 1865 ] \n",
      " alice adventures wonderland lewis carroll\n"
     ]
    }
   ],
   "source": [
    "print(alice[0], '\\n', norm_alice[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to create n-grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ngrams(sequence, n):\n",
    "    return list(\n",
    "        zip(*(sequence[index:]\n",
    "               for index in range(n)))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 'B'), ('B', 'C'), ('C', 'D')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_ngrams(['A','B','C','D'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_corpus(corpus):\n",
    "    return ' '.join([document.strip() \n",
    "                     for document in corpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_ngrams(corpus, ngram_val=1, limit=5):\n",
    "    \n",
    "    corpus = flatten_corpus(corpus)\n",
    "    tokens = nltk.word_tokenize(corpus)\n",
    "\n",
    "    ngrams = compute_ngrams(tokens, ngram_val)\n",
    "    ngrams_freq_dist = nltk.FreqDist(ngrams)\n",
    "    sorted_ngrams_fd = sorted(ngrams_freq_dist.items(), \n",
    "                              key=itemgetter(1), reverse=True)\n",
    "    sorted_ngrams = sorted_ngrams_fd[0:limit]\n",
    "    sorted_ngrams = [(' '.join(text), freq) \n",
    "                     for text, freq in sorted_ngrams]\n",
    "\n",
    "    return sorted_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said alice', 123),\n",
       " ('mock turtle', 56),\n",
       " ('march hare', 31),\n",
       " ('said king', 29),\n",
       " ('thought alice', 26),\n",
       " ('white rabbit', 22),\n",
       " ('said hatter', 22),\n",
       " ('said mock', 20),\n",
       " ('said caterpillar', 18),\n",
       " ('said gryphon', 18)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_ngrams(corpus=norm_alice, ngram_val=2,\n",
    "               limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said mock turtle', 20),\n",
       " ('said march hare', 10),\n",
       " ('poor little thing', 6),\n",
       " ('little golden key', 5),\n",
       " ('certainly said alice', 5),\n",
       " ('white kid gloves', 5),\n",
       " ('march hare said', 5),\n",
       " ('mock turtle said', 5),\n",
       " ('know said alice', 4),\n",
       " ('might well say', 4)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_ngrams(corpus=norm_alice, ngram_val=3,\n",
    "               limit=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collocations (Bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nltk.collocations.BigramCollocationFinder at 0x7fd6837ea588>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.collocations import BigramAssocMeasures\n",
    "\n",
    "finder = BigramCollocationFinder.from_documents([item.split() \n",
    "                                                for item \n",
    "                                                in norm_alice])\n",
    "finder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply frequency filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder.apply_freq_filter(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inherit BigramAssocMeasures\n",
    "class AugmentedBigramAssocMeasures(BigramAssocMeasures):\n",
    "    @classmethod\n",
    "    def dp_fwd(cls, *marginals):\n",
    "        \"\"\"Scores bigrams using delta P forward, the normalized \n",
    "        conditional prob of w2 given w1: p(w2/w1)-p(w2/_w1)\n",
    "        This may be shown with respect to a contingency table::\n",
    "\n",
    "                w1    ~w1\n",
    "             ------ ------\n",
    "         w2 | n_ii | n_oi | = n_xi\n",
    "             ------ ------\n",
    "        ~w2 | n_io | n_oo |\n",
    "             ------ ------\n",
    "             = n_ix        TOTAL = n_xx\n",
    "        \"\"\"\n",
    "        \n",
    "        n_ii, n_oi, n_io, n_oo  = cls._contingency(*marginals)\n",
    "\n",
    "        return (n_ii/(n_ii+n_io)) - (n_oi/(n_oi+n_oo))\n",
    "\n",
    "    @classmethod\n",
    "    def dp_bwd(cls, *marginals):\n",
    "        \"\"\"Scores bigrams using delta P forward, the normalized \n",
    "        conditional prob of w1 given w2: p(w1/w2)-p(w1/_w2)\n",
    "        This may be shown with respect to a contingency table::\n",
    "\n",
    "                w1    ~w1\n",
    "             ------ ------\n",
    "         w2 | n_ii | n_oi | = n_xi\n",
    "             ------ ------\n",
    "        ~w2 | n_io | n_oo |\n",
    "             ------ ------\n",
    "             = n_ix        TOTAL = n_xx\n",
    "        \"\"\"\n",
    "        \n",
    "        n_ii, n_oi, n_io, n_oo  = cls._contingency(*marginals)\n",
    "\n",
    "        return (n_ii/(n_ii+n_oi)) - (n_io/(n_io+n_oo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collocations based on raw frequencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said', 'alice'),\n",
       " ('mock', 'turtle'),\n",
       " ('march', 'hare'),\n",
       " ('said', 'king'),\n",
       " ('thought', 'alice'),\n",
       " ('said', 'hatter'),\n",
       " ('white', 'rabbit'),\n",
       " ('said', 'mock'),\n",
       " ('said', 'caterpillar'),\n",
       " ('said', 'gryphon')]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_measures = AugmentedBigramAssocMeasures()                                                \n",
    "finder.nbest(bigram_measures.raw_freq, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collocations based on PMI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('accustomed', 'usurpation', 'conquest'),\n",
       " ('adjourn', 'immediate', 'adoption'),\n",
       " ('adoption', 'energetic', 'remedies'),\n",
       " ('ancient', 'modern', 'seaography'),\n",
       " ('apple', 'roast', 'turkey'),\n",
       " ('arithmetic', 'ambition', 'distraction'),\n",
       " ('brother', 'latin', 'grammar'),\n",
       " ('canvas', 'bag', 'tied'),\n",
       " ('cherry', 'tart', 'custard'),\n",
       " ('circle', 'exact', 'shape')]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder.nbest(bigram_measures.pmi, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('soo', 'oop'), 10.771961015522411),\n",
       " (('beg', 'pardon'), 10.579315937580013),\n",
       " (('bread', 'butter'), 10.186998514801253),\n",
       " (('golden', 'key'), 10.186998514801253),\n",
       " (('kid', 'gloves'), 10.119884318942718),\n",
       " (('twinkle', 'twinkle'), 9.901244032467378),\n",
       " (('evening', 'beautiful'), 9.878876219438924),\n",
       " (('join', 'dance'), 9.878876219438924),\n",
       " (('play', 'croquet'), 9.731319031025066),\n",
       " (('set', 'work'), 9.356923516243567)]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_pmi=finder.score_ngrams(bigram_measures.pmi)\n",
    "bigrams_pmi[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('soo', 'oop'), 1.0),\n",
       " (('beg', 'pardon'), 0.9998365211705085),\n",
       " (('march', 'hare'), 0.9997542796297814),\n",
       " (('white', 'kid'), 0.9979566816510013),\n",
       " (('mock', 'turtle'), 0.9491525423728814),\n",
       " (('set', 'work'), 0.749345977763244),\n",
       " (('three', 'gardeners'), 0.7482014388489209),\n",
       " (('little', 'golden'), 0.7042309444009763),\n",
       " (('join', 'dance'), 0.6923076923076923),\n",
       " (('bread', 'butter'), 0.6665849072030087)]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_dpfwd=finder.score_ngrams(bigram_measures.dp_fwd)\n",
    "bigrams_dpfwd[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('soo', 'oop'), 1.0),\n",
       " (('mock', 'turtle'), 0.9997537754432042),\n",
       " (('join', 'dance'), 0.9996729621453683),\n",
       " (('kid', 'gloves'), 0.9995096035962403),\n",
       " (('evening', 'beautiful'), 0.9993461381283204),\n",
       " (('march', 'hare'), 0.9117647058823529),\n",
       " (('bread', 'butter'), 0.8568976188529854),\n",
       " (('golden', 'key'), 0.8568976188529854),\n",
       " (('trembling', 'voice'), 0.8298185384992643),\n",
       " (('beg', 'pardon'), 0.75)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_dpbwd=finder.score_ngrams(bigram_measures.dp_bwd)\n",
    "bigrams_dpbwd[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collocations (N-grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import TrigramCollocationFinder\n",
    "from nltk.collocations import TrigramAssocMeasures\n",
    "\n",
    "finder = TrigramCollocationFinder.from_documents([item.split() \n",
    "                                                for item \n",
    "                                                in norm_alice])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trigrams based on raw frequencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said', 'mock', 'turtle'),\n",
       " ('said', 'march', 'hare'),\n",
       " ('poor', 'little', 'thing'),\n",
       " ('little', 'golden', 'key'),\n",
       " ('march', 'hare', 'said'),\n",
       " ('mock', 'turtle', 'said'),\n",
       " ('white', 'kid', 'gloves'),\n",
       " ('beau', 'ootiful', 'soo'),\n",
       " ('certainly', 'said', 'alice'),\n",
       " ('might', 'well', 'say')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "trigram_measures = TrigramAssocMeasures()                                                \n",
    "finder.nbest(trigram_measures.raw_freq, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trigrams based on PMI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('accustomed', 'usurpation', 'conquest'),\n",
       " ('adjourn', 'immediate', 'adoption'),\n",
       " ('adoption', 'energetic', 'remedies'),\n",
       " ('ancient', 'modern', 'seaography'),\n",
       " ('apple', 'roast', 'turkey'),\n",
       " ('arithmetic', 'ambition', 'distraction'),\n",
       " ('brother', 'latin', 'grammar'),\n",
       " ('canvas', 'bag', 'tied'),\n",
       " ('cherry', 'tart', 'custard'),\n",
       " ('circle', 'exact', 'shape')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder.nbest(trigram_measures.pmi, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Tag-based Phrase Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = open(DEMO_DATA_ROOT+'/elephants.txt', 'r+').readlines()\n",
    "sentences = nltk.sent_tokenize(data[0])\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Elephants are large mammals of the family Elephantidae and the order Proboscidea',\n",
       " 'Three species are currently recognised the African bush elephant Loxodonta africana the African forest elephant L cyclotis and the Asian elephant Elephas maximus',\n",
       " 'Elephants are scattered throughout subSaharan Africa South Asia and Southeast Asia']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_sentences = tn.normalize_corpus(sentences, text_lower_case=False, \n",
    "                                     text_stemming=False, text_lemmatization=False, stopword_removal=False)\n",
    "norm_sentences[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define chunk-based tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def get_chunks(sentences, grammar = r'NP: {<DT>? <JJ>* <NN.*>+}', stopword_list=stopwords):\n",
    "    \n",
    "    all_chunks = []\n",
    "    chunker = nltk.chunk.regexp.RegexpParser(grammar)\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        \n",
    "        tagged_sents = [nltk.pos_tag(nltk.word_tokenize(sentence))]   \n",
    "        \n",
    "        chunks = [chunker.parse(tagged_sent) \n",
    "                      for tagged_sent in tagged_sents]\n",
    "        \n",
    "        wtc_sents = [nltk.chunk.tree2conlltags(chunk)\n",
    "                         for chunk in chunks]    \n",
    "        \n",
    "        flattened_chunks = list(\n",
    "                            itertools.chain.from_iterable(\n",
    "                                wtc_sent for wtc_sent in wtc_sents)\n",
    "                           )\n",
    "        \n",
    "        valid_chunks_tagged = [(status, [wtc for wtc in chunk]) \n",
    "                                   for status, chunk \n",
    "                                       in itertools.groupby(flattened_chunks, \n",
    "                                                lambda word_pos_chunk: word_pos_chunk[2] != 'O')]\n",
    "        \n",
    "        valid_chunks = [' '.join(word.lower() \n",
    "                                for word, tag, chunk in wtc_group \n",
    "                                    if word.lower() not in stopword_list) \n",
    "                                        for status, wtc_group in valid_chunks_tagged\n",
    "                                            if status]\n",
    "                                            \n",
    "        all_chunks.append(valid_chunks)\n",
    "    \n",
    "    return all_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get chunks from texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['elephants', 'large mammals', 'family elephantidae', 'order proboscidea'],\n",
       " ['species',\n",
       "  'african bush elephant loxodonta',\n",
       "  'african forest elephant l cyclotis',\n",
       "  'asian elephant elephas maximus'],\n",
       " ['elephants', 'subsaharan africa south asia', 'southeast asia'],\n",
       " ['elephantidae',\n",
       "  'family',\n",
       "  'order proboscidea',\n",
       "  'extinct members',\n",
       "  'order',\n",
       "  'deinotheres gomphotheres mammoths',\n",
       "  'mastodons'],\n",
       " ['elephants',\n",
       "  'several distinctive features',\n",
       "  'long trunk',\n",
       "  'proboscis',\n",
       "  'many purposes',\n",
       "  'water',\n",
       "  'grasping objects'],\n",
       " ['incisors', 'tusks', 'weapons', 'tools', 'objects'],\n",
       " ['elephants', 'flaps', 'body temperature'],\n",
       " ['pillarlike legs', 'great weight'],\n",
       " ['african elephants',\n",
       "  'ears',\n",
       "  'backs',\n",
       "  'asian elephants',\n",
       "  'ears',\n",
       "  'convex',\n",
       "  'level backs'],\n",
       " ['elephants', 'different habitats', 'savannahs forests deserts', 'marshes'],\n",
       " ['water'],\n",
       " ['keystone species', 'impact', 'environments'],\n",
       " ['animals',\n",
       "  'distance',\n",
       "  'elephants',\n",
       "  'predators',\n",
       "  'lions tigers hyenas',\n",
       "  'wild dogs',\n",
       "  'young elephants',\n",
       "  'calves'],\n",
       " ['elephants', 'fissionfusion society', 'multiple family groups'],\n",
       " ['females cows',\n",
       "  'family groups',\n",
       "  'female',\n",
       "  'calves',\n",
       "  'several related females'],\n",
       " ['groups', 'individual known', 'matriarch', 'cow'],\n",
       " ['males bulls', 'family groups', 'males'],\n",
       " ['adult',\n",
       "  'family groups',\n",
       "  'mate',\n",
       "  'enter state',\n",
       "  'increased testosterone',\n",
       "  'aggression',\n",
       "  'musth',\n",
       "  'dominance',\n",
       "  'reproductive success'],\n",
       " ['calves', 'centre', 'attention', 'family groups', 'mothers', 'years'],\n",
       " ['elephants', 'years', 'wild'],\n",
       " ['touch sight smell',\n",
       "  'sound elephants',\n",
       "  'infrasound',\n",
       "  'seismic communication',\n",
       "  'long distances'],\n",
       " ['elephant intelligence', 'primates', 'cetaceans'],\n",
       " ['selfawareness', 'dead individuals', 'kind'],\n",
       " ['african elephants',\n",
       "  'international union',\n",
       "  'conservation',\n",
       "  'nature iucn',\n",
       "  'asian elephant'],\n",
       " ['threats', 'populations', 'ivory trade', 'animals', 'ivory tusks'],\n",
       " ['threats', 'elephants', 'habitat destruction', 'conflicts', 'local people'],\n",
       " ['elephants', 'animals', 'asia'],\n",
       " ['past', 'war today', 'display', 'zoos', 'entertainment', 'circuses'],\n",
       " ['elephants', 'art folklore religion literature', 'popular culture']]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = get_chunks(norm_sentences)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "\n",
    "def get_tfidf_weighted_keyphrases(sentences, \n",
    "                                  grammar=r'NP: {<DT>? <JJ>* <NN.*>+}',\n",
    "                                  top_n=10):\n",
    "    \n",
    "    valid_chunks = get_chunks(sentences, grammar=grammar)\n",
    "                                     \n",
    "    dictionary = corpora.Dictionary(valid_chunks)\n",
    "    corpus = [dictionary.doc2bow(chunk) for chunk in valid_chunks]\n",
    "    \n",
    "    tfidf = models.TfidfModel(corpus)\n",
    "    corpus_tfidf = tfidf[corpus]\n",
    "    \n",
    "    weighted_phrases = {dictionary.get(idx): value \n",
    "                           for doc in corpus_tfidf \n",
    "                               for idx, value in doc}\n",
    "                            \n",
    "    weighted_phrases = sorted(weighted_phrases.items(), \n",
    "                              key=itemgetter(1), reverse=True)\n",
    "    weighted_phrases = [(term, round(wt, 3)) for term, wt in weighted_phrases]\n",
    "    \n",
    "    return weighted_phrases[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('water', 1.0),\n",
       " ('asia', 0.807),\n",
       " ('wild', 0.764),\n",
       " ('great weight', 0.707),\n",
       " ('pillarlike legs', 0.707),\n",
       " ('southeast asia', 0.693),\n",
       " ('subsaharan africa south asia', 0.693),\n",
       " ('body temperature', 0.693),\n",
       " ('flaps', 0.693),\n",
       " ('fissionfusion society', 0.693),\n",
       " ('multiple family groups', 0.693),\n",
       " ('art folklore religion literature', 0.693),\n",
       " ('popular culture', 0.693),\n",
       " ('ears', 0.681),\n",
       " ('males', 0.653),\n",
       " ('males bulls', 0.653),\n",
       " ('family elephantidae', 0.607),\n",
       " ('large mammals', 0.607),\n",
       " ('years', 0.607),\n",
       " ('environments', 0.577),\n",
       " ('impact', 0.577),\n",
       " ('keystone species', 0.577),\n",
       " ('cetaceans', 0.577),\n",
       " ('elephant intelligence', 0.577),\n",
       " ('primates', 0.577),\n",
       " ('dead individuals', 0.577),\n",
       " ('kind', 0.577),\n",
       " ('selfawareness', 0.577),\n",
       " ('different habitats', 0.57),\n",
       " ('marshes', 0.57)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tfidf_weighted_keyphrases(sentences=norm_sentences, top_n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('african bush elephant', 0.261),\n",
       " ('including', 0.141),\n",
       " ('family', 0.137),\n",
       " ('cow', 0.124),\n",
       " ('forests', 0.108),\n",
       " ('female', 0.103),\n",
       " ('asia', 0.102),\n",
       " ('objects', 0.098),\n",
       " ('sight', 0.098),\n",
       " ('ivory', 0.098),\n",
       " ('tigers', 0.098),\n",
       " ('males', 0.088),\n",
       " ('folklore', 0.087),\n",
       " ('religion', 0.087),\n",
       " ('known', 0.087),\n",
       " ('larger ears', 0.085),\n",
       " ('water', 0.075),\n",
       " ('highly recognisable', 0.075),\n",
       " ('breathing lifting', 0.074),\n",
       " ('flaps', 0.073),\n",
       " ('africa', 0.072),\n",
       " ('gomphotheres', 0.072),\n",
       " ('animals tend', 0.071),\n",
       " ('success', 0.071),\n",
       " ('south', 0.07)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.summarization import keywords\n",
    "\n",
    "key_words = keywords(data[0], ratio=1.0, scores=True, lemmatize=True)\n",
    "[(item, round(score, 3)) for item, score in key_words][:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download corpus and unzip the corpus files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-10-10 11:45:38--  https://cs.nyu.edu/~roweis/data/nips12raw_str602.tgz\n",
      "Resolving cs.nyu.edu... 128.122.49.30\n",
      "Connecting to cs.nyu.edu|128.122.49.30|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12851423 (12M) [application/x-gzip]\n",
      "Saving to: ‘nips12raw_str602.tgz’\n",
      "\n",
      "nips12raw_str602.tg 100%[===================>]  12.26M  2.69MB/s    in 5.9s    \n",
      "\n",
      "2020-10-10 11:45:45 (2.07 MB/s) - ‘nips12raw_str602.tgz’ saved [12851423/12851423]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!wget https://cs.nyu.edu/~roweis/data/nips12raw_str602.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!tar -xzf nips12raw_str602.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load  Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RAW_DATA_NOTES', 'idx', 'nips12', 'nips09', 'nips00', 'nips07', 'nips06', 'nips01', 'nips08', 'README_yann', 'MATLAB_NOTES', 'nips11', 'nips10', 'nips04', 'nips03', 'nips02', 'nips05', 'orig']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1740"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = 'nipstxt/'\n",
    "print(os.listdir(DATA_PATH))\n",
    "folders = [\"nips{0:02}\".format(i) for i in range(0,13)]\n",
    "# Read all texts into a list.\n",
    "papers = []\n",
    "for folder in folders:\n",
    "    file_names = os.listdir(DATA_PATH + folder)\n",
    "    for file_name in file_names:\n",
    "        with open(DATA_PATH + folder + '/' + file_name, encoding='utf-8', errors='ignore', mode='r+') as f:\n",
    "            data = f.read()\n",
    "        papers.append(data)\n",
    "len(papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "775 \n",
      "A NEURAL-NETWORK SOLUTION TO THE CONCENTRATOR \n",
      "ASSIGNMENT PROBLEM \n",
      "Gene A. Tagliarini \n",
      "Edward W\n"
     ]
    }
   ],
   "source": [
    "print(papers[0][:100])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1740\n",
      "CPU times: user 38.1 s, sys: 271 ms, total: 38.4 s\n",
      "Wall time: 39.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import nltk\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "wtk = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "wnl = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "\n",
    "def normalize_corpus(papers):\n",
    "    norm_papers = []\n",
    "    for paper in papers:\n",
    "        paper = paper.lower()\n",
    "        paper_tokens = [token.strip() for token in wtk.tokenize(paper)]\n",
    "        paper_tokens = [wnl.lemmatize(token) for token in paper_tokens if not token.isnumeric()]\n",
    "        paper_tokens = [token for token in paper_tokens if len(token) > 1]\n",
    "        paper_tokens = [token for token in paper_tokens if token not in stop_words]\n",
    "        paper_tokens = list(filter(None, paper_tokens))\n",
    "        if paper_tokens:\n",
    "            norm_papers.append(paper_tokens)\n",
    "            \n",
    "    return norm_papers\n",
    "    \n",
    "norm_papers = normalize_corpus(papers)\n",
    "print(len(norm_papers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Enginerring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neural_network', 'solution', 'concentrator', 'assignment', 'problem', 'gene', 'tagliarini', 'edward', 'page', 'department_computer', 'science', 'clemson', 'university', 'clemson', 'sc', 'abstract', 'network', 'simple', 'analog', 'processor', 'neuron', 'like', 'property', 'employed', 'compute', 'good', 'solution', 'variety', 'optimization', 'prob_lem', 'paper_present', 'neural_net', 'solution', 'resource', 'allocation', 'prob_lem', 'arises', 'providing', 'local', 'access', 'backbone', 'wide', 'area', 'com', 'munication', 'network', 'problem', 'described', 'term', 'energy']\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "bigram = gensim.models.Phrases(norm_papers, min_count=20, threshold=20, delimiter=b'_') # higher threshold fewer phrases.\n",
    "bigram_model = gensim.models.phrases.Phraser(bigram)\n",
    "\n",
    "print(bigram_model[norm_papers[0]][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample word to number mappings: [(0, 'able'), (1, 'abstract'), (2, 'acad_sci'), (3, 'access'), (4, 'accommodated'), (5, 'actu'), (6, 'actually'), (7, 'added'), (8, 'additionally'), (9, 'algebraic'), (10, 'algo_rithm'), (11, 'allocation'), (12, 'allow'), (13, 'allows'), (14, 'ally')]\n",
      "Total Vocabulary Size: 78892\n"
     ]
    }
   ],
   "source": [
    "norm_corpus_bigrams = [bigram_model[doc] for doc in norm_papers]\n",
    "\n",
    "# Create a dictionary representation of the documents.\n",
    "dictionary = gensim.corpora.Dictionary(norm_corpus_bigrams)\n",
    "print('Sample word to number mappings:', list(dictionary.items())[:15])\n",
    "print('Total Vocabulary Size:', len(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Vocabulary Size: 7756\n"
     ]
    }
   ],
   "source": [
    "# Filter out words that occur less than 20 documents, or more than 50% of the documents.\n",
    "dictionary.filter_extremes(no_below=20, no_above=0.6)\n",
    "print('Total Vocabulary Size:', len(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 1), (10, 1), (13, 1), (15, 1), (16, 1), (19, 1), (20, 1), (33, 3), (39, 6), (40, 1), (56, 1), (57, 1), (66, 1), (71, 1), (75, 1), (77, 4), (79, 1), (89, 2), (93, 2), (102, 2), (105, 3), (111, 1), (112, 6), (114, 2), (115, 1), (117, 1), (127, 9), (128, 1), (134, 2), (143, 1), (147, 1), (149, 7), (151, 2), (152, 4), (157, 1), (158, 1), (159, 3), (163, 1), (164, 1), (166, 2), (170, 1), (181, 2), (182, 3), (183, 2), (187, 5), (189, 3), (190, 1), (193, 2), (203, 2), (210, 1)]\n"
     ]
    }
   ],
   "source": [
    "# Transforming corpus into bag of words vectors\n",
    "bow_corpus = [dictionary.doc2bow(text) for text in norm_corpus_bigrams]\n",
    "print(bow_corpus[1][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('acad_sci', 1), ('allow', 1), ('although', 1), ('american_institute', 1), ('among', 1), ('another', 1), ('appropriate', 1), ('assume', 3), ('capacity', 6), ('cause', 1), ('comparison', 1), ('complete', 1), ('connection', 1), ('consider', 1), ('construction', 1), ('convergence', 4), ('corresponding', 1), ('defined', 2), ('detail', 2), ('either', 2), ('energy', 3), ('equal', 1), ('equation', 6), ('even', 2), ('exactly', 1), ('except', 1), ('field', 9), ('fig', 1), ('follows', 2), ('global_minimum', 1), ('guarantee', 1), ('high', 7), ('hop_field', 2), ('hopfield', 4), ('i2', 1), ('ieee_trans', 1), ('ii', 3), ('implement', 1), ('implemented', 1), ('include', 2), ('individual', 1), ('le', 2), ('least', 3), ('like', 2), ('local_minimum', 5), ('location', 3), ('low', 1), ('made', 2), ('minimum', 2), ('necessary', 1)]\n"
     ]
    }
   ],
   "source": [
    "print([(dictionary[idx] , freq) for idx, freq in bow_corpus[1][:50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of papers: 1740\n"
     ]
    }
   ],
   "source": [
    "print('Total number of papers:', len(bow_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Models with Latent Semantic Indexing (LSI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_TOPICS = 10\n",
    "lsi_bow = gensim.models.LsiModel(bow_corpus, id2word=dictionary, num_topics=TOTAL_TOPICS,\n",
    "                                 onepass=True, chunksize=1740, power_iters=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "0.215*\"unit\" + 0.212*\"state\" + 0.187*\"training\" + 0.177*\"neuron\" + 0.162*\"pattern\" + 0.145*\"image\" + 0.140*\"vector\" + 0.125*\"feature\" + 0.122*\"cell\" + 0.110*\"layer\" + 0.101*\"task\" + 0.097*\"class\" + 0.091*\"probability\" + 0.089*\"signal\" + 0.087*\"step\" + 0.086*\"response\" + 0.085*\"representation\" + 0.083*\"noise\" + 0.082*\"rule\" + 0.081*\"distribution\"\n",
      "\n",
      "Topic #2:\n",
      "0.487*\"neuron\" + 0.396*\"cell\" + -0.257*\"state\" + 0.191*\"response\" + -0.187*\"training\" + 0.170*\"stimulus\" + 0.117*\"activity\" + -0.109*\"class\" + 0.099*\"spike\" + 0.097*\"pattern\" + 0.096*\"circuit\" + 0.096*\"synaptic\" + -0.095*\"vector\" + 0.090*\"signal\" + 0.090*\"firing\" + 0.088*\"visual\" + -0.084*\"classifier\" + -0.083*\"action\" + -0.078*\"word\" + 0.078*\"cortical\"\n",
      "\n",
      "Topic #3:\n",
      "-0.627*\"state\" + 0.395*\"image\" + -0.219*\"neuron\" + 0.209*\"feature\" + -0.188*\"action\" + 0.137*\"unit\" + 0.131*\"object\" + -0.130*\"control\" + 0.129*\"training\" + -0.109*\"policy\" + 0.103*\"classifier\" + 0.090*\"class\" + -0.081*\"step\" + -0.081*\"dynamic\" + 0.080*\"classification\" + 0.078*\"layer\" + 0.076*\"recognition\" + -0.074*\"reinforcement_learning\" + 0.069*\"representation\" + 0.068*\"pattern\"\n",
      "\n",
      "Topic #4:\n",
      "0.686*\"unit\" + -0.433*\"image\" + 0.182*\"pattern\" + 0.131*\"layer\" + 0.123*\"hidden_unit\" + 0.121*\"net\" + 0.114*\"training\" + -0.112*\"feature\" + 0.109*\"activation\" + 0.107*\"rule\" + -0.097*\"neuron\" + 0.078*\"word\" + -0.070*\"pixel\" + 0.070*\"connection\" + -0.067*\"object\" + -0.065*\"state\" + -0.060*\"distribution\" + -0.059*\"face\" + 0.057*\"architecture\" + -0.055*\"estimate\"\n",
      "\n",
      "Topic #5:\n",
      "-0.428*\"image\" + -0.348*\"state\" + 0.266*\"neuron\" + -0.264*\"unit\" + 0.181*\"training\" + 0.174*\"class\" + -0.168*\"object\" + 0.167*\"classifier\" + -0.147*\"action\" + -0.122*\"visual\" + 0.117*\"vector\" + 0.115*\"node\" + 0.105*\"distribution\" + -0.103*\"motion\" + -0.099*\"feature\" + 0.097*\"classification\" + -0.097*\"control\" + -0.095*\"task\" + -0.087*\"cell\" + -0.083*\"representation\"\n",
      "\n",
      "Topic #6:\n",
      "0.660*\"cell\" + -0.508*\"neuron\" + -0.213*\"image\" + -0.103*\"chip\" + -0.097*\"unit\" + 0.093*\"response\" + -0.090*\"object\" + 0.083*\"rat\" + 0.076*\"distribution\" + -0.070*\"circuit\" + 0.069*\"probability\" + 0.064*\"stimulus\" + -0.061*\"memory\" + -0.058*\"analog\" + -0.058*\"activation\" + 0.055*\"class\" + -0.053*\"bit\" + -0.052*\"net\" + 0.051*\"cortical\" + 0.050*\"firing\"\n",
      "\n",
      "Topic #7:\n",
      "-0.353*\"word\" + 0.281*\"unit\" + -0.272*\"training\" + -0.257*\"classifier\" + -0.177*\"recognition\" + 0.159*\"distribution\" + -0.152*\"feature\" + -0.144*\"state\" + -0.142*\"pattern\" + 0.141*\"vector\" + -0.128*\"cell\" + -0.128*\"task\" + 0.122*\"approximation\" + 0.121*\"variable\" + 0.110*\"equation\" + -0.107*\"classification\" + 0.106*\"noise\" + -0.103*\"class\" + 0.101*\"matrix\" + -0.098*\"neuron\"\n",
      "\n",
      "Topic #8:\n",
      "-0.303*\"pattern\" + 0.243*\"signal\" + 0.236*\"control\" + 0.202*\"training\" + -0.181*\"rule\" + -0.178*\"state\" + 0.167*\"noise\" + -0.166*\"class\" + 0.162*\"word\" + -0.155*\"cell\" + -0.154*\"feature\" + 0.147*\"motion\" + 0.140*\"task\" + -0.127*\"node\" + -0.124*\"neuron\" + 0.116*\"target\" + 0.114*\"circuit\" + -0.114*\"probability\" + -0.110*\"classifier\" + -0.109*\"image\"\n",
      "\n",
      "Topic #9:\n",
      "-0.472*\"node\" + -0.254*\"circuit\" + 0.214*\"word\" + -0.201*\"chip\" + 0.190*\"neuron\" + 0.172*\"stimulus\" + -0.160*\"classifier\" + -0.152*\"current\" + 0.147*\"feature\" + -0.146*\"voltage\" + 0.145*\"distribution\" + -0.141*\"control\" + -0.124*\"rule\" + -0.110*\"layer\" + -0.105*\"analog\" + -0.091*\"tree\" + 0.084*\"response\" + 0.080*\"state\" + 0.079*\"probability\" + 0.079*\"estimate\"\n",
      "\n",
      "Topic #10:\n",
      "-0.518*\"word\" + 0.254*\"training\" + -0.236*\"vector\" + 0.222*\"task\" + 0.194*\"pattern\" + 0.156*\"classifier\" + -0.149*\"node\" + -0.146*\"recognition\" + 0.139*\"control\" + -0.138*\"sequence\" + 0.126*\"rule\" + -0.125*\"circuit\" + -0.123*\"cell\" + 0.113*\"action\" + 0.105*\"neuron\" + -0.094*\"hmm\" + -0.093*\"character\" + -0.088*\"chip\" + -0.088*\"matrix\" + -0.085*\"structure\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for topic_id, topic in lsi_bow.print_topics(num_topics=10, num_words=20):\n",
    "    print('Topic #'+str(topic_id+1)+':')\n",
    "    print(topic)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "==================================================\n",
      "Direction 1: [('unit', 0.215), ('state', 0.212), ('training', 0.187), ('neuron', 0.177), ('pattern', 0.162), ('image', 0.145), ('vector', 0.14), ('feature', 0.125), ('cell', 0.122), ('layer', 0.11), ('task', 0.101), ('class', 0.097), ('probability', 0.091), ('signal', 0.089), ('step', 0.087), ('response', 0.086), ('representation', 0.085), ('noise', 0.083), ('rule', 0.082), ('distribution', 0.081)]\n",
      "--------------------------------------------------\n",
      "Direction 2: []\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #2:\n",
      "==================================================\n",
      "Direction 1: [('neuron', 0.487), ('cell', 0.396), ('response', 0.191), ('stimulus', 0.17), ('activity', 0.117), ('spike', 0.099), ('pattern', 0.097), ('circuit', 0.096), ('synaptic', 0.096), ('signal', 0.09), ('firing', 0.09), ('visual', 0.088), ('cortical', 0.078)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('state', -0.257), ('training', -0.187), ('class', -0.109), ('vector', -0.095), ('classifier', -0.084), ('action', -0.083), ('word', -0.078)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #3:\n",
      "==================================================\n",
      "Direction 1: [('image', 0.395), ('feature', 0.209), ('unit', 0.137), ('object', 0.131), ('training', 0.129), ('classifier', 0.103), ('class', 0.09), ('classification', 0.08), ('layer', 0.078), ('recognition', 0.076), ('representation', 0.069), ('pattern', 0.068)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('state', -0.627), ('neuron', -0.219), ('action', -0.188), ('control', -0.13), ('policy', -0.109), ('step', -0.081), ('dynamic', -0.081), ('reinforcement_learning', -0.074)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #4:\n",
      "==================================================\n",
      "Direction 1: [('unit', 0.686), ('pattern', 0.182), ('layer', 0.131), ('hidden_unit', 0.123), ('net', 0.121), ('training', 0.114), ('activation', 0.109), ('rule', 0.107), ('word', 0.078), ('connection', 0.07), ('architecture', 0.057)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('image', -0.433), ('feature', -0.112), ('neuron', -0.097), ('pixel', -0.07), ('object', -0.067), ('state', -0.065), ('distribution', -0.06), ('face', -0.059), ('estimate', -0.055)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #5:\n",
      "==================================================\n",
      "Direction 1: [('neuron', 0.266), ('training', 0.181), ('class', 0.174), ('classifier', 0.167), ('vector', 0.117), ('node', 0.115), ('distribution', 0.105), ('classification', 0.097)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('image', -0.428), ('state', -0.348), ('unit', -0.264), ('object', -0.168), ('action', -0.147), ('visual', -0.122), ('motion', -0.103), ('feature', -0.099), ('control', -0.097), ('task', -0.095), ('cell', -0.087), ('representation', -0.083)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #6:\n",
      "==================================================\n",
      "Direction 1: [('cell', 0.66), ('response', 0.093), ('rat', 0.083), ('distribution', 0.076), ('probability', 0.069), ('stimulus', 0.064), ('class', 0.055), ('cortical', 0.051), ('firing', 0.05)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('neuron', -0.508), ('image', -0.213), ('chip', -0.103), ('unit', -0.097), ('object', -0.09), ('circuit', -0.07), ('memory', -0.061), ('analog', -0.058), ('activation', -0.058), ('bit', -0.053), ('net', -0.052)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #7:\n",
      "==================================================\n",
      "Direction 1: [('unit', 0.281), ('distribution', 0.159), ('vector', 0.141), ('approximation', 0.122), ('variable', 0.121), ('equation', 0.11), ('noise', 0.106), ('matrix', 0.101)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('word', -0.353), ('training', -0.272), ('classifier', -0.257), ('recognition', -0.177), ('feature', -0.152), ('state', -0.144), ('pattern', -0.142), ('cell', -0.128), ('task', -0.128), ('classification', -0.107), ('class', -0.103), ('neuron', -0.098)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #8:\n",
      "==================================================\n",
      "Direction 1: [('signal', 0.243), ('control', 0.236), ('training', 0.202), ('noise', 0.167), ('word', 0.162), ('motion', 0.147), ('task', 0.14), ('target', 0.116), ('circuit', 0.114)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('pattern', -0.303), ('rule', -0.181), ('state', -0.178), ('class', -0.166), ('cell', -0.155), ('feature', -0.154), ('node', -0.127), ('neuron', -0.124), ('probability', -0.114), ('classifier', -0.11), ('image', -0.109)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #9:\n",
      "==================================================\n",
      "Direction 1: [('word', 0.214), ('neuron', 0.19), ('stimulus', 0.172), ('feature', 0.147), ('distribution', 0.145), ('response', 0.084), ('state', 0.08), ('probability', 0.079), ('estimate', 0.079)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('node', -0.472), ('circuit', -0.254), ('chip', -0.201), ('classifier', -0.16), ('current', -0.152), ('voltage', -0.146), ('control', -0.141), ('rule', -0.124), ('layer', -0.11), ('analog', -0.105), ('tree', -0.091)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #10:\n",
      "==================================================\n",
      "Direction 1: [('training', 0.254), ('task', 0.222), ('pattern', 0.194), ('classifier', 0.156), ('control', 0.139), ('rule', 0.126), ('action', 0.113), ('neuron', 0.105)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('word', -0.518), ('vector', -0.236), ('node', -0.149), ('recognition', -0.146), ('sequence', -0.138), ('circuit', -0.125), ('cell', -0.123), ('hmm', -0.094), ('character', -0.093), ('chip', -0.088), ('matrix', -0.088), ('structure', -0.085)]\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in range(TOTAL_TOPICS):\n",
    "    print('Topic #'+str(n+1)+':')\n",
    "    print('='*50)\n",
    "    d1 = []\n",
    "    d2 = []\n",
    "    for term, wt in lsi_bow.show_topic(n, topn=20):\n",
    "        if wt >= 0:\n",
    "            d1.append((term, round(wt, 3)))\n",
    "        else:\n",
    "            d2.append((term, round(wt, 3)))\n",
    "\n",
    "    print('Direction 1:', d1)\n",
    "    print('-'*50)\n",
    "    print('Direction 2:', d2)\n",
    "    print('-'*50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7756, 10), (10,), (10, 1740))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_topic = lsi_bow.projection.u\n",
    "singular_values = lsi_bow.projection.s\n",
    "topic_document = (gensim.matutils.corpus2dense(lsi_bow[bow_corpus], len(singular_values)).T / singular_values).T\n",
    "term_topic.shape, singular_values.shape, topic_document.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>T9</th>\n",
       "      <th>T10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.019</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.016</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.021</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.032</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.032</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>0.038</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.012</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.040</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.058</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>0.037</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.023</td>\n",
       "      <td>0.040</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.065</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>-0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.035</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.032</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.025</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.024</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.028</td>\n",
       "      <td>0.050</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>-0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.025</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       T1     T2     T3     T4     T5     T6     T7     T8     T9    T10\n",
       "0   0.019  0.026 -0.029 -0.012  0.022 -0.047  0.005 -0.020  0.011  0.002\n",
       "1   0.016  0.004 -0.012 -0.001  0.007 -0.015  0.012 -0.007 -0.003 -0.002\n",
       "2   0.019 -0.003  0.014  0.032  0.011 -0.002 -0.011 -0.041 -0.029  0.016\n",
       "3   0.021  0.028 -0.004 -0.003 -0.003  0.000 -0.008  0.009  0.008  0.014\n",
       "4   0.032 -0.011  0.007  0.030 -0.015 -0.018  0.042 -0.015  0.004 -0.017\n",
       "5   0.032 -0.009 -0.022  0.026  0.001 -0.018  0.038 -0.015  0.007  0.002\n",
       "6   0.012  0.005 -0.009 -0.008  0.014 -0.006  0.012  0.006  0.006  0.002\n",
       "7   0.040 -0.001  0.058 -0.073 -0.051 -0.038  0.037 -0.031  0.015 -0.034\n",
       "8   0.015  0.023 -0.010  0.005  0.010 -0.013  0.001 -0.005 -0.004 -0.004\n",
       "9   0.023  0.040 -0.017 -0.007 -0.019  0.065 -0.024  0.007 -0.022 -0.001\n",
       "10  0.035  0.017  0.032 -0.056 -0.037 -0.059 -0.005 -0.013 -0.021  0.017\n",
       "11  0.025 -0.010  0.019 -0.023 -0.014 -0.006  0.001  0.001 -0.017 -0.014\n",
       "12  0.016  0.017 -0.013 -0.008  0.024 -0.028  0.000 -0.019  0.008  0.006\n",
       "13  0.028  0.050 -0.031 -0.016  0.028 -0.067 -0.010  0.006 -0.058 -0.026\n",
       "14  0.025 -0.006 -0.028 -0.018  0.007 -0.013  0.035  0.002 -0.006 -0.015"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_topics = pd.DataFrame(np.round(topic_document.T, 3), \n",
    "                               columns=['T'+str(i) for i in range(1, TOTAL_TOPICS+1)])\n",
    "document_topics.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document #13:\n",
      "Dominant Topics (top 3): ['T6', 'T9', 'T2']\n",
      "Paper Summary:\n",
      "564 \n",
      "PROGRAMMABLE SYNAPTIC CHIP FOR \n",
      "ELECTRONIC NEURAL NETWORKS \n",
      "A. Moopenn, H. Langenbacher, A.P. Thakoor, and S.K. Khanna \n",
      "Jet Propulsion Laboratory \n",
      "California Institute of Technology \n",
      "Pasadena, CA 91009 \n",
      "ABSTRACT \n",
      "A binary synaptic matrix chip has been developed for electronic \n",
      "neural networks. The matrix chip contains a programmable 32X32 \n",
      "array of \"long channel\" NMOSFET binary connection elements imple- \n",
      "mented in a 3-um bulk CMOS process. Since the neurons are kept off- \n",
      "chip, the synapti\n",
      "\n",
      "Document #250:\n",
      "Dominant Topics (top 3): ['T8', 'T1', 'T5']\n",
      "Paper Summary:\n",
      "308 Donnett and Smithers \n",
      "Neuronal Group Selection Theory: \n",
      "A Grounding in Robotics \n",
      "Jim Donnett nd Tim Smithers \n",
      "Department of Artificial Intelligence \n",
      "University of Edinburgh \n",
      "5 Forrest Hill \n",
      "Edinburgh EH1 2QL \n",
      "S COTLAND \n",
      "ABSTRACT \n",
      "In this paper, we discuss a current attempt at applying the organi- \n",
      "zational principle Edelman calls Neuronal Group Selection to the \n",
      "control of a real, two-link robotic manipulator. We begin by moti- \n",
      "vating the need for an alternative to the position-control par\n",
      "\n",
      "Document #500:\n",
      "Dominant Topics (top 3): ['T4', 'T1', 'T3']\n",
      "Paper Summary:\n",
      "A Self-Organizing Integrated Segmentation And \n",
      "Recognition Neural Net \n",
      "Jim Keeler * \n",
      "MCC \n",
      "3500 West Balcones Center Drive \n",
      "Austin, TX 78729 \n",
      "David E. Rumelhart \n",
      "Psychology Department \n",
      "Stanford University \n",
      "Stanford, CA 94305 \n",
      "Abstract \n",
      "We present a neural network algorithm that simultaneously performs seg- \n",
      "mentation and recognition of input patterns that self-organizes to detect \n",
      "input pattern locations and pattern boundaries. We demonstrate this neu- \n",
      "ral network architecture on character recog\n",
      "\n"
     ]
    }
   ],
   "source": [
    "document_numbers = [13, 250, 500]\n",
    "\n",
    "for document_number in document_numbers:\n",
    "    top_topics = list(document_topics.columns[np.argsort(-np.absolute(document_topics.iloc[document_number].values))[:3]])\n",
    "    print('Document #'+str(document_number)+':')\n",
    "    print('Dominant Topics (top 3):', top_topics)\n",
    "    print('Paper Summary:')\n",
    "    print(papers[document_number][:500])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Models with Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 3s, sys: 1.88 s, total: 3min 5s\n",
      "Wall time: 3min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lda_model = gensim.models.LdaModel(corpus=bow_corpus, id2word=dictionary, chunksize=1740, \n",
    "                                   alpha='auto', eta='auto', random_state=42,\n",
    "                                   iterations=500, num_topics=TOTAL_TOPICS, \n",
    "                                   passes=20, eval_every=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "0.008*\"noise\" + 0.008*\"linear\" + 0.008*\"solution\" + 0.008*\"vector\" + 0.008*\"equation\" + 0.006*\"matrix\" + 0.005*\"training\" + 0.005*\"rule\" + 0.004*\"optimal\" + 0.004*\"signal\" + 0.004*\"eq\" + 0.004*\"distribution\" + 0.004*\"component\" + 0.004*\"filter\" + 0.004*\"line\" + 0.004*\"local\" + 0.004*\"rate\" + 0.004*\"average\" + 0.004*\"surface\" + 0.004*\"ica\"\n",
      "\n",
      "Topic #2:\n",
      "0.009*\"vector\" + 0.007*\"let\" + 0.006*\"theorem\" + 0.006*\"class\" + 0.006*\"bound\" + 0.006*\"node\" + 0.005*\"threshold\" + 0.005*\"linear\" + 0.005*\"matrix\" + 0.005*\"size\" + 0.004*\"proof\" + 0.004*\"complexity\" + 0.004*\"consider\" + 0.004*\"polynomial\" + 0.004*\"unit\" + 0.004*\"bit\" + 0.004*\"layer\" + 0.004*\"defined\" + 0.004*\"probability\" + 0.003*\"approximation\"\n",
      "\n",
      "Topic #3:\n",
      "0.033*\"state\" + 0.010*\"action\" + 0.008*\"step\" + 0.007*\"control\" + 0.006*\"policy\" + 0.006*\"task\" + 0.005*\"reinforcement_learning\" + 0.005*\"optimal\" + 0.004*\"convergence\" + 0.004*\"rate\" + 0.004*\"stochastic\" + 0.004*\"sequence\" + 0.004*\"environment\" + 0.003*\"dynamic\" + 0.003*\"transition\" + 0.003*\"probability\" + 0.003*\"goal\" + 0.003*\"reward\" + 0.003*\"update\" + 0.003*\"iteration\"\n",
      "\n",
      "Topic #4:\n",
      "0.009*\"distribution\" + 0.007*\"training\" + 0.006*\"estimate\" + 0.006*\"variable\" + 0.006*\"class\" + 0.006*\"gaussian\" + 0.005*\"probability\" + 0.005*\"approximation\" + 0.005*\"prior\" + 0.005*\"sample\" + 0.004*\"mixture\" + 0.004*\"density\" + 0.004*\"bayesian\" + 0.004*\"prediction\" + 0.004*\"kernel\" + 0.004*\"vector\" + 0.004*\"variance\" + 0.004*\"feature\" + 0.004*\"regression\" + 0.003*\"estimation\"\n",
      "\n",
      "Topic #5:\n",
      "0.014*\"control\" + 0.006*\"movement\" + 0.006*\"motor\" + 0.005*\"trajectory\" + 0.005*\"controller\" + 0.005*\"processor\" + 0.005*\"position\" + 0.004*\"change\" + 0.004*\"dynamic\" + 0.004*\"hand\" + 0.004*\"chip\" + 0.004*\"arm\" + 0.004*\"state\" + 0.004*\"architecture\" + 0.004*\"parallel\" + 0.004*\"training\" + 0.004*\"application\" + 0.004*\"target\" + 0.003*\"forward\" + 0.003*\"feedback\"\n",
      "\n",
      "Topic #6:\n",
      "0.016*\"training\" + 0.011*\"word\" + 0.009*\"recognition\" + 0.008*\"vector\" + 0.008*\"unit\" + 0.007*\"speech\" + 0.006*\"trained\" + 0.005*\"layer\" + 0.005*\"net\" + 0.005*\"architecture\" + 0.005*\"classification\" + 0.004*\"feature\" + 0.004*\"hmm\" + 0.004*\"task\" + 0.004*\"pattern\" + 0.004*\"class\" + 0.004*\"classifier\" + 0.004*\"sequence\" + 0.004*\"speaker\" + 0.004*\"experiment\"\n",
      "\n",
      "Topic #7:\n",
      "0.034*\"image\" + 0.014*\"feature\" + 0.013*\"object\" + 0.008*\"pixel\" + 0.006*\"visual\" + 0.005*\"representation\" + 0.004*\"view\" + 0.004*\"location\" + 0.004*\"region\" + 0.004*\"position\" + 0.004*\"filter\" + 0.004*\"field\" + 0.004*\"recognition\" + 0.004*\"edge\" + 0.004*\"scale\" + 0.004*\"part\" + 0.004*\"human\" + 0.003*\"signal\" + 0.003*\"target\" + 0.003*\"face\"\n",
      "\n",
      "Topic #8:\n",
      "0.024*\"neuron\" + 0.009*\"cell\" + 0.007*\"circuit\" + 0.006*\"signal\" + 0.006*\"current\" + 0.005*\"synaptic\" + 0.005*\"spike\" + 0.005*\"response\" + 0.005*\"neural\" + 0.005*\"pattern\" + 0.005*\"voltage\" + 0.005*\"dynamic\" + 0.004*\"activity\" + 0.004*\"noise\" + 0.004*\"chip\" + 0.004*\"synapsis\" + 0.004*\"state\" + 0.003*\"frequency\" + 0.003*\"effect\" + 0.003*\"connection\"\n",
      "\n",
      "Topic #9:\n",
      "0.026*\"unit\" + 0.012*\"cell\" + 0.012*\"pattern\" + 0.009*\"stimulus\" + 0.009*\"layer\" + 0.008*\"response\" + 0.008*\"activity\" + 0.006*\"representation\" + 0.006*\"activation\" + 0.005*\"connection\" + 0.005*\"neuron\" + 0.005*\"visual\" + 0.004*\"hidden_unit\" + 0.004*\"motion\" + 0.004*\"structure\" + 0.004*\"direction\" + 0.004*\"receptive_field\" + 0.003*\"task\" + 0.003*\"simulation\" + 0.003*\"training\"\n",
      "\n",
      "Topic #10:\n",
      "0.009*\"rule\" + 0.008*\"node\" + 0.007*\"pattern\" + 0.007*\"training\" + 0.006*\"tree\" + 0.005*\"structure\" + 0.005*\"memory\" + 0.005*\"class\" + 0.004*\"probability\" + 0.004*\"representation\" + 0.004*\"cluster\" + 0.004*\"classifier\" + 0.004*\"graph\" + 0.004*\"classification\" + 0.004*\"feature\" + 0.004*\"size\" + 0.004*\"task\" + 0.003*\"training_set\" + 0.003*\"clustering\" + 0.003*\"table\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for topic_id, topic in lda_model.print_topics(num_topics=10, num_words=20):\n",
    "    print('Topic #'+str(topic_id+1)+':')\n",
    "    print(topic)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Coherence Score: -1.0446050148659014\n"
     ]
    }
   ],
   "source": [
    "topics_coherences = lda_model.top_topics(bow_corpus, topn=20)\n",
    "avg_coherence_score = np.mean([item[1] for item in topics_coherences])\n",
    "print('Avg. Coherence Score:', avg_coherence_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Topics with Weights\n",
      "==================================================\n",
      "Topic #1:\n",
      "[('vector', 0.009), ('let', 0.007), ('theorem', 0.006), ('class', 0.006), ('bound', 0.006), ('node', 0.006), ('threshold', 0.005), ('linear', 0.005), ('matrix', 0.005), ('size', 0.005), ('proof', 0.004), ('complexity', 0.004), ('consider', 0.004), ('polynomial', 0.004), ('unit', 0.004), ('bit', 0.004), ('layer', 0.004), ('defined', 0.004), ('probability', 0.004), ('approximation', 0.003)]\n",
      "\n",
      "Topic #2:\n",
      "[('unit', 0.026), ('cell', 0.012), ('pattern', 0.012), ('stimulus', 0.009), ('layer', 0.009), ('response', 0.008), ('activity', 0.008), ('representation', 0.006), ('activation', 0.006), ('connection', 0.005), ('neuron', 0.005), ('visual', 0.005), ('hidden_unit', 0.004), ('motion', 0.004), ('structure', 0.004), ('direction', 0.004), ('receptive_field', 0.004), ('task', 0.003), ('simulation', 0.003), ('training', 0.003)]\n",
      "\n",
      "Topic #3:\n",
      "[('neuron', 0.024), ('cell', 0.009), ('circuit', 0.007), ('signal', 0.006), ('current', 0.006), ('synaptic', 0.005), ('spike', 0.005), ('response', 0.005), ('neural', 0.005), ('pattern', 0.005), ('voltage', 0.005), ('dynamic', 0.005), ('activity', 0.004), ('noise', 0.004), ('chip', 0.004), ('synapsis', 0.004), ('state', 0.004), ('frequency', 0.003), ('effect', 0.003), ('connection', 0.003)]\n",
      "\n",
      "Topic #4:\n",
      "[('training', 0.016), ('word', 0.011), ('recognition', 0.009), ('vector', 0.008), ('unit', 0.008), ('speech', 0.007), ('trained', 0.006), ('layer', 0.005), ('net', 0.005), ('architecture', 0.005), ('classification', 0.005), ('feature', 0.004), ('hmm', 0.004), ('task', 0.004), ('pattern', 0.004), ('class', 0.004), ('classifier', 0.004), ('sequence', 0.004), ('speaker', 0.004), ('experiment', 0.004)]\n",
      "\n",
      "Topic #5:\n",
      "[('rule', 0.009), ('node', 0.008), ('pattern', 0.007), ('training', 0.007), ('tree', 0.006), ('structure', 0.005), ('memory', 0.005), ('class', 0.005), ('probability', 0.004), ('representation', 0.004), ('cluster', 0.004), ('classifier', 0.004), ('graph', 0.004), ('classification', 0.004), ('feature', 0.004), ('size', 0.004), ('task', 0.004), ('training_set', 0.003), ('clustering', 0.003), ('table', 0.003)]\n",
      "\n",
      "Topic #6:\n",
      "[('distribution', 0.009), ('training', 0.007), ('estimate', 0.006), ('variable', 0.006), ('class', 0.006), ('gaussian', 0.006), ('probability', 0.005), ('approximation', 0.005), ('prior', 0.005), ('sample', 0.005), ('mixture', 0.004), ('density', 0.004), ('bayesian', 0.004), ('prediction', 0.004), ('kernel', 0.004), ('vector', 0.004), ('variance', 0.004), ('feature', 0.004), ('regression', 0.004), ('estimation', 0.003)]\n",
      "\n",
      "Topic #7:\n",
      "[('image', 0.034), ('feature', 0.014), ('object', 0.013), ('pixel', 0.008), ('visual', 0.006), ('representation', 0.005), ('view', 0.004), ('location', 0.004), ('region', 0.004), ('position', 0.004), ('filter', 0.004), ('field', 0.004), ('recognition', 0.004), ('edge', 0.004), ('scale', 0.004), ('part', 0.004), ('human', 0.004), ('signal', 0.003), ('target', 0.003), ('face', 0.003)]\n",
      "\n",
      "Topic #8:\n",
      "[('state', 0.033), ('action', 0.01), ('step', 0.008), ('control', 0.007), ('policy', 0.006), ('task', 0.006), ('reinforcement_learning', 0.005), ('optimal', 0.005), ('convergence', 0.004), ('rate', 0.004), ('stochastic', 0.004), ('sequence', 0.004), ('environment', 0.004), ('dynamic', 0.003), ('transition', 0.003), ('probability', 0.003), ('goal', 0.003), ('reward', 0.003), ('update', 0.003), ('iteration', 0.003)]\n",
      "\n",
      "Topic #9:\n",
      "[('control', 0.014), ('movement', 0.006), ('motor', 0.006), ('trajectory', 0.005), ('controller', 0.005), ('processor', 0.005), ('position', 0.005), ('change', 0.004), ('dynamic', 0.004), ('hand', 0.004), ('chip', 0.004), ('arm', 0.004), ('state', 0.004), ('architecture', 0.004), ('parallel', 0.004), ('training', 0.004), ('application', 0.004), ('target', 0.004), ('forward', 0.003), ('feedback', 0.003)]\n",
      "\n",
      "Topic #10:\n",
      "[('noise', 0.008), ('linear', 0.008), ('solution', 0.008), ('vector', 0.008), ('equation', 0.008), ('matrix', 0.006), ('training', 0.005), ('rule', 0.005), ('optimal', 0.004), ('signal', 0.004), ('eq', 0.004), ('distribution', 0.004), ('component', 0.004), ('filter', 0.004), ('line', 0.004), ('local', 0.004), ('rate', 0.004), ('average', 0.004), ('surface', 0.004), ('ica', 0.004)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topics_with_wts = [item[0] for item in topics_coherences]\n",
    "print('LDA Topics with Weights')\n",
    "print('='*50)\n",
    "for idx, topic in enumerate(topics_with_wts):\n",
    "    print('Topic #'+str(idx+1)+':')\n",
    "    print([(term, round(wt, 3)) for wt, term in topic])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Topics without Weights\n",
      "==================================================\n",
      "Topic #1:\n",
      "['vector', 'let', 'theorem', 'class', 'bound', 'node', 'threshold', 'linear', 'matrix', 'size', 'proof', 'complexity', 'consider', 'polynomial', 'unit', 'bit', 'layer', 'defined', 'probability', 'approximation']\n",
      "\n",
      "Topic #2:\n",
      "['unit', 'cell', 'pattern', 'stimulus', 'layer', 'response', 'activity', 'representation', 'activation', 'connection', 'neuron', 'visual', 'hidden_unit', 'motion', 'structure', 'direction', 'receptive_field', 'task', 'simulation', 'training']\n",
      "\n",
      "Topic #3:\n",
      "['neuron', 'cell', 'circuit', 'signal', 'current', 'synaptic', 'spike', 'response', 'neural', 'pattern', 'voltage', 'dynamic', 'activity', 'noise', 'chip', 'synapsis', 'state', 'frequency', 'effect', 'connection']\n",
      "\n",
      "Topic #4:\n",
      "['training', 'word', 'recognition', 'vector', 'unit', 'speech', 'trained', 'layer', 'net', 'architecture', 'classification', 'feature', 'hmm', 'task', 'pattern', 'class', 'classifier', 'sequence', 'speaker', 'experiment']\n",
      "\n",
      "Topic #5:\n",
      "['rule', 'node', 'pattern', 'training', 'tree', 'structure', 'memory', 'class', 'probability', 'representation', 'cluster', 'classifier', 'graph', 'classification', 'feature', 'size', 'task', 'training_set', 'clustering', 'table']\n",
      "\n",
      "Topic #6:\n",
      "['distribution', 'training', 'estimate', 'variable', 'class', 'gaussian', 'probability', 'approximation', 'prior', 'sample', 'mixture', 'density', 'bayesian', 'prediction', 'kernel', 'vector', 'variance', 'feature', 'regression', 'estimation']\n",
      "\n",
      "Topic #7:\n",
      "['image', 'feature', 'object', 'pixel', 'visual', 'representation', 'view', 'location', 'region', 'position', 'filter', 'field', 'recognition', 'edge', 'scale', 'part', 'human', 'signal', 'target', 'face']\n",
      "\n",
      "Topic #8:\n",
      "['state', 'action', 'step', 'control', 'policy', 'task', 'reinforcement_learning', 'optimal', 'convergence', 'rate', 'stochastic', 'sequence', 'environment', 'dynamic', 'transition', 'probability', 'goal', 'reward', 'update', 'iteration']\n",
      "\n",
      "Topic #9:\n",
      "['control', 'movement', 'motor', 'trajectory', 'controller', 'processor', 'position', 'change', 'dynamic', 'hand', 'chip', 'arm', 'state', 'architecture', 'parallel', 'training', 'application', 'target', 'forward', 'feedback']\n",
      "\n",
      "Topic #10:\n",
      "['noise', 'linear', 'solution', 'vector', 'equation', 'matrix', 'training', 'rule', 'optimal', 'signal', 'eq', 'distribution', 'component', 'filter', 'line', 'local', 'rate', 'average', 'surface', 'ica']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('LDA Topics without Weights')\n",
    "print('='*50)\n",
    "for idx, topic in enumerate(topics_with_wts):\n",
    "    print('Topic #'+str(idx+1)+':')\n",
    "    print([term for wt, term in topic])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Coherence Score (Cv): 0.4603294946568357\n",
      "Avg. Coherence Score (UMass): -1.0446050148659014\n",
      "Model Perplexity: -7.800904216105166\n"
     ]
    }
   ],
   "source": [
    "cv_coherence_model_lda = gensim.models.CoherenceModel(model=lda_model, corpus=bow_corpus, \n",
    "                                                      texts=norm_corpus_bigrams,\n",
    "                                                      dictionary=dictionary, \n",
    "                                                      coherence='c_v')\n",
    "avg_coherence_cv = cv_coherence_model_lda.get_coherence()\n",
    "\n",
    "umass_coherence_model_lda = gensim.models.CoherenceModel(model=lda_model, corpus=bow_corpus, \n",
    "                                                         texts=norm_corpus_bigrams,\n",
    "                                                         dictionary=dictionary, \n",
    "                                                         coherence='u_mass')\n",
    "avg_coherence_umass = umass_coherence_model_lda.get_coherence()\n",
    "\n",
    "perplexity = lda_model.log_perplexity(bow_corpus)\n",
    "\n",
    "print('Avg. Coherence Score (Cv):', avg_coherence_cv)\n",
    "print('Avg. Coherence Score (UMass):', avg_coherence_umass)\n",
    "print('Model Perplexity:', perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA with Mallet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-10-10 12:08:45--  http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
      "Resolving mallet.cs.umass.edu... 128.119.246.70\n",
      "Connecting to mallet.cs.umass.edu|128.119.246.70|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 16184794 (15M) [application/zip]\n",
      "Saving to: ‘mallet-2.0.8.zip’\n",
      "\n",
      "mallet-2.0.8.zip    100%[===================>]  15.43M  4.00MB/s    in 3.9s    \n",
      "\n",
      "2020-10-10 12:08:50 (4.00 MB/s) - ‘mallet-2.0.8.zip’ saved [16184794/16184794]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -q mallet-2.0.8.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "MALLET_PATH = 'mallet-2.0.8/bin/mallet'\n",
    "lda_mallet = gensim.models.wrappers.LdaMallet(mallet_path=MALLET_PATH, corpus=bow_corpus, \n",
    "                                              num_topics=TOTAL_TOPICS, id2word=dictionary,\n",
    "                                              iterations=500, workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "['neuron', 'cell', 'response', 'stimulus', 'activity', 'pattern', 'signal', 'spike', 'effect', 'frequency', 'neural', 'synaptic', 'cortical', 'firing', 'connection', 'et_al', 'brain', 'temporal', 'cortex', 'change']\n",
      "\n",
      "Topic #2:\n",
      "['search', 'experiment', 'cluster', 'feature', 'technique', 'graph', 'measure', 'size', 'cost', 'clustering', 'test', 'run', 'local', 'random', 'solution', 'table', 'region', 'distance', 'average', 'instance']\n",
      "\n",
      "Topic #3:\n",
      "['image', 'object', 'feature', 'visual', 'motion', 'position', 'direction', 'pixel', 'map', 'location', 'field', 'representation', 'region', 'view', 'target', 'face', 'filter', 'human', 'local', 'subject']\n",
      "\n",
      "Topic #4:\n",
      "['class', 'bound', 'size', 'probability', 'theorem', 'tree', 'node', 'theory', 'linear', 'threshold', 'complexity', 'defined', 'constant', 'approximation', 'loss', 'proof', 'hypothesis', 'polynomial', 'machine', 'distribution']\n",
      "\n",
      "Topic #5:\n",
      "['unit', 'pattern', 'layer', 'training', 'hidden_unit', 'rule', 'net', 'architecture', 'node', 'activation', 'representation', 'task', 'recurrent', 'trained', 'structure', 'connection', 'sequence', 'module', 'back_propagation', 'learn']\n",
      "\n",
      "Topic #6:\n",
      "['neuron', 'circuit', 'memory', 'current', 'signal', 'chip', 'analog', 'bit', 'voltage', 'noise', 'code', 'channel', 'neural', 'implementation', 'processor', 'parallel', 'operation', 'design', 'connection', 'computation']\n",
      "\n",
      "Topic #7:\n",
      "['state', 'control', 'action', 'step', 'trajectory', 'policy', 'task', 'dynamic', 'environment', 'controller', 'optimal', 'reinforcement_learning', 'transition', 'change', 'goal', 'robot', 'sequence', 'path', 'rate', 'adaptive']\n",
      "\n",
      "Topic #8:\n",
      "['distribution', 'estimate', 'noise', 'gaussian', 'variable', 'probability', 'prior', 'prediction', 'approximation', 'density', 'mixture', 'variance', 'sample', 'estimation', 'training', 'bayesian', 'regression', 'average', 'log', 'likelihood']\n",
      "\n",
      "Topic #9:\n",
      "['training', 'classification', 'word', 'class', 'classifier', 'recognition', 'feature', 'pattern', 'speech', 'trained', 'test', 'vector', 'training_set', 'character', 'sequence', 'experiment', 'hmm', 'context', 'test_set', 'table']\n",
      "\n",
      "Topic #10:\n",
      "['vector', 'matrix', 'equation', 'solution', 'linear', 'dynamic', 'nonlinear', 'eq', 'gradient', 'convergence', 'component', 'rate', 'rule', 'source', 'constraint', 'dimensional', 'energy', 'property', 'optimal', 'line']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topics = [[(term, round(wt, 3)) \n",
    "               for term, wt in lda_mallet.show_topic(n, topn=20)] \n",
    "                   for n in range(0, TOTAL_TOPICS)]\n",
    "\n",
    "for idx, topic in enumerate(topics):\n",
    "    print('Topic #'+str(idx+1)+':')\n",
    "    print([term for term, wt in topic])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Coherence Score (Cv): 0.5038963843699132\n",
      "Avg. Coherence Score (UMass): -1.0285099132611792\n",
      "Model Perplexity: -8.53533\n"
     ]
    }
   ],
   "source": [
    "cv_coherence_model_lda_mallet = gensim.models.CoherenceModel(model=lda_mallet, corpus=bow_corpus, \n",
    "                                                             texts=norm_corpus_bigrams,\n",
    "                                                             dictionary=dictionary, \n",
    "                                                             coherence='c_v')\n",
    "avg_coherence_cv = cv_coherence_model_lda_mallet.get_coherence()\n",
    "\n",
    "umass_coherence_model_lda_mallet = gensim.models.CoherenceModel(model=lda_mallet, corpus=bow_corpus, \n",
    "                                                                texts=norm_corpus_bigrams,\n",
    "                                                                dictionary=dictionary,  \n",
    "                                                                coherence='u_mass')\n",
    "avg_coherence_umass = umass_coherence_model_lda_mallet.get_coherence()\n",
    "\n",
    "# from STDOUT: <500> LL/token: -8.53533\n",
    "perplexity = -8.53533\n",
    "print('Avg. Coherence Score (Cv):', avg_coherence_cv)\n",
    "print('Avg. Coherence Score (UMass):', avg_coherence_umass)\n",
    "print('Model Perplexity:', perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA Tuning - Finading Optimal Number of Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def topic_model_coherence_generator(corpus, texts, dictionary, \n",
    "                                    start_topic_count=2, end_topic_count=10, step=1,\n",
    "                                    cpus=1):\n",
    "    \n",
    "    models = []\n",
    "    coherence_scores = []\n",
    "    for topic_nums in tqdm(range(start_topic_count, end_topic_count+1, step)):\n",
    "        mallet_lda_model = gensim.models.wrappers.LdaMallet(mallet_path=MALLET_PATH, corpus=corpus,\n",
    "                                                            num_topics=topic_nums, id2word=dictionary,\n",
    "                                                            iterations=500, workers=cpus)\n",
    "        cv_coherence_model_mallet_lda = gensim.models.CoherenceModel(model=mallet_lda_model, corpus=corpus, \n",
    "                                                                     texts=texts, dictionary=dictionary, \n",
    "                                                                     coherence='c_v')\n",
    "        coherence_score = cv_coherence_model_mallet_lda.get_coherence()\n",
    "        coherence_scores.append(coherence_score)\n",
    "        models.append(mallet_lda_model)\n",
    "    \n",
    "    return models, coherence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [51:04<00:00, 105.66s/it]\n"
     ]
    }
   ],
   "source": [
    "lda_models, coherence_scores = topic_model_coherence_generator(corpus=bow_corpus, texts=norm_corpus_bigrams,\n",
    "                                                               dictionary=dictionary, start_topic_count=2,\n",
    "                                                               end_topic_count=30, step=1, cpus=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Topics</th>\n",
       "      <th>Coherence Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>0.5475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19</td>\n",
       "      <td>0.5438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>25</td>\n",
       "      <td>0.5425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>24</td>\n",
       "      <td>0.5411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>28</td>\n",
       "      <td>0.5410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>26</td>\n",
       "      <td>0.5410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18</td>\n",
       "      <td>0.5401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>23</td>\n",
       "      <td>0.5375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>30</td>\n",
       "      <td>0.5338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>29</td>\n",
       "      <td>0.5331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number of Topics  Coherence Score\n",
       "18                20           0.5475\n",
       "17                19           0.5438\n",
       "23                25           0.5425\n",
       "22                24           0.5411\n",
       "26                28           0.5410\n",
       "24                26           0.5410\n",
       "16                18           0.5401\n",
       "21                23           0.5375\n",
       "28                30           0.5338\n",
       "27                29           0.5331"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence_df = pd.DataFrame({'Number of Topics': range(2, 31, 1),\n",
    "                             'Coherence Score': np.round(coherence_scores, 4)})\n",
    "coherence_df.sort_values(by=['Coherence Score'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline\n",
    "\n",
    "x_ax = range(2, 31, 1)\n",
    "y_ax = coherence_scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(x_ax, y_ax, c='r')\n",
    "plt.axhline(y=0.535, c='k', linestyle='--', linewidth=2)\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "xl = plt.xlabel('Number of Topics')\n",
    "yl = plt.ylabel('Coherence Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_idx = coherence_df[coherence_df['Number of Topics'] == 20].index[0]\n",
    "best_lda_model = lda_models[best_model_idx]\n",
    "best_lda_model.num_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "['word', 'recognition', 'training', 'speech', 'context', 'hmm', 'sequence', 'state', 'speaker', 'frame', 'letter', 'speech_recognition', 'phoneme', 'mlp', 'feature', 'experiment', 'vowel', 'trained', 'hybrid', 'segmentation']\n",
      "\n",
      "Topic #2:\n",
      "['classification', 'class', 'classifier', 'feature', 'pattern', 'training', 'character', 'face', 'test', 'training_set', 'recognition', 'digit', 'distance', 'database', 'sample', 'error_rate', 'rate', 'size', 'nearest_neighbor', 'trained']\n",
      "\n",
      "Topic #3:\n",
      "['training', 'prediction', 'test', 'training_set', 'experiment', 'selection', 'trained', 'table', 'regression', 'average', 'query', 'measure', 'cross_validation', 'technique', 'time_series', 'application', 'expert', 'rbf', 'test_set', 'bias']\n",
      "\n",
      "Topic #4:\n",
      "['neuron', 'cell', 'spike', 'synaptic', 'activity', 'response', 'firing', 'stimulus', 'pattern', 'synapsis', 'effect', 'threshold', 'neural', 'et_al', 'neuronal', 'inhibitory', 'simulation', 'firing_rate', 'excitatory', 'current']\n",
      "\n",
      "Topic #5:\n",
      "['state', 'control', 'action', 'policy', 'step', 'controller', 'environment', 'reinforcement_learning', 'task', 'robot', 'trajectory', 'optimal', 'goal', 'reward', 'change', 'td', 'agent', 'trial', 'position', 'current']\n",
      "\n",
      "Topic #6:\n",
      "['rule', 'representation', 'task', 'human', 'structure', 'feature', 'similarity', 'search', 'subject', 'instance', 'learned', 'knowledge', 'connectionist', 'domain', 'role', 'level', 'theory', 'category', 'position', 'note']\n",
      "\n",
      "Topic #7:\n",
      "['vector', 'matrix', 'linear', 'nonlinear', 'dimensional', 'mapping', 'dimension', 'transformation', 'component', 'local', 'map', 'operator', 'distance', 'basis', 'pca', 'structure', 'rule', 'projection', 'inverse', 'principal_component']\n",
      "\n",
      "Topic #8:\n",
      "['distribution', 'probability', 'estimate', 'prior', 'gaussian', 'sample', 'density', 'bayesian', 'estimation', 'variance', 'log', 'approximation', 'estimator', 'entropy', 'posterior', 'kernel', 'noise', 'true', 'stochastic', 'statistic']\n",
      "\n",
      "Topic #9:\n",
      "['solution', 'convergence', 'gradient', 'constraint', 'equation', 'rate', 'iteration', 'optimization', 'energy', 'minimum', 'update', 'optimal', 'gradient_descent', 'constant', 'derivative', 'cost', 'step', 'quadratic', 'find', 'local_minimum']\n",
      "\n",
      "Topic #10:\n",
      "['memory', 'bit', 'pattern', 'code', 'capacity', 'neuron', 'element', 'processor', 'size', 'vector', 'parallel', 'hopfield', 'computation', 'stored', 'connection', 'operation', 'neural_net', 'coding', 'binary', 'computer']\n",
      "\n",
      "Topic #11:\n",
      "['noise', 'equation', 'curve', 'correlation', 'average', 'eq', 'rate', 'theory', 'limit', 'solution', 'generalization_error', 'distribution', 'optimal', 'size', 'teacher', 'line', 'effect', 'random', 'student', 'find']\n",
      "\n",
      "Topic #12:\n",
      "['motion', 'visual', 'response', 'stimulus', 'cell', 'map', 'direction', 'receptive_field', 'activity', 'spatial', 'orientation', 'eye', 'location', 'unit', 'field', 'target', 'center', 'velocity', 'position', 'pattern']\n",
      "\n",
      "Topic #13:\n",
      "['variable', 'mixture', 'cluster', 'clustering', 'step', 'component', 'em', 'expert', 'hidden', 'likelihood', 'structure', 'mean_field', 'approximation', 'probability', 'em_algorithm', 'missing', 'mi', 'xi', 'log_likelihood', 'binary']\n",
      "\n",
      "Topic #14:\n",
      "['bound', 'class', 'theorem', 'approximation', 'proof', 'polynomial', 'loss', 'linear', 'complexity', 'xi', 'theory', 'threshold', 'defined', 'constant', 'size', 'condition', 'hypothesis', 'bounded', 'definition', 'assume']\n",
      "\n",
      "Topic #15:\n",
      "['dynamic', 'state', 'phase', 'module', 'behavior', 'recurrent', 'attractor', 'feedback', 'trajectory', 'neural', 'control', 'delay', 'equation', 'oscillation', 'fixed_point', 'oscillator', 'connection', 'motor', 'stable', 'stability']\n",
      "\n",
      "Topic #16:\n",
      "['unit', 'layer', 'hidden_unit', 'net', 'training', 'pattern', 'architecture', 'activation', 'trained', 'hidden_layer', 'back_propagation', 'connection', 'task', 'hidden', 'learn', 'simulation', 'backpropagation', 'target', 'epoch', 'step']\n",
      "\n",
      "Topic #17:\n",
      "['node', 'sequence', 'tree', 'graph', 'structure', 'state', 'symbol', 'string', 'path', 'length', 'level', 'machine', 'link', 'step', 'edge', 'language', 'grammar', 'local', 'markov', 'recurrent']\n",
      "\n",
      "Topic #18:\n",
      "['circuit', 'chip', 'current', 'analog', 'voltage', 'neuron', 'design', 'implementation', 'device', 'synapse', 'digital', 'neural', 'pulse', 'transistor', 'array', 'gain', 'line', 'analog_vlsi', 'hardware', 'implemented']\n",
      "\n",
      "Topic #19:\n",
      "['image', 'object', 'feature', 'pixel', 'view', 'region', 'surface', 'shape', 'visual', 'scale', 'local', 'contour', 'part', 'edge', 'representation', 'location', 'position', 'scene', 'vision', 'matching']\n",
      "\n",
      "Topic #20:\n",
      "['signal', 'filter', 'frequency', 'source', 'channel', 'noise', 'response', 'component', 'temporal', 'sound', 'auditory', 'ica', 'amplitude', 'phase', 'adaptation', 'detection', 'change', 'eeg', 'processing', 'subject']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topics = [[(term, round(wt, 3)) \n",
    "               for term, wt in best_lda_model.show_topic(n, topn=20)] \n",
    "                   for n in range(0, best_lda_model.num_topics)]\n",
    "\n",
    "for idx, topic in enumerate(topics):\n",
    "    print('Topic #'+str(idx+1)+':')\n",
    "    print([term for term, wt in topic])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "      <th>Topic 3</th>\n",
       "      <th>Topic 4</th>\n",
       "      <th>Topic 5</th>\n",
       "      <th>Topic 6</th>\n",
       "      <th>Topic 7</th>\n",
       "      <th>Topic 8</th>\n",
       "      <th>Topic 9</th>\n",
       "      <th>Topic 10</th>\n",
       "      <th>Topic 11</th>\n",
       "      <th>Topic 12</th>\n",
       "      <th>Topic 13</th>\n",
       "      <th>Topic 14</th>\n",
       "      <th>Topic 15</th>\n",
       "      <th>Topic 16</th>\n",
       "      <th>Topic 17</th>\n",
       "      <th>Topic 18</th>\n",
       "      <th>Topic 19</th>\n",
       "      <th>Topic 20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Term1</th>\n",
       "      <td>word</td>\n",
       "      <td>classification</td>\n",
       "      <td>training</td>\n",
       "      <td>neuron</td>\n",
       "      <td>state</td>\n",
       "      <td>rule</td>\n",
       "      <td>vector</td>\n",
       "      <td>distribution</td>\n",
       "      <td>solution</td>\n",
       "      <td>memory</td>\n",
       "      <td>noise</td>\n",
       "      <td>motion</td>\n",
       "      <td>variable</td>\n",
       "      <td>bound</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>unit</td>\n",
       "      <td>node</td>\n",
       "      <td>circuit</td>\n",
       "      <td>image</td>\n",
       "      <td>signal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term2</th>\n",
       "      <td>recognition</td>\n",
       "      <td>class</td>\n",
       "      <td>prediction</td>\n",
       "      <td>cell</td>\n",
       "      <td>control</td>\n",
       "      <td>representation</td>\n",
       "      <td>matrix</td>\n",
       "      <td>probability</td>\n",
       "      <td>convergence</td>\n",
       "      <td>bit</td>\n",
       "      <td>equation</td>\n",
       "      <td>visual</td>\n",
       "      <td>mixture</td>\n",
       "      <td>class</td>\n",
       "      <td>state</td>\n",
       "      <td>layer</td>\n",
       "      <td>sequence</td>\n",
       "      <td>chip</td>\n",
       "      <td>object</td>\n",
       "      <td>filter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term3</th>\n",
       "      <td>training</td>\n",
       "      <td>classifier</td>\n",
       "      <td>test</td>\n",
       "      <td>spike</td>\n",
       "      <td>action</td>\n",
       "      <td>task</td>\n",
       "      <td>linear</td>\n",
       "      <td>estimate</td>\n",
       "      <td>gradient</td>\n",
       "      <td>pattern</td>\n",
       "      <td>curve</td>\n",
       "      <td>response</td>\n",
       "      <td>cluster</td>\n",
       "      <td>theorem</td>\n",
       "      <td>phase</td>\n",
       "      <td>hidden_unit</td>\n",
       "      <td>tree</td>\n",
       "      <td>current</td>\n",
       "      <td>feature</td>\n",
       "      <td>frequency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term4</th>\n",
       "      <td>speech</td>\n",
       "      <td>feature</td>\n",
       "      <td>training_set</td>\n",
       "      <td>synaptic</td>\n",
       "      <td>policy</td>\n",
       "      <td>human</td>\n",
       "      <td>nonlinear</td>\n",
       "      <td>prior</td>\n",
       "      <td>constraint</td>\n",
       "      <td>code</td>\n",
       "      <td>correlation</td>\n",
       "      <td>stimulus</td>\n",
       "      <td>clustering</td>\n",
       "      <td>approximation</td>\n",
       "      <td>module</td>\n",
       "      <td>net</td>\n",
       "      <td>graph</td>\n",
       "      <td>analog</td>\n",
       "      <td>pixel</td>\n",
       "      <td>source</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term5</th>\n",
       "      <td>context</td>\n",
       "      <td>pattern</td>\n",
       "      <td>experiment</td>\n",
       "      <td>activity</td>\n",
       "      <td>step</td>\n",
       "      <td>structure</td>\n",
       "      <td>dimensional</td>\n",
       "      <td>gaussian</td>\n",
       "      <td>equation</td>\n",
       "      <td>capacity</td>\n",
       "      <td>average</td>\n",
       "      <td>cell</td>\n",
       "      <td>step</td>\n",
       "      <td>proof</td>\n",
       "      <td>behavior</td>\n",
       "      <td>training</td>\n",
       "      <td>structure</td>\n",
       "      <td>voltage</td>\n",
       "      <td>view</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term6</th>\n",
       "      <td>hmm</td>\n",
       "      <td>training</td>\n",
       "      <td>selection</td>\n",
       "      <td>response</td>\n",
       "      <td>controller</td>\n",
       "      <td>feature</td>\n",
       "      <td>mapping</td>\n",
       "      <td>sample</td>\n",
       "      <td>rate</td>\n",
       "      <td>neuron</td>\n",
       "      <td>eq</td>\n",
       "      <td>map</td>\n",
       "      <td>component</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>recurrent</td>\n",
       "      <td>pattern</td>\n",
       "      <td>state</td>\n",
       "      <td>neuron</td>\n",
       "      <td>region</td>\n",
       "      <td>noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term7</th>\n",
       "      <td>sequence</td>\n",
       "      <td>character</td>\n",
       "      <td>trained</td>\n",
       "      <td>firing</td>\n",
       "      <td>environment</td>\n",
       "      <td>similarity</td>\n",
       "      <td>dimension</td>\n",
       "      <td>density</td>\n",
       "      <td>iteration</td>\n",
       "      <td>element</td>\n",
       "      <td>rate</td>\n",
       "      <td>direction</td>\n",
       "      <td>em</td>\n",
       "      <td>loss</td>\n",
       "      <td>attractor</td>\n",
       "      <td>architecture</td>\n",
       "      <td>symbol</td>\n",
       "      <td>design</td>\n",
       "      <td>surface</td>\n",
       "      <td>response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term8</th>\n",
       "      <td>state</td>\n",
       "      <td>face</td>\n",
       "      <td>table</td>\n",
       "      <td>stimulus</td>\n",
       "      <td>reinforcement_learning</td>\n",
       "      <td>search</td>\n",
       "      <td>transformation</td>\n",
       "      <td>bayesian</td>\n",
       "      <td>optimization</td>\n",
       "      <td>processor</td>\n",
       "      <td>theory</td>\n",
       "      <td>receptive_field</td>\n",
       "      <td>expert</td>\n",
       "      <td>linear</td>\n",
       "      <td>feedback</td>\n",
       "      <td>activation</td>\n",
       "      <td>string</td>\n",
       "      <td>implementation</td>\n",
       "      <td>shape</td>\n",
       "      <td>component</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term9</th>\n",
       "      <td>speaker</td>\n",
       "      <td>test</td>\n",
       "      <td>regression</td>\n",
       "      <td>pattern</td>\n",
       "      <td>task</td>\n",
       "      <td>subject</td>\n",
       "      <td>component</td>\n",
       "      <td>estimation</td>\n",
       "      <td>energy</td>\n",
       "      <td>size</td>\n",
       "      <td>limit</td>\n",
       "      <td>activity</td>\n",
       "      <td>hidden</td>\n",
       "      <td>complexity</td>\n",
       "      <td>trajectory</td>\n",
       "      <td>trained</td>\n",
       "      <td>path</td>\n",
       "      <td>device</td>\n",
       "      <td>visual</td>\n",
       "      <td>temporal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term10</th>\n",
       "      <td>frame</td>\n",
       "      <td>training_set</td>\n",
       "      <td>average</td>\n",
       "      <td>synapsis</td>\n",
       "      <td>robot</td>\n",
       "      <td>instance</td>\n",
       "      <td>local</td>\n",
       "      <td>variance</td>\n",
       "      <td>minimum</td>\n",
       "      <td>vector</td>\n",
       "      <td>solution</td>\n",
       "      <td>spatial</td>\n",
       "      <td>likelihood</td>\n",
       "      <td>xi</td>\n",
       "      <td>neural</td>\n",
       "      <td>hidden_layer</td>\n",
       "      <td>length</td>\n",
       "      <td>synapse</td>\n",
       "      <td>scale</td>\n",
       "      <td>sound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term11</th>\n",
       "      <td>letter</td>\n",
       "      <td>recognition</td>\n",
       "      <td>query</td>\n",
       "      <td>effect</td>\n",
       "      <td>trajectory</td>\n",
       "      <td>learned</td>\n",
       "      <td>map</td>\n",
       "      <td>log</td>\n",
       "      <td>update</td>\n",
       "      <td>parallel</td>\n",
       "      <td>generalization_error</td>\n",
       "      <td>orientation</td>\n",
       "      <td>structure</td>\n",
       "      <td>theory</td>\n",
       "      <td>control</td>\n",
       "      <td>back_propagation</td>\n",
       "      <td>level</td>\n",
       "      <td>digital</td>\n",
       "      <td>local</td>\n",
       "      <td>auditory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term12</th>\n",
       "      <td>speech_recognition</td>\n",
       "      <td>digit</td>\n",
       "      <td>measure</td>\n",
       "      <td>threshold</td>\n",
       "      <td>optimal</td>\n",
       "      <td>knowledge</td>\n",
       "      <td>operator</td>\n",
       "      <td>approximation</td>\n",
       "      <td>optimal</td>\n",
       "      <td>hopfield</td>\n",
       "      <td>distribution</td>\n",
       "      <td>eye</td>\n",
       "      <td>mean_field</td>\n",
       "      <td>threshold</td>\n",
       "      <td>delay</td>\n",
       "      <td>connection</td>\n",
       "      <td>machine</td>\n",
       "      <td>neural</td>\n",
       "      <td>contour</td>\n",
       "      <td>ica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term13</th>\n",
       "      <td>phoneme</td>\n",
       "      <td>distance</td>\n",
       "      <td>cross_validation</td>\n",
       "      <td>neural</td>\n",
       "      <td>goal</td>\n",
       "      <td>connectionist</td>\n",
       "      <td>distance</td>\n",
       "      <td>estimator</td>\n",
       "      <td>gradient_descent</td>\n",
       "      <td>computation</td>\n",
       "      <td>optimal</td>\n",
       "      <td>location</td>\n",
       "      <td>approximation</td>\n",
       "      <td>defined</td>\n",
       "      <td>equation</td>\n",
       "      <td>task</td>\n",
       "      <td>link</td>\n",
       "      <td>pulse</td>\n",
       "      <td>part</td>\n",
       "      <td>amplitude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term14</th>\n",
       "      <td>mlp</td>\n",
       "      <td>database</td>\n",
       "      <td>technique</td>\n",
       "      <td>et_al</td>\n",
       "      <td>reward</td>\n",
       "      <td>domain</td>\n",
       "      <td>basis</td>\n",
       "      <td>entropy</td>\n",
       "      <td>constant</td>\n",
       "      <td>stored</td>\n",
       "      <td>size</td>\n",
       "      <td>unit</td>\n",
       "      <td>probability</td>\n",
       "      <td>constant</td>\n",
       "      <td>oscillation</td>\n",
       "      <td>hidden</td>\n",
       "      <td>step</td>\n",
       "      <td>transistor</td>\n",
       "      <td>edge</td>\n",
       "      <td>phase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term15</th>\n",
       "      <td>feature</td>\n",
       "      <td>sample</td>\n",
       "      <td>time_series</td>\n",
       "      <td>neuronal</td>\n",
       "      <td>change</td>\n",
       "      <td>role</td>\n",
       "      <td>pca</td>\n",
       "      <td>posterior</td>\n",
       "      <td>derivative</td>\n",
       "      <td>connection</td>\n",
       "      <td>teacher</td>\n",
       "      <td>field</td>\n",
       "      <td>em_algorithm</td>\n",
       "      <td>size</td>\n",
       "      <td>fixed_point</td>\n",
       "      <td>learn</td>\n",
       "      <td>edge</td>\n",
       "      <td>array</td>\n",
       "      <td>representation</td>\n",
       "      <td>adaptation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term16</th>\n",
       "      <td>experiment</td>\n",
       "      <td>error_rate</td>\n",
       "      <td>application</td>\n",
       "      <td>inhibitory</td>\n",
       "      <td>td</td>\n",
       "      <td>level</td>\n",
       "      <td>structure</td>\n",
       "      <td>kernel</td>\n",
       "      <td>cost</td>\n",
       "      <td>operation</td>\n",
       "      <td>line</td>\n",
       "      <td>target</td>\n",
       "      <td>missing</td>\n",
       "      <td>condition</td>\n",
       "      <td>oscillator</td>\n",
       "      <td>simulation</td>\n",
       "      <td>language</td>\n",
       "      <td>gain</td>\n",
       "      <td>location</td>\n",
       "      <td>detection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term17</th>\n",
       "      <td>vowel</td>\n",
       "      <td>rate</td>\n",
       "      <td>expert</td>\n",
       "      <td>simulation</td>\n",
       "      <td>agent</td>\n",
       "      <td>theory</td>\n",
       "      <td>rule</td>\n",
       "      <td>noise</td>\n",
       "      <td>step</td>\n",
       "      <td>neural_net</td>\n",
       "      <td>effect</td>\n",
       "      <td>center</td>\n",
       "      <td>mi</td>\n",
       "      <td>hypothesis</td>\n",
       "      <td>connection</td>\n",
       "      <td>backpropagation</td>\n",
       "      <td>grammar</td>\n",
       "      <td>line</td>\n",
       "      <td>position</td>\n",
       "      <td>change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term18</th>\n",
       "      <td>trained</td>\n",
       "      <td>size</td>\n",
       "      <td>rbf</td>\n",
       "      <td>firing_rate</td>\n",
       "      <td>trial</td>\n",
       "      <td>category</td>\n",
       "      <td>projection</td>\n",
       "      <td>true</td>\n",
       "      <td>quadratic</td>\n",
       "      <td>coding</td>\n",
       "      <td>random</td>\n",
       "      <td>velocity</td>\n",
       "      <td>xi</td>\n",
       "      <td>bounded</td>\n",
       "      <td>motor</td>\n",
       "      <td>target</td>\n",
       "      <td>local</td>\n",
       "      <td>analog_vlsi</td>\n",
       "      <td>scene</td>\n",
       "      <td>eeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term19</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>nearest_neighbor</td>\n",
       "      <td>test_set</td>\n",
       "      <td>excitatory</td>\n",
       "      <td>position</td>\n",
       "      <td>position</td>\n",
       "      <td>inverse</td>\n",
       "      <td>stochastic</td>\n",
       "      <td>find</td>\n",
       "      <td>binary</td>\n",
       "      <td>student</td>\n",
       "      <td>position</td>\n",
       "      <td>log_likelihood</td>\n",
       "      <td>definition</td>\n",
       "      <td>stable</td>\n",
       "      <td>epoch</td>\n",
       "      <td>markov</td>\n",
       "      <td>hardware</td>\n",
       "      <td>vision</td>\n",
       "      <td>processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term20</th>\n",
       "      <td>segmentation</td>\n",
       "      <td>trained</td>\n",
       "      <td>bias</td>\n",
       "      <td>current</td>\n",
       "      <td>current</td>\n",
       "      <td>note</td>\n",
       "      <td>principal_component</td>\n",
       "      <td>statistic</td>\n",
       "      <td>local_minimum</td>\n",
       "      <td>computer</td>\n",
       "      <td>find</td>\n",
       "      <td>pattern</td>\n",
       "      <td>binary</td>\n",
       "      <td>assume</td>\n",
       "      <td>stability</td>\n",
       "      <td>step</td>\n",
       "      <td>recurrent</td>\n",
       "      <td>implemented</td>\n",
       "      <td>matching</td>\n",
       "      <td>subject</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Topic 1           Topic 2           Topic 3      Topic 4  \\\n",
       "Term1                 word    classification          training       neuron   \n",
       "Term2          recognition             class        prediction         cell   \n",
       "Term3             training        classifier              test        spike   \n",
       "Term4               speech           feature      training_set     synaptic   \n",
       "Term5              context           pattern        experiment     activity   \n",
       "Term6                  hmm          training         selection     response   \n",
       "Term7             sequence         character           trained       firing   \n",
       "Term8                state              face             table     stimulus   \n",
       "Term9              speaker              test        regression      pattern   \n",
       "Term10               frame      training_set           average     synapsis   \n",
       "Term11              letter       recognition             query       effect   \n",
       "Term12  speech_recognition             digit           measure    threshold   \n",
       "Term13             phoneme          distance  cross_validation       neural   \n",
       "Term14                 mlp          database         technique        et_al   \n",
       "Term15             feature            sample       time_series     neuronal   \n",
       "Term16          experiment        error_rate       application   inhibitory   \n",
       "Term17               vowel              rate            expert   simulation   \n",
       "Term18             trained              size               rbf  firing_rate   \n",
       "Term19              hybrid  nearest_neighbor          test_set   excitatory   \n",
       "Term20        segmentation           trained              bias      current   \n",
       "\n",
       "                       Topic 5         Topic 6              Topic 7  \\\n",
       "Term1                    state            rule               vector   \n",
       "Term2                  control  representation               matrix   \n",
       "Term3                   action            task               linear   \n",
       "Term4                   policy           human            nonlinear   \n",
       "Term5                     step       structure          dimensional   \n",
       "Term6               controller         feature              mapping   \n",
       "Term7              environment      similarity            dimension   \n",
       "Term8   reinforcement_learning          search       transformation   \n",
       "Term9                     task         subject            component   \n",
       "Term10                   robot        instance                local   \n",
       "Term11              trajectory         learned                  map   \n",
       "Term12                 optimal       knowledge             operator   \n",
       "Term13                    goal   connectionist             distance   \n",
       "Term14                  reward          domain                basis   \n",
       "Term15                  change            role                  pca   \n",
       "Term16                      td           level            structure   \n",
       "Term17                   agent          theory                 rule   \n",
       "Term18                   trial        category           projection   \n",
       "Term19                position        position              inverse   \n",
       "Term20                 current            note  principal_component   \n",
       "\n",
       "              Topic 8           Topic 9     Topic 10              Topic 11  \\\n",
       "Term1    distribution          solution       memory                 noise   \n",
       "Term2     probability       convergence          bit              equation   \n",
       "Term3        estimate          gradient      pattern                 curve   \n",
       "Term4           prior        constraint         code           correlation   \n",
       "Term5        gaussian          equation     capacity               average   \n",
       "Term6          sample              rate       neuron                    eq   \n",
       "Term7         density         iteration      element                  rate   \n",
       "Term8        bayesian      optimization    processor                theory   \n",
       "Term9      estimation            energy         size                 limit   \n",
       "Term10       variance           minimum       vector              solution   \n",
       "Term11            log            update     parallel  generalization_error   \n",
       "Term12  approximation           optimal     hopfield          distribution   \n",
       "Term13      estimator  gradient_descent  computation               optimal   \n",
       "Term14        entropy          constant       stored                  size   \n",
       "Term15      posterior        derivative   connection               teacher   \n",
       "Term16         kernel              cost    operation                  line   \n",
       "Term17          noise              step   neural_net                effect   \n",
       "Term18           true         quadratic       coding                random   \n",
       "Term19     stochastic              find       binary               student   \n",
       "Term20      statistic     local_minimum     computer                  find   \n",
       "\n",
       "               Topic 12        Topic 13       Topic 14     Topic 15  \\\n",
       "Term1            motion        variable          bound      dynamic   \n",
       "Term2            visual         mixture          class        state   \n",
       "Term3          response         cluster        theorem        phase   \n",
       "Term4          stimulus      clustering  approximation       module   \n",
       "Term5              cell            step          proof     behavior   \n",
       "Term6               map       component     polynomial    recurrent   \n",
       "Term7         direction              em           loss    attractor   \n",
       "Term8   receptive_field          expert         linear     feedback   \n",
       "Term9          activity          hidden     complexity   trajectory   \n",
       "Term10          spatial      likelihood             xi       neural   \n",
       "Term11      orientation       structure         theory      control   \n",
       "Term12              eye      mean_field      threshold        delay   \n",
       "Term13         location   approximation        defined     equation   \n",
       "Term14             unit     probability       constant  oscillation   \n",
       "Term15            field    em_algorithm           size  fixed_point   \n",
       "Term16           target         missing      condition   oscillator   \n",
       "Term17           center              mi     hypothesis   connection   \n",
       "Term18         velocity              xi        bounded        motor   \n",
       "Term19         position  log_likelihood     definition       stable   \n",
       "Term20          pattern          binary         assume    stability   \n",
       "\n",
       "                Topic 16   Topic 17        Topic 18        Topic 19  \\\n",
       "Term1               unit       node         circuit           image   \n",
       "Term2              layer   sequence            chip          object   \n",
       "Term3        hidden_unit       tree         current         feature   \n",
       "Term4                net      graph          analog           pixel   \n",
       "Term5           training  structure         voltage            view   \n",
       "Term6            pattern      state          neuron          region   \n",
       "Term7       architecture     symbol          design         surface   \n",
       "Term8         activation     string  implementation           shape   \n",
       "Term9            trained       path          device          visual   \n",
       "Term10      hidden_layer     length         synapse           scale   \n",
       "Term11  back_propagation      level         digital           local   \n",
       "Term12        connection    machine          neural         contour   \n",
       "Term13              task       link           pulse            part   \n",
       "Term14            hidden       step      transistor            edge   \n",
       "Term15             learn       edge           array  representation   \n",
       "Term16        simulation   language            gain        location   \n",
       "Term17   backpropagation    grammar            line        position   \n",
       "Term18            target      local     analog_vlsi           scene   \n",
       "Term19             epoch     markov        hardware          vision   \n",
       "Term20              step  recurrent     implemented        matching   \n",
       "\n",
       "          Topic 20  \n",
       "Term1       signal  \n",
       "Term2       filter  \n",
       "Term3    frequency  \n",
       "Term4       source  \n",
       "Term5      channel  \n",
       "Term6        noise  \n",
       "Term7     response  \n",
       "Term8    component  \n",
       "Term9     temporal  \n",
       "Term10       sound  \n",
       "Term11    auditory  \n",
       "Term12         ica  \n",
       "Term13   amplitude  \n",
       "Term14       phase  \n",
       "Term15  adaptation  \n",
       "Term16   detection  \n",
       "Term17      change  \n",
       "Term18         eeg  \n",
       "Term19  processing  \n",
       "Term20     subject  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_df = pd.DataFrame([[term for term, wt in topic] \n",
    "                              for topic in topics], \n",
    "                         columns = ['Term'+str(i) for i in range(1, 21)],\n",
    "                         index=['Topic '+str(t) for t in range(1, best_lda_model.num_topics+1)]).T\n",
    "topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Alvin/.local/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Terms per Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic1</th>\n",
       "      <td>word, recognition, training, speech, context, hmm, sequence, state, speaker, frame, letter, speech_recognition, phoneme, mlp, feature, experiment, vowel, trained, hybrid, segmentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic2</th>\n",
       "      <td>classification, class, classifier, feature, pattern, training, character, face, test, training_set, recognition, digit, distance, database, sample, error_rate, rate, size, nearest_neighbor, trained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic3</th>\n",
       "      <td>training, prediction, test, training_set, experiment, selection, trained, table, regression, average, query, measure, cross_validation, technique, time_series, application, expert, rbf, test_set, bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic4</th>\n",
       "      <td>neuron, cell, spike, synaptic, activity, response, firing, stimulus, pattern, synapsis, effect, threshold, neural, et_al, neuronal, inhibitory, simulation, firing_rate, excitatory, current</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic5</th>\n",
       "      <td>state, control, action, policy, step, controller, environment, reinforcement_learning, task, robot, trajectory, optimal, goal, reward, change, td, agent, trial, position, current</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic6</th>\n",
       "      <td>rule, representation, task, human, structure, feature, similarity, search, subject, instance, learned, knowledge, connectionist, domain, role, level, theory, category, position, note</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic7</th>\n",
       "      <td>vector, matrix, linear, nonlinear, dimensional, mapping, dimension, transformation, component, local, map, operator, distance, basis, pca, structure, rule, projection, inverse, principal_component</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic8</th>\n",
       "      <td>distribution, probability, estimate, prior, gaussian, sample, density, bayesian, estimation, variance, log, approximation, estimator, entropy, posterior, kernel, noise, true, stochastic, statistic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic9</th>\n",
       "      <td>solution, convergence, gradient, constraint, equation, rate, iteration, optimization, energy, minimum, update, optimal, gradient_descent, constant, derivative, cost, step, quadratic, find, local_minimum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic10</th>\n",
       "      <td>memory, bit, pattern, code, capacity, neuron, element, processor, size, vector, parallel, hopfield, computation, stored, connection, operation, neural_net, coding, binary, computer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic11</th>\n",
       "      <td>noise, equation, curve, correlation, average, eq, rate, theory, limit, solution, generalization_error, distribution, optimal, size, teacher, line, effect, random, student, find</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic12</th>\n",
       "      <td>motion, visual, response, stimulus, cell, map, direction, receptive_field, activity, spatial, orientation, eye, location, unit, field, target, center, velocity, position, pattern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic13</th>\n",
       "      <td>variable, mixture, cluster, clustering, step, component, em, expert, hidden, likelihood, structure, mean_field, approximation, probability, em_algorithm, missing, mi, xi, log_likelihood, binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic14</th>\n",
       "      <td>bound, class, theorem, approximation, proof, polynomial, loss, linear, complexity, xi, theory, threshold, defined, constant, size, condition, hypothesis, bounded, definition, assume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic15</th>\n",
       "      <td>dynamic, state, phase, module, behavior, recurrent, attractor, feedback, trajectory, neural, control, delay, equation, oscillation, fixed_point, oscillator, connection, motor, stable, stability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic16</th>\n",
       "      <td>unit, layer, hidden_unit, net, training, pattern, architecture, activation, trained, hidden_layer, back_propagation, connection, task, hidden, learn, simulation, backpropagation, target, epoch, step</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic17</th>\n",
       "      <td>node, sequence, tree, graph, structure, state, symbol, string, path, length, level, machine, link, step, edge, language, grammar, local, markov, recurrent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic18</th>\n",
       "      <td>circuit, chip, current, analog, voltage, neuron, design, implementation, device, synapse, digital, neural, pulse, transistor, array, gain, line, analog_vlsi, hardware, implemented</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic19</th>\n",
       "      <td>image, object, feature, pixel, view, region, surface, shape, visual, scale, local, contour, part, edge, representation, location, position, scene, vision, matching</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic20</th>\n",
       "      <td>signal, filter, frequency, source, channel, noise, response, component, temporal, sound, auditory, ica, amplitude, phase, adaptation, detection, change, eeg, processing, subject</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                    Terms per Topic\n",
       "Topic1   word, recognition, training, speech, context, hmm, sequence, state, speaker, frame, letter, speech_recognition, phoneme, mlp, feature, experiment, vowel, trained, hybrid, segmentation                   \n",
       "Topic2   classification, class, classifier, feature, pattern, training, character, face, test, training_set, recognition, digit, distance, database, sample, error_rate, rate, size, nearest_neighbor, trained     \n",
       "Topic3   training, prediction, test, training_set, experiment, selection, trained, table, regression, average, query, measure, cross_validation, technique, time_series, application, expert, rbf, test_set, bias  \n",
       "Topic4   neuron, cell, spike, synaptic, activity, response, firing, stimulus, pattern, synapsis, effect, threshold, neural, et_al, neuronal, inhibitory, simulation, firing_rate, excitatory, current              \n",
       "Topic5   state, control, action, policy, step, controller, environment, reinforcement_learning, task, robot, trajectory, optimal, goal, reward, change, td, agent, trial, position, current                        \n",
       "Topic6   rule, representation, task, human, structure, feature, similarity, search, subject, instance, learned, knowledge, connectionist, domain, role, level, theory, category, position, note                    \n",
       "Topic7   vector, matrix, linear, nonlinear, dimensional, mapping, dimension, transformation, component, local, map, operator, distance, basis, pca, structure, rule, projection, inverse, principal_component      \n",
       "Topic8   distribution, probability, estimate, prior, gaussian, sample, density, bayesian, estimation, variance, log, approximation, estimator, entropy, posterior, kernel, noise, true, stochastic, statistic      \n",
       "Topic9   solution, convergence, gradient, constraint, equation, rate, iteration, optimization, energy, minimum, update, optimal, gradient_descent, constant, derivative, cost, step, quadratic, find, local_minimum\n",
       "Topic10  memory, bit, pattern, code, capacity, neuron, element, processor, size, vector, parallel, hopfield, computation, stored, connection, operation, neural_net, coding, binary, computer                      \n",
       "Topic11  noise, equation, curve, correlation, average, eq, rate, theory, limit, solution, generalization_error, distribution, optimal, size, teacher, line, effect, random, student, find                          \n",
       "Topic12  motion, visual, response, stimulus, cell, map, direction, receptive_field, activity, spatial, orientation, eye, location, unit, field, target, center, velocity, position, pattern                        \n",
       "Topic13  variable, mixture, cluster, clustering, step, component, em, expert, hidden, likelihood, structure, mean_field, approximation, probability, em_algorithm, missing, mi, xi, log_likelihood, binary         \n",
       "Topic14  bound, class, theorem, approximation, proof, polynomial, loss, linear, complexity, xi, theory, threshold, defined, constant, size, condition, hypothesis, bounded, definition, assume                     \n",
       "Topic15  dynamic, state, phase, module, behavior, recurrent, attractor, feedback, trajectory, neural, control, delay, equation, oscillation, fixed_point, oscillator, connection, motor, stable, stability         \n",
       "Topic16  unit, layer, hidden_unit, net, training, pattern, architecture, activation, trained, hidden_layer, back_propagation, connection, task, hidden, learn, simulation, backpropagation, target, epoch, step    \n",
       "Topic17  node, sequence, tree, graph, structure, state, symbol, string, path, length, level, machine, link, step, edge, language, grammar, local, markov, recurrent                                                \n",
       "Topic18  circuit, chip, current, analog, voltage, neuron, design, implementation, device, synapse, digital, neural, pulse, transistor, array, gain, line, analog_vlsi, hardware, implemented                       \n",
       "Topic19  image, object, feature, pixel, view, region, surface, shape, visual, scale, local, contour, part, edge, representation, location, position, scene, vision, matching                                       \n",
       "Topic20  signal, filter, frequency, source, channel, noise, response, component, temporal, sound, auditory, ica, amplitude, phase, adaptation, detection, change, eeg, processing, subject                         "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "topics_df = pd.DataFrame([', '.join([term for term, wt in topic])  \n",
    "                              for topic in topics],\n",
    "                         columns = ['Terms per Topic'],\n",
    "                         index=['Topic'+str(t) for t in range(1, best_lda_model.num_topics+1)]\n",
    "                         )\n",
    "topics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting Topic Model Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_results = best_lda_model[bow_corpus]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8, 0.2286752707313455),\n",
       " (9, 0.219922860109776),\n",
       " (16, 0.20199731453507883),\n",
       " (11, 0.22351903724452743),\n",
       " (15, 0.448782535684299)]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_topics = [sorted(topics, key=lambda record: -record[1])[0] \n",
    "                     for topics in tm_results]\n",
    "corpus_topics[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_topic_df = pd.DataFrame()\n",
    "corpus_topic_df['Document'] = range(0, len(papers))\n",
    "corpus_topic_df['Dominant Topic'] = [item[0]+1 for item in corpus_topics]\n",
    "corpus_topic_df['Contribution %'] = [round(item[1]*100, 2) for item in corpus_topics]\n",
    "corpus_topic_df['Topic Desc'] = [topics_df.iloc[t[0]]['Terms per Topic'] for t in corpus_topics]\n",
    "corpus_topic_df['Paper'] = papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dominant topics distribution across corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_colwidth', 200)\n",
    "# topic_stats_df = corpus_topic_df.groupby('Dominant Topic').agg({\n",
    "#                                                 'Dominant Topic': {\n",
    "#                                                     'Doc Count': np.size,\n",
    "#                                                     '% Total Docs': np.size }\n",
    "#                                               })\n",
    "# topic_stats_df = topic_stats_df['Dominant Topic'].reset_index()\n",
    "# topic_stats_df['% Total Docs'] = topic_stats_df['% Total Docs'].apply(lambda row: round((row*100) / len(papers), 2))\n",
    "# topic_stats_df['Topic Desc'] = [topics_df.iloc[t]['Terms per Topic'] for t in range(len(topic_stats_df))]\n",
    "# topic_stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dominant topics in specific papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Dominant Topic</th>\n",
       "      <th>Contribution %</th>\n",
       "      <th>Topic Desc</th>\n",
       "      <th>Paper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>27.44</td>\n",
       "      <td>neuron, cell, spike, synaptic, activity, response, firing, stimulus, pattern, synapsis, effect, threshold, neural, et_al, neuronal, inhibitory, simulation, firing_rate, excitatory, current</td>\n",
       "      <td>367 \\nSCHEMA FOR MOTOR CONTROL \\nUTILIZING A NETWORK MODEL OF THE CEREBELLUM \\nJames C. Houk, Ph.D. \\nNorthwestern University Medical School, Chicago, Illinois \\n60201 \\nABSTRACT \\nThis paper outl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>67.04</td>\n",
       "      <td>circuit, chip, current, analog, voltage, neuron, design, implementation, device, synapse, digital, neural, pulse, transistor, array, gain, line, analog_vlsi, hardware, implemented</td>\n",
       "      <td>564 \\nPROGRAMMABLE SYNAPTIC CHIP FOR \\nELECTRONIC NEURAL NETWORKS \\nA. Moopenn, H. Langenbacher, A.P. Thakoor, and S.K. Khanna \\nJet Propulsion Laboratory \\nCalifornia Institute of Technology \\nPa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>18.68</td>\n",
       "      <td>unit, layer, hidden_unit, net, training, pattern, architecture, activation, trained, hidden_layer, back_propagation, connection, task, hidden, learn, simulation, backpropagation, target, epoch, step</td>\n",
       "      <td>348 \\nMinkowski-r Back-Propagation: Learning in Connectionist \\nModels with Non-Euclidian Error Signals \\nStephen Jos6 Hanson and David J. Burr \\nBell Communications Research \\nMorristown, New Jer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>392</td>\n",
       "      <td>5</td>\n",
       "      <td>40.82</td>\n",
       "      <td>state, control, action, policy, step, controller, environment, reinforcement_learning, task, robot, trajectory, optimal, goal, reward, change, td, agent, trial, position, current</td>\n",
       "      <td>Learning Trajectory and Force Control \\nof an Artificial Muscle Arm \\nby Parallel-hierarchical Neural Network Model \\nMasazumi Katayama Mitsuo Kawato \\nCognitive Processes Department \\nATR Auditor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>503</td>\n",
       "      <td>14</td>\n",
       "      <td>77.50</td>\n",
       "      <td>bound, class, theorem, approximation, proof, polynomial, loss, linear, complexity, xi, theory, threshold, defined, constant, size, condition, hypothesis, bounded, definition, assume</td>\n",
       "      <td>Polynomial Uniform Convergence of \\nRelative Frequencies to Probabilities \\nAlberto Bertoni, Paola Campadelll;' Anna Morpurgo, Sandra Panlzza \\nDipartimento di Scienze dell'Informazione \\nUniversi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>681</td>\n",
       "      <td>18</td>\n",
       "      <td>40.43</td>\n",
       "      <td>circuit, chip, current, analog, voltage, neuron, design, implementation, device, synapse, digital, neural, pulse, transistor, array, gain, line, analog_vlsi, hardware, implemented</td>\n",
       "      <td>Visual Motion Computation in Analog \\nVLSI using Pulses \\nRahul Sarpeshkar, Wyeth Bair and Christof Koch \\nComputation and Neural Systems Program \\nCalifornia Institute of Technology \\nPasadena, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>733</td>\n",
       "      <td>4</td>\n",
       "      <td>28.12</td>\n",
       "      <td>neuron, cell, spike, synaptic, activity, response, firing, stimulus, pattern, synapsis, effect, threshold, neural, et_al, neuronal, inhibitory, simulation, firing_rate, excitatory, current</td>\n",
       "      <td>Foraging in an Uncertain Environment Using \\nPredictive Hebbian Learning \\nP. Read Montague ; Peter Dayan, and Terrence J. Sejnowski \\nComputational Neurobiology Lab, The Salk Institute, \\n10010 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>906</td>\n",
       "      <td>19</td>\n",
       "      <td>35.45</td>\n",
       "      <td>image, object, feature, pixel, view, region, surface, shape, visual, scale, local, contour, part, edge, representation, location, position, scene, vision, matching</td>\n",
       "      <td>Correlation and Interpolation Networks for \\nReal-time Expression Analysis/Synthesis. \\nTrevor Darrell, Irfan Essa, Alex Pentland \\nPerceptual Computing Group \\nMIT Media Lab \\nAbstract \\nWe descr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>15</td>\n",
       "      <td>38.69</td>\n",
       "      <td>dynamic, state, phase, module, behavior, recurrent, attractor, feedback, trajectory, neural, control, delay, equation, oscillation, fixed_point, oscillator, connection, motor, stable, stability</td>\n",
       "      <td>Dynamics of Attention as Near \\nSaddle-Node Bifurcation Behavior \\nHiroyuki Nakahara* \\nGeneral Systems Studies \\nUniversity of Tokyo \\n3-8-1 Komaba, Meguro \\nTokyo 153, Japan \\nn akahar a@vermeer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>1622</td>\n",
       "      <td>8</td>\n",
       "      <td>37.00</td>\n",
       "      <td>distribution, probability, estimate, prior, gaussian, sample, density, bayesian, estimation, variance, log, approximation, estimator, entropy, posterior, kernel, noise, true, stochastic, statistic</td>\n",
       "      <td>Probabilistic methods for Support Vector \\nMachines \\nPeter Sollich \\nDepartment of Mathematics, King's College London \\nStrand, London WC2R 2LS, U.K. Email: peter.sollich@kcl.ac.uk \\nAbstract \\nI...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Document  Dominant Topic  Contribution %  \\\n",
       "9            9               4           27.44   \n",
       "13          13              18           67.04   \n",
       "17          17              16           18.68   \n",
       "392        392               5           40.82   \n",
       "503        503              14           77.50   \n",
       "681        681              18           40.43   \n",
       "733        733               4           28.12   \n",
       "906        906              19           35.45   \n",
       "996        996              15           38.69   \n",
       "1622      1622               8           37.00   \n",
       "\n",
       "                                                                                                                                                                                                  Topic Desc  \\\n",
       "9               neuron, cell, spike, synaptic, activity, response, firing, stimulus, pattern, synapsis, effect, threshold, neural, et_al, neuronal, inhibitory, simulation, firing_rate, excitatory, current   \n",
       "13                       circuit, chip, current, analog, voltage, neuron, design, implementation, device, synapse, digital, neural, pulse, transistor, array, gain, line, analog_vlsi, hardware, implemented   \n",
       "17    unit, layer, hidden_unit, net, training, pattern, architecture, activation, trained, hidden_layer, back_propagation, connection, task, hidden, learn, simulation, backpropagation, target, epoch, step   \n",
       "392                       state, control, action, policy, step, controller, environment, reinforcement_learning, task, robot, trajectory, optimal, goal, reward, change, td, agent, trial, position, current   \n",
       "503                    bound, class, theorem, approximation, proof, polynomial, loss, linear, complexity, xi, theory, threshold, defined, constant, size, condition, hypothesis, bounded, definition, assume   \n",
       "681                      circuit, chip, current, analog, voltage, neuron, design, implementation, device, synapse, digital, neural, pulse, transistor, array, gain, line, analog_vlsi, hardware, implemented   \n",
       "733             neuron, cell, spike, synaptic, activity, response, firing, stimulus, pattern, synapsis, effect, threshold, neural, et_al, neuronal, inhibitory, simulation, firing_rate, excitatory, current   \n",
       "906                                      image, object, feature, pixel, view, region, surface, shape, visual, scale, local, contour, part, edge, representation, location, position, scene, vision, matching   \n",
       "996        dynamic, state, phase, module, behavior, recurrent, attractor, feedback, trajectory, neural, control, delay, equation, oscillation, fixed_point, oscillator, connection, motor, stable, stability   \n",
       "1622    distribution, probability, estimate, prior, gaussian, sample, density, bayesian, estimation, variance, log, approximation, estimator, entropy, posterior, kernel, noise, true, stochastic, statistic   \n",
       "\n",
       "                                                                                                                                                                                                        Paper  \n",
       "9     367 \\nSCHEMA FOR MOTOR CONTROL \\nUTILIZING A NETWORK MODEL OF THE CEREBELLUM \\nJames C. Houk, Ph.D. \\nNorthwestern University Medical School, Chicago, Illinois \\n60201 \\nABSTRACT \\nThis paper outl...  \n",
       "13    564 \\nPROGRAMMABLE SYNAPTIC CHIP FOR \\nELECTRONIC NEURAL NETWORKS \\nA. Moopenn, H. Langenbacher, A.P. Thakoor, and S.K. Khanna \\nJet Propulsion Laboratory \\nCalifornia Institute of Technology \\nPa...  \n",
       "17    348 \\nMinkowski-r Back-Propagation: Learning in Connectionist \\nModels with Non-Euclidian Error Signals \\nStephen Jos6 Hanson and David J. Burr \\nBell Communications Research \\nMorristown, New Jer...  \n",
       "392   Learning Trajectory and Force Control \\nof an Artificial Muscle Arm \\nby Parallel-hierarchical Neural Network Model \\nMasazumi Katayama Mitsuo Kawato \\nCognitive Processes Department \\nATR Auditor...  \n",
       "503   Polynomial Uniform Convergence of \\nRelative Frequencies to Probabilities \\nAlberto Bertoni, Paola Campadelll;' Anna Morpurgo, Sandra Panlzza \\nDipartimento di Scienze dell'Informazione \\nUniversi...  \n",
       "681   Visual Motion Computation in Analog \\nVLSI using Pulses \\nRahul Sarpeshkar, Wyeth Bair and Christof Koch \\nComputation and Neural Systems Program \\nCalifornia Institute of Technology \\nPasadena, C...  \n",
       "733   Foraging in an Uncertain Environment Using \\nPredictive Hebbian Learning \\nP. Read Montague ; Peter Dayan, and Terrence J. Sejnowski \\nComputational Neurobiology Lab, The Salk Institute, \\n10010 ...  \n",
       "906   Correlation and Interpolation Networks for \\nReal-time Expression Analysis/Synthesis. \\nTrevor Darrell, Irfan Essa, Alex Pentland \\nPerceptual Computing Group \\nMIT Media Lab \\nAbstract \\nWe descr...  \n",
       "996   Dynamics of Attention as Near \\nSaddle-Node Bifurcation Behavior \\nHiroyuki Nakahara* \\nGeneral Systems Studies \\nUniversity of Tokyo \\n3-8-1 Komaba, Meguro \\nTokyo 153, Japan \\nn akahar a@vermeer...  \n",
       "1622  Probabilistic methods for Support Vector \\nMachines \\nPeter Sollich \\nDepartment of Mathematics, King's College London \\nStrand, London WC2R 2LS, U.K. Email: peter.sollich@kcl.ac.uk \\nAbstract \\nI...  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 200)\n",
    "(corpus_topic_df[corpus_topic_df['Document']\n",
    "                 .isin([681, 9, 392, 1622, 17, \n",
    "                        906, 996, 503, 13, 733])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relevant papers per topic based on dominance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Dominant Topic</th>\n",
       "      <th>Contribution %</th>\n",
       "      <th>Topic Desc</th>\n",
       "      <th>Paper</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dominant Topic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1135</th>\n",
       "      <td>1135</td>\n",
       "      <td>1</td>\n",
       "      <td>71.51</td>\n",
       "      <td>word, recognition, training, speech, context, hmm, sequence, state, speaker, frame, letter, speech_recognition, phoneme, mlp, feature, experiment, vowel, trained, hybrid, segmentation</td>\n",
       "      <td>Context-Dependent Classes in a Hybrid \\nRecurrent Network-HMM Speech \\nRecognition System \\nDan Kershaw Tony Robinson Mike Hochberg \\nCambridge University Engineering Department, \\nTrumpington Str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>635</td>\n",
       "      <td>1</td>\n",
       "      <td>71.48</td>\n",
       "      <td>word, recognition, training, speech, context, hmm, sequence, state, speaker, frame, letter, speech_recognition, phoneme, mlp, feature, experiment, vowel, trained, hybrid, segmentation</td>\n",
       "      <td>Connected Letter Recognition with a \\nMulti-State Time Delay Neural Network \\nHermann Hild and Alex Waibel \\nSchool of Computer Science \\nCarnegie Mellon University \\nPittsburgh, PA 15213-3891, US...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>532</td>\n",
       "      <td>1</td>\n",
       "      <td>68.61</td>\n",
       "      <td>word, recognition, training, speech, context, hmm, sequence, state, speaker, frame, letter, speech_recognition, phoneme, mlp, feature, experiment, vowel, trained, hybrid, segmentation</td>\n",
       "      <td>Multi-State Time Delay Neural Networks \\nfor Continuous Speech Recognition \\nPatrick Haffner \\nCNET Lannion A TSS/RCP \\n22301 LANNION, FRANCE \\nhaffnerlannion.cnet. fr \\nAlex Waibel \\nCarnegie Me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>612</td>\n",
       "      <td>1</td>\n",
       "      <td>66.65</td>\n",
       "      <td>word, recognition, training, speech, context, hmm, sequence, state, speaker, frame, letter, speech_recognition, phoneme, mlp, feature, experiment, vowel, trained, hybrid, segmentation</td>\n",
       "      <td>Context-Dependent Multiple \\nDistribution Phonetic Modeling with \\nMLPs \\nMichael Cohen \\nSKI International \\nMenlo Prk, CA 94025 \\nHoracio Franco \\nSKI International \\nNelson Morgan \\nIntl. Comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>651</td>\n",
       "      <td>1</td>\n",
       "      <td>64.78</td>\n",
       "      <td>word, recognition, training, speech, context, hmm, sequence, state, speaker, frame, letter, speech_recognition, phoneme, mlp, feature, experiment, vowel, trained, hybrid, segmentation</td>\n",
       "      <td>Modeling Consistency in a Speaker Independent \\nContinuous Speech Recognition System \\nYochai Konig, Nelson Morgan, Chuck Wooters \\nInternational Computer Science Institute \\n1947 Center Street, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">20</th>\n",
       "      <th>1284</th>\n",
       "      <td>1284</td>\n",
       "      <td>20</td>\n",
       "      <td>18.90</td>\n",
       "      <td>signal, filter, frequency, source, channel, noise, response, component, temporal, sound, auditory, ica, amplitude, phase, adaptation, detection, change, eeg, processing, subject</td>\n",
       "      <td>Viewpoint invariant face recognition using \\nindependent component analysis and \\nattractor networks \\nMarian Stewart Bartlett \\nUniversity of California San Diego \\nThe Salk Institute \\nLa Jolla,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>312</td>\n",
       "      <td>20</td>\n",
       "      <td>16.67</td>\n",
       "      <td>signal, filter, frequency, source, channel, noise, response, component, temporal, sound, auditory, ica, amplitude, phase, adaptation, detection, change, eeg, processing, subject</td>\n",
       "      <td>A Theory for Neural Networks with Time Delays \\nBert de Vries \\nDepartment of Electrical Engineering \\nUniversity of Florida, CSE 447 \\nGainesville, FL 32611 \\nJose C. Principe \\nDepartment of Ele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>567</td>\n",
       "      <td>20</td>\n",
       "      <td>16.53</td>\n",
       "      <td>signal, filter, frequency, source, channel, noise, response, component, temporal, sound, auditory, ica, amplitude, phase, adaptation, detection, change, eeg, processing, subject</td>\n",
       "      <td>Modeling Applications with the Focused Gamma Net \\nJose C. Principe, Bert de Vries, Jyh-Ming Kuo and Pedro Guedes de Oliveira* \\nDepartment of Electrical Engineering \\nUniversity of Florida, CSE 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>158</td>\n",
       "      <td>20</td>\n",
       "      <td>14.95</td>\n",
       "      <td>signal, filter, frequency, source, channel, noise, response, component, temporal, sound, auditory, ica, amplitude, phase, adaptation, detection, change, eeg, processing, subject</td>\n",
       "      <td>436 \\nSIMULATION AND MEASUREMENT OF \\nTHE ELECTRIC FIELDS GENERATED \\nBY WEAKLY ELECTRIC FISH \\nBrian Rasnow 1, Christopher Assad 2, Mark E. Nelson 3 and James M. Bower 3 \\nDivisions of Physics 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>257</td>\n",
       "      <td>20</td>\n",
       "      <td>13.29</td>\n",
       "      <td>signal, filter, frequency, source, channel, noise, response, component, temporal, sound, auditory, ica, amplitude, phase, adaptation, detection, change, eeg, processing, subject</td>\n",
       "      <td>542 Kassebaum, Tenorio and Schaefers \\nThe Cocktail Party Problem: \\nSpeech/Data Signal Separation Comparison \\nbetween Backpropagation and SONN \\nJohn Kassebaum \\njakec.ecn.purdue.edu \\nManoel F...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1740 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Document  Dominant Topic  Contribution %  \\\n",
       "Dominant Topic                                                  \n",
       "1              1135      1135               1           71.51   \n",
       "               635        635               1           71.48   \n",
       "               532        532               1           68.61   \n",
       "               612        612               1           66.65   \n",
       "               651        651               1           64.78   \n",
       "...                       ...             ...             ...   \n",
       "20             1284      1284              20           18.90   \n",
       "               312        312              20           16.67   \n",
       "               567        567              20           16.53   \n",
       "               158        158              20           14.95   \n",
       "               257        257              20           13.29   \n",
       "\n",
       "                                                                                                                                                                                                  Topic Desc  \\\n",
       "Dominant Topic                                                                                                                                                                                                 \n",
       "1              1135  word, recognition, training, speech, context, hmm, sequence, state, speaker, frame, letter, speech_recognition, phoneme, mlp, feature, experiment, vowel, trained, hybrid, segmentation   \n",
       "               635   word, recognition, training, speech, context, hmm, sequence, state, speaker, frame, letter, speech_recognition, phoneme, mlp, feature, experiment, vowel, trained, hybrid, segmentation   \n",
       "               532   word, recognition, training, speech, context, hmm, sequence, state, speaker, frame, letter, speech_recognition, phoneme, mlp, feature, experiment, vowel, trained, hybrid, segmentation   \n",
       "               612   word, recognition, training, speech, context, hmm, sequence, state, speaker, frame, letter, speech_recognition, phoneme, mlp, feature, experiment, vowel, trained, hybrid, segmentation   \n",
       "               651   word, recognition, training, speech, context, hmm, sequence, state, speaker, frame, letter, speech_recognition, phoneme, mlp, feature, experiment, vowel, trained, hybrid, segmentation   \n",
       "...                                                                                                                                                                                                      ...   \n",
       "20             1284        signal, filter, frequency, source, channel, noise, response, component, temporal, sound, auditory, ica, amplitude, phase, adaptation, detection, change, eeg, processing, subject   \n",
       "               312         signal, filter, frequency, source, channel, noise, response, component, temporal, sound, auditory, ica, amplitude, phase, adaptation, detection, change, eeg, processing, subject   \n",
       "               567         signal, filter, frequency, source, channel, noise, response, component, temporal, sound, auditory, ica, amplitude, phase, adaptation, detection, change, eeg, processing, subject   \n",
       "               158         signal, filter, frequency, source, channel, noise, response, component, temporal, sound, auditory, ica, amplitude, phase, adaptation, detection, change, eeg, processing, subject   \n",
       "               257         signal, filter, frequency, source, channel, noise, response, component, temporal, sound, auditory, ica, amplitude, phase, adaptation, detection, change, eeg, processing, subject   \n",
       "\n",
       "                                                                                                                                                                                                                       Paper  \n",
       "Dominant Topic                                                                                                                                                                                                                \n",
       "1              1135  Context-Dependent Classes in a Hybrid \\nRecurrent Network-HMM Speech \\nRecognition System \\nDan Kershaw Tony Robinson Mike Hochberg \\nCambridge University Engineering Department, \\nTrumpington Str...  \n",
       "               635   Connected Letter Recognition with a \\nMulti-State Time Delay Neural Network \\nHermann Hild and Alex Waibel \\nSchool of Computer Science \\nCarnegie Mellon University \\nPittsburgh, PA 15213-3891, US...  \n",
       "               532   Multi-State Time Delay Neural Networks \\nfor Continuous Speech Recognition \\nPatrick Haffner \\nCNET Lannion A TSS/RCP \\n22301 LANNION, FRANCE \\nhaffnerlannion.cnet. fr \\nAlex Waibel \\nCarnegie Me...  \n",
       "               612   Context-Dependent Multiple \\nDistribution Phonetic Modeling with \\nMLPs \\nMichael Cohen \\nSKI International \\nMenlo Prk, CA 94025 \\nHoracio Franco \\nSKI International \\nNelson Morgan \\nIntl. Comp...  \n",
       "               651   Modeling Consistency in a Speaker Independent \\nContinuous Speech Recognition System \\nYochai Konig, Nelson Morgan, Chuck Wooters \\nInternational Computer Science Institute \\n1947 Center Street, S...  \n",
       "...                                                                                                                                                                                                                      ...  \n",
       "20             1284  Viewpoint invariant face recognition using \\nindependent component analysis and \\nattractor networks \\nMarian Stewart Bartlett \\nUniversity of California San Diego \\nThe Salk Institute \\nLa Jolla,...  \n",
       "               312   A Theory for Neural Networks with Time Delays \\nBert de Vries \\nDepartment of Electrical Engineering \\nUniversity of Florida, CSE 447 \\nGainesville, FL 32611 \\nJose C. Principe \\nDepartment of Ele...  \n",
       "               567   Modeling Applications with the Focused Gamma Net \\nJose C. Principe, Bert de Vries, Jyh-Ming Kuo and Pedro Guedes de Oliveira* \\nDepartment of Electrical Engineering \\nUniversity of Florida, CSE 4...  \n",
       "               158   436 \\nSIMULATION AND MEASUREMENT OF \\nTHE ELECTRIC FIELDS GENERATED \\nBY WEAKLY ELECTRIC FISH \\nBrian Rasnow 1, Christopher Assad 2, Mark E. Nelson 3 and James M. Bower 3 \\nDivisions of Physics 1,...  \n",
       "               257   542 Kassebaum, Tenorio and Schaefers \\nThe Cocktail Party Problem: \\nSpeech/Data Signal Separation Comparison \\nbetween Backpropagation and SONN \\nJohn Kassebaum \\njakec.ecn.purdue.edu \\nManoel F...  \n",
       "\n",
       "[1740 rows x 5 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_topic_df.groupby('Dominant Topic').apply(lambda \n",
    "                                                topic_set: (topic_set.sort_values(by=['Contribution %'], \n",
    "                                                                                         ascending=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Topics for New Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total New Papers: 4\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "# papers manually downloaded from NIPS 16\n",
    "# https://papers.nips.cc/book/advances-in-neural-information-processing-systems-29-2016\n",
    "\n",
    "new_paper_files = glob.glob('test_data/nips16*.txt')\n",
    "new_papers = []\n",
    "for fn in new_paper_files:\n",
    "    with open(fn, encoding='utf-8', errors='ignore', mode='r+') as f:\n",
    "        data = f.read()\n",
    "        new_papers.append(data)\n",
    "              \n",
    "print('Total New Papers:', len(new_papers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing_pipeline(documents, normalizer_fn, bigram_model):\n",
    "    norm_docs = normalizer_fn(documents)\n",
    "    norm_docs_bigrams = bigram_model[norm_docs]\n",
    "    return norm_docs_bigrams\n",
    "\n",
    "def bow_features_pipeline(tokenized_docs, dictionary):\n",
    "    paper_bow_features = [dictionary.doc2bow(text) \n",
    "                              for text in tokenized_docs]\n",
    "    return paper_bow_features\n",
    "\n",
    "norm_new_papers = text_preprocessing_pipeline(documents=new_papers, normalizer_fn=normalize_corpus, \n",
    "                                              bigram_model=bigram_model)\n",
    "norm_bow_features = bow_features_pipeline(tokenized_docs=norm_new_papers, dictionary=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cooperative', 'graphical_model', 'josip', 'djolonga', 'dept_computer', 'science', 'eth', 'zurich', 'josipd', 'inf', 'ethz', 'ch', 'stefanie', 'jegelka', 'csail', 'mit', 'stefje', 'mit_edu', 'sebastian', 'tschiatschek', 'dept_computer', 'science', 'eth', 'zurich', 'stschia', 'inf', 'ethz', 'ch', 'andreas', 'krause']\n"
     ]
    }
   ],
   "source": [
    "print(norm_new_papers[0][:30])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (5, 1), (11, 1), (13, 1), (14, 1), (30, 1), (31, 2), (33, 4), (34, 1), (41, 3), (43, 1), (50, 1), (51, 1), (53, 1), (56, 1), (57, 2), (58, 1), (59, 6), (62, 1), (73, 7), (76, 1), (77, 4), (79, 2), (80, 1), (81, 2), (82, 2), (84, 3), (89, 5), (92, 1)]\n"
     ]
    }
   ],
   "source": [
    "print(norm_bow_features[0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_predictions(topic_model, corpus, topn=3):\n",
    "    topic_predictions = topic_model[corpus]\n",
    "    best_topics = [[(topic, round(wt, 3)) \n",
    "                        for topic, wt in sorted(topic_predictions[i], \n",
    "                                                key=lambda row: -row[1])[:topn]] \n",
    "                            for i in range(len(topic_predictions))]\n",
    "    return best_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(13, 0.212), (12, 0.207)],\n",
       " [(4, 0.393), (13, 0.219)],\n",
       " [(18, 0.263), (3, 0.136)],\n",
       " [(0, 0.265), (5, 0.177)]]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_preds = get_topic_predictions(topic_model=best_lda_model, \n",
    "                                    corpus=norm_bow_features, topn=2)\n",
    "topic_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame()\n",
    "results_df['Papers'] = range(1, len(new_papers)+1)\n",
    "results_df['Dominant Topics'] = [[topic_num+1 for topic_num, wt in item] for item in topic_preds]\n",
    "res = results_df.set_index(['Papers'])['Dominant Topics'].apply(pd.Series).stack().reset_index(level=1, drop=True)\n",
    "results_df = pd.DataFrame({'Dominant Topics': res.values}, index=res.index)\n",
    "results_df['Contribution %'] = [topic_wt for topic_list in \n",
    "                                        [[round(wt*100, 2) \n",
    "                                              for topic_num, wt in item] \n",
    "                                                 for item in topic_preds] \n",
    "                                    for topic_wt in topic_list]\n",
    "\n",
    "results_df['Topic Desc'] = [topics_df.iloc[t-1]['Terms per Topic'] for t in results_df['Dominant Topics'].values]\n",
    "results_df['Paper Desc'] = [new_papers[i-1][:200] for i in results_df.index.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant Topics</th>\n",
       "      <th>Contribution %</th>\n",
       "      <th>Topic Desc</th>\n",
       "      <th>Paper Desc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Papers</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>21.2</td>\n",
       "      <td>bound, class, theorem, approximation, proof, polynomial, loss, linear, complexity, xi, theory, threshold, defined, constant, size, condition, hypothesis, bounded, definition, assume</td>\n",
       "      <td>Cooperative Graphical Models\\nJosip Djolonga\\nDept. of Computer Science, ETH Zurich ¨\\njosipd@inf.ethz.ch\\nStefanie Jegelka\\nCSAIL, MIT\\nstefje@mit.edu\\nSebastian Tschiatschek\\nDept. of Computer Science, ETH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>20.7</td>\n",
       "      <td>variable, mixture, cluster, clustering, step, component, em, expert, hidden, likelihood, structure, mean_field, approximation, probability, em_algorithm, missing, mi, xi, log_likelihood, binary</td>\n",
       "      <td>Cooperative Graphical Models\\nJosip Djolonga\\nDept. of Computer Science, ETH Zurich ¨\\njosipd@inf.ethz.ch\\nStefanie Jegelka\\nCSAIL, MIT\\nstefje@mit.edu\\nSebastian Tschiatschek\\nDept. of Computer Science, ETH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>state, control, action, policy, step, controller, environment, reinforcement_learning, task, robot, trajectory, optimal, goal, reward, change, td, agent, trial, position, current</td>\n",
       "      <td>PAC Reinforcement Learning with Rich Observations\\nAkshay Krishnamurthy\\nUniversity of Massachusetts, Amherst\\nAmherst, MA, 01003\\nakshay@cs.umass.edu\\nAlekh Agarwal\\nMicrosoft Research\\nNew York, NY 10011\\na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>21.9</td>\n",
       "      <td>bound, class, theorem, approximation, proof, polynomial, loss, linear, complexity, xi, theory, threshold, defined, constant, size, condition, hypothesis, bounded, definition, assume</td>\n",
       "      <td>PAC Reinforcement Learning with Rich Observations\\nAkshay Krishnamurthy\\nUniversity of Massachusetts, Amherst\\nAmherst, MA, 01003\\nakshay@cs.umass.edu\\nAlekh Agarwal\\nMicrosoft Research\\nNew York, NY 10011\\na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>26.3</td>\n",
       "      <td>image, object, feature, pixel, view, region, surface, shape, visual, scale, local, contour, part, edge, representation, location, position, scene, vision, matching</td>\n",
       "      <td>Automated scalable segmentation of neurons from\\nmultispectral images\\nUygar Sümbül\\nGrossman Center for the Statistics of Mind\\nand Dept. of Statistics, Columbia University\\nDouglas Roossien Jr.\\nUniversit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>13.6</td>\n",
       "      <td>neuron, cell, spike, synaptic, activity, response, firing, stimulus, pattern, synapsis, effect, threshold, neural, et_al, neuronal, inhibitory, simulation, firing_rate, excitatory, current</td>\n",
       "      <td>Automated scalable segmentation of neurons from\\nmultispectral images\\nUygar Sümbül\\nGrossman Center for the Statistics of Mind\\nand Dept. of Statistics, Columbia University\\nDouglas Roossien Jr.\\nUniversit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>word, recognition, training, speech, context, hmm, sequence, state, speaker, frame, letter, speech_recognition, phoneme, mlp, feature, experiment, vowel, trained, hybrid, segmentation</td>\n",
       "      <td>Unsupervised Learning of Spoken Language with\\nVisual Context\\nDavid Harwath, Antonio Torralba, and James R. Glass\\nComputer Science and Artificial Intelligence Laboratory\\nMassachusetts Institute of Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>17.7</td>\n",
       "      <td>rule, representation, task, human, structure, feature, similarity, search, subject, instance, learned, knowledge, connectionist, domain, role, level, theory, category, position, note</td>\n",
       "      <td>Unsupervised Learning of Spoken Language with\\nVisual Context\\nDavid Harwath, Antonio Torralba, and James R. Glass\\nComputer Science and Artificial Intelligence Laboratory\\nMassachusetts Institute of Tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dominant Topics  Contribution %  \\\n",
       "Papers                                    \n",
       "1                    14            21.2   \n",
       "1                    13            20.7   \n",
       "2                     5            39.3   \n",
       "2                    14            21.9   \n",
       "3                    19            26.3   \n",
       "3                     4            13.6   \n",
       "4                     1            26.5   \n",
       "4                     6            17.7   \n",
       "\n",
       "                                                                                                                                                                                               Topic Desc  \\\n",
       "Papers                                                                                                                                                                                                      \n",
       "1                   bound, class, theorem, approximation, proof, polynomial, loss, linear, complexity, xi, theory, threshold, defined, constant, size, condition, hypothesis, bounded, definition, assume   \n",
       "1       variable, mixture, cluster, clustering, step, component, em, expert, hidden, likelihood, structure, mean_field, approximation, probability, em_algorithm, missing, mi, xi, log_likelihood, binary   \n",
       "2                      state, control, action, policy, step, controller, environment, reinforcement_learning, task, robot, trajectory, optimal, goal, reward, change, td, agent, trial, position, current   \n",
       "2                   bound, class, theorem, approximation, proof, polynomial, loss, linear, complexity, xi, theory, threshold, defined, constant, size, condition, hypothesis, bounded, definition, assume   \n",
       "3                                     image, object, feature, pixel, view, region, surface, shape, visual, scale, local, contour, part, edge, representation, location, position, scene, vision, matching   \n",
       "3            neuron, cell, spike, synaptic, activity, response, firing, stimulus, pattern, synapsis, effect, threshold, neural, et_al, neuronal, inhibitory, simulation, firing_rate, excitatory, current   \n",
       "4                 word, recognition, training, speech, context, hmm, sequence, state, speaker, frame, letter, speech_recognition, phoneme, mlp, feature, experiment, vowel, trained, hybrid, segmentation   \n",
       "4                  rule, representation, task, human, structure, feature, similarity, search, subject, instance, learned, knowledge, connectionist, domain, role, level, theory, category, position, note   \n",
       "\n",
       "                                                                                                                                                                                                              Paper Desc  \n",
       "Papers                                                                                                                                                                                                                    \n",
       "1       Cooperative Graphical Models\\nJosip Djolonga\\nDept. of Computer Science, ETH Zurich ¨\\njosipd@inf.ethz.ch\\nStefanie Jegelka\\nCSAIL, MIT\\nstefje@mit.edu\\nSebastian Tschiatschek\\nDept. of Computer Science, ETH   \n",
       "1       Cooperative Graphical Models\\nJosip Djolonga\\nDept. of Computer Science, ETH Zurich ¨\\njosipd@inf.ethz.ch\\nStefanie Jegelka\\nCSAIL, MIT\\nstefje@mit.edu\\nSebastian Tschiatschek\\nDept. of Computer Science, ETH   \n",
       "2       PAC Reinforcement Learning with Rich Observations\\nAkshay Krishnamurthy\\nUniversity of Massachusetts, Amherst\\nAmherst, MA, 01003\\nakshay@cs.umass.edu\\nAlekh Agarwal\\nMicrosoft Research\\nNew York, NY 10011\\na  \n",
       "2       PAC Reinforcement Learning with Rich Observations\\nAkshay Krishnamurthy\\nUniversity of Massachusetts, Amherst\\nAmherst, MA, 01003\\nakshay@cs.umass.edu\\nAlekh Agarwal\\nMicrosoft Research\\nNew York, NY 10011\\na  \n",
       "3         Automated scalable segmentation of neurons from\\nmultispectral images\\nUygar Sümbül\\nGrossman Center for the Statistics of Mind\\nand Dept. of Statistics, Columbia University\\nDouglas Roossien Jr.\\nUniversit  \n",
       "3         Automated scalable segmentation of neurons from\\nmultispectral images\\nUygar Sümbül\\nGrossman Center for the Statistics of Mind\\nand Dept. of Statistics, Columbia University\\nDouglas Roossien Jr.\\nUniversit  \n",
       "4           Unsupervised Learning of Spoken Language with\\nVisual Context\\nDavid Harwath, Antonio Torralba, and James R. Glass\\nComputer Science and Artificial Intelligence Laboratory\\nMassachusetts Institute of Tech  \n",
       "4           Unsupervised Learning of Spoken Language with\\nVisual Context\\nDavid Harwath, Antonio Torralba, and James R. Glass\\nComputer Science and Artificial Intelligence Laboratory\\nMassachusetts Institute of Tech  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 300)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Text Analytics with Python (2nd Ed.) Chapter 6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-notes",
   "language": "python",
   "name": "python-notes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
