{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbKLRwnl-CE3"
   },
   "source": [
    "# Hyper-Parameter Tuning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EAo_DBkSEDFh"
   },
   "source": [
    "There are two important techniques to fine-tune the hyperparameters of the model: Grid Search and Cross Validation.\n",
    "\n",
    "- Grid Search\n",
    "  - Define a few parameter values and experiment all these values in modeling. Use `sklearn.model_selection.GridSearchCV` to find the best parameter settings.\n",
    "- Cross Validation\n",
    "  - Fine-tune the parameters using cross-validation. Common CV methods include `sklearn.model_selection.StratifiedKFold`, `sklearn_model_selection.ShuffleSplit`, `LeaveOneOut`.\n",
    "\n",
    "Both mothods can make use of the `pipeline` in sklearn to streamline the processing of training and validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nXT1cD7kFe0q"
   },
   "source": [
    "## SVM Model\n",
    "\n",
    "- This example is from the officient `sklearn` documentation\n",
    "- A classic SVM model with train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "MIhKFSpm-zA9",
    "outputId": "408ac41b-ff2b-4f02-844f-6f48180b5431"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Normal SVM model\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "X.shape, y.shape\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=0)\n",
    "\n",
    "X_train.shape, y_train.shape\n",
    "\n",
    "X_test.shape, y_test.shape\n",
    "\n",
    "## fit on train sets\n",
    "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "## test on test sets\n",
    "clf.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKLsU9QlGBE9"
   },
   "source": [
    "## Default K-fold Cross Validation\n",
    "\n",
    "- We can easily use the `cross_val_score()` to do the K-fold cross validation for a specific training model (without shuffling)\n",
    "\n",
    ":::{note}\n",
    "By default, `train_test_split` returns a random split.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "K4mKbh0OF5Of",
    "outputId": "5960b3e3-eabf-46b7-f017-67d2c07db029"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97 (+/- 0.09)\n"
     ]
    }
   ],
   "source": [
    "## Cross-validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf = svm.SVC(kernel='linear', C=1)\n",
    "scores = cross_val_score(clf, X, y, cv=10, scoring='f1_macro')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvPHjM6mD2vU"
   },
   "source": [
    "## GridSearchCV and Fine-Tuning Hyper-Parameters\n",
    "\n",
    "- Important steps:\n",
    "  - Define SVM classifier\n",
    "  - Define a set of parameter values to experiment\n",
    "  - Use `GridSearchCV` to find the best parameter settings\n",
    "  - `GridSearchCV` by default implements cross-validation methods to find the optimal parameter settings.\n",
    "  - In other words, we can specify our own more sophisticated CV methods in `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "id": "W8zpNtic-CE5",
    "outputId": "f38a5485-d7f0-45a5-fda5-8e33ea9f0d33"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000737</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 1, 'kernel': 'linear'}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.016330</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000651</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.021082</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000511</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>10</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 10, 'kernel': 'linear'}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.038873</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000604</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>10</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 10, 'kernel': 'rbf'}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.016330</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
       "0       0.000737      0.000221  ...        0.016330                1\n",
       "1       0.000651      0.000035  ...        0.021082                4\n",
       "2       0.000511      0.000027  ...        0.038873                3\n",
       "3       0.000604      0.000047  ...        0.016330                1\n",
       "\n",
       "[4 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "iris = datasets.load_iris()\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, parameters, cv=5) # \n",
    "clf.fit(iris.data, iris.target)\n",
    "\n",
    "\n",
    "sorted(clf.cv_results_.keys())\n",
    "\n",
    "#print(clf.cv_results_)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "cv_results_df=pd.DataFrame(clf.cv_results_)\n",
    "cv_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ueHg5TA_AU1F"
   },
   "source": [
    "## Cross-validation, Hyper-Parameter Tuning, and Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IcbYtf3gCvKZ"
   },
   "source": [
    "- Common cross validation methods:\n",
    "  - `StratifiedKFold`: Split data into train and validation sets by preserving the percentage of samples of each class\n",
    "  - `ShuffleSplit`: Split data into train and validation sets by first shuffling the data and then splitting\n",
    "  - `StratifiedShuffleSplit`: Stratified + Shuffled\n",
    "  - `LeaveOneOut`: Creating train sets by taking all samples execept one, which is left out for validation\n",
    "- Important Steps\n",
    "  - Define all preprocessing methods as Tranasformer\n",
    "  - Create a pipeline\n",
    "  - Define a cross-validation method\n",
    "  - Use `cross_val_score()` to fine the best parameter settings by feeding the pipeline and the CV method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "qp5xx62YAYoe",
    "outputId": "d13c40b6-0fee-45ec-d4ec-d5373a3ef867"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold CV: [0.96666667 0.96666667 0.96666667 0.9        1.        ]\n",
      "Shuffle CV: [0.86666667 1.         1.         1.         0.93333333]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "## Create pipeline\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), svm.SVC(C=1))\n",
    "\n",
    "## Define CV methods\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=7)\n",
    "shuffsplit = ShuffleSplit(n_splits=5, test_size=0.1, random_state=7)\n",
    "\n",
    "## CV results\n",
    "print('K-fold CV:', cross_val_score(clf, X, y, cv=kfold))\n",
    "print('Shuffle CV:', cross_val_score(clf, X, y, cv=shuffsplit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cTEs-RISH6kn"
   },
   "source": [
    "## Deep Learning Example\n",
    "\n",
    "- This is based on [GridSearchCV with keras](https://www.kaggle.com/shujunge/gridsearchcv-with-keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cYju7A82ARuq"
   },
   "source": [
    "## MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "bb3b9e82b3bcccfaa5563ffe64e1431aec593c0a",
    "id": "olo7bEiC-CFB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from time import time\n",
    "nb_classes = 10\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(X_train.shape[0], 784)\n",
    "X_test = X_test.reshape(X_test.shape[0], 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "8be8a0b79d81c63aa38523e3fdf13caa15e19390",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "id": "Ad2iv3IU-CFH",
    "outputId": "084beac6-5903-4317-9978-3e0a191ab4fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "## Convert y labels (integers) into binary class matrix\n",
    "from keras.utils import np_utils\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "print(Y_train[:5,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H97ae9GP_AeG"
   },
   "source": [
    "## Hyper-Parameter Tuning Using Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qt44scNyKOYX"
   },
   "source": [
    "In this example, we aim to fine-tune the following hyper-parameters of the deep neural network:\n",
    "\n",
    "- `optimizer`\n",
    "- `kernel_initializer` of the Dense layer\n",
    "\n",
    "We can fine-tune other common parameters like epochs and batch-sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "fd1a6fbbbabb324601c0321cae18e8d24d27c661",
    "id": "ibcMSsHw-CFL"
   },
   "outputs": [],
   "source": [
    "def create_model(optimizer='rmsprop', init='glorot_uniform'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_shape=(784,)))\n",
    "    model.add(Activation('relu')) # An \"activation\" is just a non-linear function applied to the output\n",
    "    model.add(Dropout(0.2))   # Dropout helps protect the model from memorizing or \"overfitting\" the training data\n",
    "    model.add(Dense(512, kernel_initializer=init))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10, kernel_initializer=init))\n",
    "    model.add(Activation('softmax')) # This special \"softmax\" a\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy']) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "fd1a6fbbbabb324601c0321cae18e8d24d27c661",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hpa0nnAm-CFO",
    "outputId": "3b72ca48-e6c1-4141-bf92-35c9a434c6a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0417 - accuracy: 0.9264\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0259 - accuracy: 0.9593\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0416 - accuracy: 0.9270\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0226 - accuracy: 0.9651\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0410 - accuracy: 0.9282\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0270 - accuracy: 0.9578\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0415 - accuracy: 0.9274\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0289 - accuracy: 0.9567\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0419 - accuracy: 0.9270\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0221 - accuracy: 0.9633\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0406 - accuracy: 0.9271\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0220 - accuracy: 0.9626\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0399 - accuracy: 0.9276\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0239 - accuracy: 0.9604\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0397 - accuracy: 0.9293\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0232 - accuracy: 0.9592\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0406 - accuracy: 0.9277\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0219 - accuracy: 0.9624\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0406 - accuracy: 0.9271\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0213 - accuracy: 0.9628\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0421 - accuracy: 0.9262\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0254 - accuracy: 0.9599\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0416 - accuracy: 0.9277\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0239 - accuracy: 0.9621\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0418 - accuracy: 0.9276\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0271 - accuracy: 0.9573\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0416 - accuracy: 0.9277\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0272 - accuracy: 0.9560\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0423 - accuracy: 0.9250\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0227 - accuracy: 0.9643\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0407 - accuracy: 0.9268\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0263 - accuracy: 0.9568\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0405 - accuracy: 0.9283\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0219 - accuracy: 0.9612\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0409 - accuracy: 0.9275\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0227 - accuracy: 0.9615\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0406 - accuracy: 0.9284\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0241 - accuracy: 0.9573\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0407 - accuracy: 0.9276\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0184 - accuracy: 0.9672\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0422 - accuracy: 0.9251\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0253 - accuracy: 0.9614\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0417 - accuracy: 0.9264\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0238 - accuracy: 0.9621\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0418 - accuracy: 0.9266\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0261 - accuracy: 0.9584\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0412 - accuracy: 0.9276\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0331 - accuracy: 0.9478\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0428 - accuracy: 0.9250\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0223 - accuracy: 0.9663\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0412 - accuracy: 0.9258\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0211 - accuracy: 0.9632\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0411 - accuracy: 0.9243\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0281 - accuracy: 0.9517\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0417 - accuracy: 0.9268\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0311 - accuracy: 0.9483\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0412 - accuracy: 0.9266\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0247 - accuracy: 0.9566\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0421 - accuracy: 0.9253\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0255 - accuracy: 0.9543\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0370 - accuracy: 0.9340\n",
      "total time: 163.10951614379883\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "start=time()\n",
    "model = KerasClassifier(build_fn=create_model)\n",
    "optimizers = ['rmsprop', 'adam']\n",
    "init = ['glorot_uniform', 'normal', 'uniform']\n",
    "# epochs = [50, 100, 150]\n",
    "# batches = [5, 10, 20]\n",
    "param_grid = dict(optimizer=optimizers, init=init)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "grid_result = grid.fit(X_train, Y_train)\n",
    "print(\"total time:\",time()-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "1dPmHvy-Ak4J",
    "outputId": "1f0c6d47-485a-479c-f7e7-73f659b30f91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.961483 using {'init': 'glorot_uniform', 'optimizer': 'adam'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_init</th>\n",
       "      <th>param_optimizer</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.962227</td>\n",
       "      <td>0.534804</td>\n",
       "      <td>0.789589</td>\n",
       "      <td>0.021689</td>\n",
       "      <td>glorot_uniform</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>{'init': 'glorot_uniform', 'optimizer': 'rmspr...</td>\n",
       "      <td>0.959333</td>\n",
       "      <td>0.965083</td>\n",
       "      <td>0.957750</td>\n",
       "      <td>0.956667</td>\n",
       "      <td>0.963333</td>\n",
       "      <td>0.960433</td>\n",
       "      <td>0.003244</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.087789</td>\n",
       "      <td>0.024603</td>\n",
       "      <td>0.798292</td>\n",
       "      <td>0.013339</td>\n",
       "      <td>glorot_uniform</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'init': 'glorot_uniform', 'optimizer': 'adam'}</td>\n",
       "      <td>0.962583</td>\n",
       "      <td>0.960417</td>\n",
       "      <td>0.959250</td>\n",
       "      <td>0.962417</td>\n",
       "      <td>0.962750</td>\n",
       "      <td>0.961483</td>\n",
       "      <td>0.001401</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.723551</td>\n",
       "      <td>0.063123</td>\n",
       "      <td>0.842619</td>\n",
       "      <td>0.107239</td>\n",
       "      <td>normal</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>{'init': 'normal', 'optimizer': 'rmsprop'}</td>\n",
       "      <td>0.959917</td>\n",
       "      <td>0.962083</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>0.956000</td>\n",
       "      <td>0.964333</td>\n",
       "      <td>0.959933</td>\n",
       "      <td>0.003040</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.174438</td>\n",
       "      <td>0.124374</td>\n",
       "      <td>0.784431</td>\n",
       "      <td>0.015665</td>\n",
       "      <td>normal</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'init': 'normal', 'optimizer': 'adam'}</td>\n",
       "      <td>0.956833</td>\n",
       "      <td>0.961167</td>\n",
       "      <td>0.961500</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>0.967167</td>\n",
       "      <td>0.960800</td>\n",
       "      <td>0.003712</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.698246</td>\n",
       "      <td>0.033024</td>\n",
       "      <td>0.798633</td>\n",
       "      <td>0.015098</td>\n",
       "      <td>uniform</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>{'init': 'uniform', 'optimizer': 'rmsprop'}</td>\n",
       "      <td>0.961417</td>\n",
       "      <td>0.962083</td>\n",
       "      <td>0.958417</td>\n",
       "      <td>0.947833</td>\n",
       "      <td>0.966250</td>\n",
       "      <td>0.959200</td>\n",
       "      <td>0.006209</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.086391</td>\n",
       "      <td>0.034679</td>\n",
       "      <td>0.859442</td>\n",
       "      <td>0.142505</td>\n",
       "      <td>uniform</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'init': 'uniform', 'optimizer': 'adam'}</td>\n",
       "      <td>0.963250</td>\n",
       "      <td>0.951667</td>\n",
       "      <td>0.948333</td>\n",
       "      <td>0.956583</td>\n",
       "      <td>0.954333</td>\n",
       "      <td>0.954833</td>\n",
       "      <td>0.005029</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
       "0       4.962227      0.534804  ...        0.003244                3\n",
       "1       4.087789      0.024603  ...        0.001401                1\n",
       "2       4.723551      0.063123  ...        0.003040                4\n",
       "3       4.174438      0.124374  ...        0.003712                2\n",
       "4       4.698246      0.033024  ...        0.006209                5\n",
       "5       4.086391      0.034679  ...        0.005029                6\n",
       "\n",
       "[6 rows x 15 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The Best Model\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "## Print all experiment results\n",
    "import pandas as pd\n",
    "results = pd.DataFrame(grid_result.cv_results_)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hN94q8lgLzbZ"
   },
   "source": [
    "## K-fold Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QIr_Ey-3UATG"
   },
   "source": [
    "- Similar to shuffle split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "51GkGGAqMHDj"
   },
   "outputs": [],
   "source": [
    "np.random.seed(7)\n",
    "seed=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "74441edf84611c3c879a790c4fe1cbf17e318cdd",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_DLsvxZQ-CFT",
    "outputId": "0d6fc607-523e-4a6b-aeb8-aff311e2ce32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1047 - accuracy: 0.7911\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0458 - accuracy: 0.9188\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0334 - accuracy: 0.9411\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0255 - accuracy: 0.9559\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0207 - accuracy: 0.9641\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0168 - accuracy: 0.9712\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0141 - accuracy: 0.9755\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0121 - accuracy: 0.9795\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0108 - accuracy: 0.9817\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0095 - accuracy: 0.9835\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0121 - accuracy: 0.9782\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1044 - accuracy: 0.7950\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0435 - accuracy: 0.9239\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0319 - accuracy: 0.9445\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0257 - accuracy: 0.9552\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0196 - accuracy: 0.9662\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0161 - accuracy: 0.9725\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0141 - accuracy: 0.9758\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0117 - accuracy: 0.9799\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0100 - accuracy: 0.9825\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0088 - accuracy: 0.9851\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 0.9748\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1058 - accuracy: 0.7887\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0450 - accuracy: 0.9204\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0318 - accuracy: 0.9444\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0249 - accuracy: 0.9570\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0199 - accuracy: 0.9663\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0168 - accuracy: 0.9714\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0140 - accuracy: 0.9765\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0117 - accuracy: 0.9802\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0102 - accuracy: 0.9827\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0088 - accuracy: 0.9859\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0184 - accuracy: 0.9685\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1028 - accuracy: 0.7998\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0449 - accuracy: 0.9203\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0322 - accuracy: 0.9445\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0243 - accuracy: 0.9577\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0198 - accuracy: 0.9660\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0167 - accuracy: 0.9715\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0141 - accuracy: 0.9757\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0121 - accuracy: 0.9796\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0097 - accuracy: 0.9830\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0088 - accuracy: 0.9846\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 0.9783\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1050 - accuracy: 0.7889\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0456 - accuracy: 0.9189\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0325 - accuracy: 0.9439\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0252 - accuracy: 0.9563\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0206 - accuracy: 0.9643\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0165 - accuracy: 0.9717\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0142 - accuracy: 0.9763\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0117 - accuracy: 0.9799\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0102 - accuracy: 0.9829\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0086 - accuracy: 0.9852\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9750\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1059 - accuracy: 0.7875\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0451 - accuracy: 0.9212\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0322 - accuracy: 0.9446\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0246 - accuracy: 0.9583\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0206 - accuracy: 0.9649\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0163 - accuracy: 0.9719\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0141 - accuracy: 0.9750\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0122 - accuracy: 0.9793\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9819\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0086 - accuracy: 0.9855\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0154 - accuracy: 0.9740\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1047 - accuracy: 0.7929\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0460 - accuracy: 0.9187\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0328 - accuracy: 0.9433\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0247 - accuracy: 0.9576\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0205 - accuracy: 0.9644\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0175 - accuracy: 0.9700\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0141 - accuracy: 0.9755\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0117 - accuracy: 0.9800\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0105 - accuracy: 0.9820\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0084 - accuracy: 0.9853\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0143 - accuracy: 0.9763\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1046 - accuracy: 0.7949\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0463 - accuracy: 0.9182\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0328 - accuracy: 0.9426\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0253 - accuracy: 0.9556\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0206 - accuracy: 0.9649\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0167 - accuracy: 0.9714\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0145 - accuracy: 0.9753\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0118 - accuracy: 0.9797\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0102 - accuracy: 0.9828\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0085 - accuracy: 0.9856\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0181 - accuracy: 0.9720\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1042 - accuracy: 0.7922\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0440 - accuracy: 0.9239\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0324 - accuracy: 0.9429\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0248 - accuracy: 0.9578\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0199 - accuracy: 0.9663\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0166 - accuracy: 0.9719\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0138 - accuracy: 0.9764\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9820\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0102 - accuracy: 0.9823\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0081 - accuracy: 0.9863\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0180 - accuracy: 0.9710\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1045 - accuracy: 0.7953\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0455 - accuracy: 0.9199\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0328 - accuracy: 0.9438\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0252 - accuracy: 0.9557\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0209 - accuracy: 0.9647\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0175 - accuracy: 0.9697\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0145 - accuracy: 0.9749\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0124 - accuracy: 0.9785\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0102 - accuracy: 0.9824\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0089 - accuracy: 0.9847\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9810\n",
      "K-fold Results: 97.49% (0.36%)\n",
      "total time: 29.779260635375977\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_shape=(784,)))\n",
    "    model.add(Activation('relu')) # An \"activation\" is just a non-linear function applied to the output\n",
    "    model.add(Dropout(0.2))   # Dropout helps protect the model from memorizing or \"overfitting\" the training data\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax')) # This special \"softmax\" a\n",
    "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy']) \n",
    "    return model\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "start=time()\n",
    "\n",
    "model2 = KerasClassifier(build_fn=create_model, epochs=10, batch_size=1500,verbose=1)\n",
    "results = cross_val_score(model2, X_train, Y_train, cv=10)\n",
    "\n",
    "print(\"K-fold Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "print(\"total time:\",time()-start)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQcCe8EhQu0V"
   },
   "source": [
    "## Shuffle Split Cross Validation\n",
    "\n",
    "- Shuffle but not stratified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "bDfQpCRNQBzx",
    "outputId": "f8baeafa-1ce3-4fa6-edbb-a19b36167e14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1039 - accuracy: 0.7965\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0454 - accuracy: 0.9197\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0335 - accuracy: 0.9410\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0259 - accuracy: 0.9553\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0202 - accuracy: 0.9651\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0169 - accuracy: 0.9713\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0142 - accuracy: 0.9758\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0126 - accuracy: 0.9788\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0098 - accuracy: 0.9839\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0092 - accuracy: 0.9839\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0129 - accuracy: 0.9773\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1039 - accuracy: 0.7952\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0453 - accuracy: 0.9183\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0320 - accuracy: 0.9442\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0261 - accuracy: 0.9551\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0208 - accuracy: 0.9647\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0164 - accuracy: 0.9723\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0139 - accuracy: 0.9765\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0120 - accuracy: 0.9791\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0101 - accuracy: 0.9835\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0088 - accuracy: 0.9850\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0124 - accuracy: 0.9788\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1057 - accuracy: 0.7922\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0458 - accuracy: 0.9200\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0323 - accuracy: 0.9431\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0257 - accuracy: 0.9568\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0208 - accuracy: 0.9642\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0169 - accuracy: 0.9709\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0141 - accuracy: 0.9753\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0123 - accuracy: 0.9788\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0101 - accuracy: 0.9828\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0093 - accuracy: 0.9839\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0122 - accuracy: 0.9783\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1039 - accuracy: 0.7970\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0442 - accuracy: 0.9224\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0321 - accuracy: 0.9445\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0249 - accuracy: 0.9570\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0206 - accuracy: 0.9644\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0164 - accuracy: 0.9709\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0140 - accuracy: 0.9765\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0114 - accuracy: 0.9802\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0103 - accuracy: 0.9818\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0084 - accuracy: 0.9858\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0167 - accuracy: 0.9733\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1043 - accuracy: 0.7938\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0453 - accuracy: 0.9199\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0331 - accuracy: 0.9418\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0255 - accuracy: 0.9557\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0208 - accuracy: 0.9642\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0163 - accuracy: 0.9714\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0141 - accuracy: 0.9749\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0124 - accuracy: 0.9781\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0098 - accuracy: 0.9834\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0087 - accuracy: 0.9851\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0168 - accuracy: 0.9752\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1014 - accuracy: 0.8043\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0443 - accuracy: 0.9218\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0323 - accuracy: 0.9439\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0247 - accuracy: 0.9577\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0202 - accuracy: 0.9654\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0164 - accuracy: 0.9724\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0139 - accuracy: 0.9759\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0113 - accuracy: 0.9806\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0100 - accuracy: 0.9821\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0084 - accuracy: 0.9860\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.9800\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1080 - accuracy: 0.7908\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0467 - accuracy: 0.9186\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0332 - accuracy: 0.9424\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0253 - accuracy: 0.9568\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0209 - accuracy: 0.9638\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0170 - accuracy: 0.9702\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0141 - accuracy: 0.9760\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0120 - accuracy: 0.9789\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0101 - accuracy: 0.9831\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0091 - accuracy: 0.9847\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9785\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1038 - accuracy: 0.7945\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0448 - accuracy: 0.9215\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0322 - accuracy: 0.9439\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0253 - accuracy: 0.9561\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0204 - accuracy: 0.9649\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0163 - accuracy: 0.9718\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0136 - accuracy: 0.9768\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0121 - accuracy: 0.9788\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0100 - accuracy: 0.9822\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0087 - accuracy: 0.9849\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0155 - accuracy: 0.9747\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1076 - accuracy: 0.7903\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0463 - accuracy: 0.9187\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0328 - accuracy: 0.9422\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0250 - accuracy: 0.9565\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0199 - accuracy: 0.9658\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0171 - accuracy: 0.9701\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0136 - accuracy: 0.9765\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0116 - accuracy: 0.9802\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0102 - accuracy: 0.9823\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0090 - accuracy: 0.9845\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 0.9770\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1045 - accuracy: 0.7910\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0454 - accuracy: 0.9210\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0324 - accuracy: 0.9441\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0253 - accuracy: 0.9561\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0202 - accuracy: 0.9651\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0165 - accuracy: 0.9719\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0144 - accuracy: 0.9755\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0116 - accuracy: 0.9804\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0100 - accuracy: 0.9832\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0089 - accuracy: 0.9848\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0127 - accuracy: 0.9787\n",
      "K-fold Results: 97.72% (0.20%)\n",
      "total time: 31.2500159740448\n"
     ]
    }
   ],
   "source": [
    "## Shuffle Split\n",
    "start=time()\n",
    "sf = ShuffleSplit(n_splits=10)\n",
    "results = cross_val_score(model2, X_train, Y_train, cv=sf)\n",
    "print(\"K-fold Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "print(\"total time:\",time()-start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LE-2zm3OQ1at"
   },
   "source": [
    "## Stratified K-Fold Validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wBGCb4jgSQZ5"
   },
   "source": [
    "- Stratified but not shuffled\n",
    "- Stratified cross-validation gives poor results. No idea why? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277
    },
    "id": "gBdGQJaORI3_",
    "outputId": "094d8934-40f4-4c98-c53f-493fd29d1a6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[5 0 4 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0: 5923,\n",
       "         1: 6742,\n",
       "         2: 5958,\n",
       "         3: 6131,\n",
       "         4: 5842,\n",
       "         5: 5421,\n",
       "         6: 5918,\n",
       "         7: 6265,\n",
       "         8: 5851,\n",
       "         9: 5949})"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Y_train[:4,])\n",
    "print(y_train[:4])\n",
    "from collections import Counter\n",
    "\n",
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-Nr5e0lhTi_g",
    "outputId": "d982f2f5-2924-4924-d65e-733ed3e6497e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 10.0234 - accuracy: 0.0974\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8925 - accuracy: 0.1069\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8916 - accuracy: 0.1004\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8916 - accuracy: 0.0986\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.8916 - accuracy: 0.1016\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8916 - accuracy: 0.0997\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8916 - accuracy: 0.0999\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8916 - accuracy: 0.1024\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8916 - accuracy: 0.1017\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.8916 - accuracy: 0.1002\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9.8922 - accuracy: 0.0987\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 10.0317 - accuracy: 0.0952\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.8930 - accuracy: 0.1012\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8919 - accuracy: 0.1015\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.8918 - accuracy: 0.1006\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.8918 - accuracy: 0.0984\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8918 - accuracy: 0.0992\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.8918 - accuracy: 0.0992\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8918 - accuracy: 0.0981\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8918 - accuracy: 0.0992\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.8918 - accuracy: 0.1014\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9.8903 - accuracy: 0.0987\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 10.0076 - accuracy: 0.0989\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.8922 - accuracy: 0.1001\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8918 - accuracy: 0.1016\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8918 - accuracy: 0.0968\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.8918 - accuracy: 0.1012\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.8918 - accuracy: 0.0975\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.8918 - accuracy: 0.0995\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.8918 - accuracy: 0.1021\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8918 - accuracy: 0.1017\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8918 - accuracy: 0.1018\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9.8903 - accuracy: 0.0993\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 10.0352 - accuracy: 0.1036\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8921 - accuracy: 0.1104\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8918 - accuracy: 0.1044\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8918 - accuracy: 0.1035\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8918 - accuracy: 0.0994\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.8918 - accuracy: 0.1016\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8918 - accuracy: 0.0992\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8918 - accuracy: 0.1004\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8918 - accuracy: 0.1002\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8918 - accuracy: 0.1022\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9.8903 - accuracy: 0.1022\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 10.0332 - accuracy: 0.0993\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.8924 - accuracy: 0.1021\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.8916 - accuracy: 0.1002\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.8916 - accuracy: 0.0984\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8916 - accuracy: 0.0999\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8916 - accuracy: 0.0978\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.8916 - accuracy: 0.0956\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.8916 - accuracy: 0.1037\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8916 - accuracy: 0.1028\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8916 - accuracy: 0.1009\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9.8922 - accuracy: 0.0992\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 10.0069 - accuracy: 0.0996\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.8921 - accuracy: 0.0977\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.8916 - accuracy: 0.1000\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8916 - accuracy: 0.0980\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8916 - accuracy: 0.1004\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.8916 - accuracy: 0.0998\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.8916 - accuracy: 0.0991\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.8916 - accuracy: 0.1025\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8916 - accuracy: 0.1010\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.8916 - accuracy: 0.0991\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9.8925 - accuracy: 0.1023\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 10.0232 - accuracy: 0.0983\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.8921 - accuracy: 0.0992\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8916 - accuracy: 0.0999\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8916 - accuracy: 0.0981\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8916 - accuracy: 0.0989\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8916 - accuracy: 0.0995\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.8916 - accuracy: 0.0973\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8916 - accuracy: 0.1000\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8916 - accuracy: 0.1006\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.8916 - accuracy: 0.0990\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9.8925 - accuracy: 0.0975\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 10.0450 - accuracy: 0.0947\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8924 - accuracy: 0.0943\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8919 - accuracy: 0.1015\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8918 - accuracy: 0.0983\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8918 - accuracy: 0.0987\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8918 - accuracy: 0.1005\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8918 - accuracy: 0.1005\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8918 - accuracy: 0.0977\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8918 - accuracy: 0.1024\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8918 - accuracy: 0.1005\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9.8900 - accuracy: 0.0987\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 10.0163 - accuracy: 0.1055\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8919 - accuracy: 0.0834\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8915 - accuracy: 0.0926\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8915 - accuracy: 0.0991\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8915 - accuracy: 0.1032\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.8915 - accuracy: 0.1005\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8915 - accuracy: 0.1022\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8915 - accuracy: 0.1000\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8915 - accuracy: 0.1006\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8915 - accuracy: 0.0996\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9.8929 - accuracy: 0.0987\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 10.0165 - accuracy: 0.1039\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.8919 - accuracy: 0.0942\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.8915 - accuracy: 0.0979\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.8915 - accuracy: 0.0997\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.8915 - accuracy: 0.1028\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8915 - accuracy: 0.1006\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8915 - accuracy: 0.0996\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 9.8915 - accuracy: 0.1008\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8915 - accuracy: 0.1046\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 9.8915 - accuracy: 0.0997\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9.8933 - accuracy: 0.1022\n",
      "Stratified K-fold Results: 9.97% (0.17%)\n",
      "total time: 30.07964015007019\n"
     ]
    }
   ],
   "source": [
    "## Stratified Shuffle\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "start=time()\n",
    "sk = StratifiedKFold(n_splits=10)\n",
    "results = cross_val_score(model2, X_train, y_train, cv=sk)\n",
    "print(\"Stratified K-fold Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "print(\"total time:\",time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_TZlgwPZS_ND"
   },
   "source": [
    "## Stratified Shuffle Split\n",
    "\n",
    "- A mix of `StratifiedKFold` and `ShuffleSplit`, which returns stratified randomized folds\n",
    "- The folds are made by preserving the percentage of samples for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "AFgSsR9zQ1Ic",
    "outputId": "e205238d-c54a-4590-c18f-bdd05dc9924a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1072 - accuracy: 0.7853\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0460 - accuracy: 0.9186\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0341 - accuracy: 0.9406\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0260 - accuracy: 0.9551\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0209 - accuracy: 0.9644\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0170 - accuracy: 0.9708\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0143 - accuracy: 0.9756\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0122 - accuracy: 0.9788\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0101 - accuracy: 0.9828\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0093 - accuracy: 0.9840\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 0.9753\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1032 - accuracy: 0.7954\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0449 - accuracy: 0.9205\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0321 - accuracy: 0.9437\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0250 - accuracy: 0.9573\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0204 - accuracy: 0.9647\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0168 - accuracy: 0.9714\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0142 - accuracy: 0.9754\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0118 - accuracy: 0.9803\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0099 - accuracy: 0.9833\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0086 - accuracy: 0.9856\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.9752\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1054 - accuracy: 0.7976\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0474 - accuracy: 0.9161\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0328 - accuracy: 0.9434\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0253 - accuracy: 0.9564\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0205 - accuracy: 0.9654\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0171 - accuracy: 0.9706\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0136 - accuracy: 0.9767\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0124 - accuracy: 0.9790\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0105 - accuracy: 0.9818\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0087 - accuracy: 0.9849\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9745\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1044 - accuracy: 0.7927\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0452 - accuracy: 0.9197\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0320 - accuracy: 0.9444\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0250 - accuracy: 0.9570\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0198 - accuracy: 0.9658\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0167 - accuracy: 0.9710\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0139 - accuracy: 0.9762\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0117 - accuracy: 0.9803\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0102 - accuracy: 0.9824\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0088 - accuracy: 0.9849\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 0.9722\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1065 - accuracy: 0.7891\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0462 - accuracy: 0.9185\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0330 - accuracy: 0.9418\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0252 - accuracy: 0.9568\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0214 - accuracy: 0.9632\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0170 - accuracy: 0.9709\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0144 - accuracy: 0.9744\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0120 - accuracy: 0.9794\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0107 - accuracy: 0.9810\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0094 - accuracy: 0.9841\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0141 - accuracy: 0.9780\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.1051 - accuracy: 0.7913\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0464 - accuracy: 0.9176\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0320 - accuracy: 0.9447\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0254 - accuracy: 0.9560\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0204 - accuracy: 0.9648\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0170 - accuracy: 0.9709\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0143 - accuracy: 0.9752\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0117 - accuracy: 0.9796\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0104 - accuracy: 0.9824\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0088 - accuracy: 0.9849\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9770\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1052 - accuracy: 0.7921\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0445 - accuracy: 0.9216\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0325 - accuracy: 0.9442\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0254 - accuracy: 0.9570\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0201 - accuracy: 0.9650\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0168 - accuracy: 0.9705\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0140 - accuracy: 0.9766\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0118 - accuracy: 0.9799\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0098 - accuracy: 0.9833\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0089 - accuracy: 0.9847\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0138 - accuracy: 0.9763\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.1029 - accuracy: 0.7947\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0447 - accuracy: 0.9211\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0316 - accuracy: 0.9444\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0239 - accuracy: 0.9595\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0198 - accuracy: 0.9657\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0157 - accuracy: 0.9731\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0139 - accuracy: 0.9756\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0119 - accuracy: 0.9797\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0093 - accuracy: 0.9842\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0086 - accuracy: 0.9854\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0127 - accuracy: 0.9777\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1030 - accuracy: 0.7933\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0447 - accuracy: 0.9201\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0322 - accuracy: 0.9437\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0250 - accuracy: 0.9572\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0193 - accuracy: 0.9659\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0168 - accuracy: 0.9704\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0134 - accuracy: 0.9769\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0123 - accuracy: 0.9788\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0096 - accuracy: 0.9834\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0086 - accuracy: 0.9857\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0136 - accuracy: 0.9775\n",
      "Epoch 1/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.1058 - accuracy: 0.7881\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0448 - accuracy: 0.9198\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0323 - accuracy: 0.9436\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0259 - accuracy: 0.9553\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0201 - accuracy: 0.9648\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0171 - accuracy: 0.9708\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0141 - accuracy: 0.9756\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0120 - accuracy: 0.9790\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0102 - accuracy: 0.9822\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0083 - accuracy: 0.9862\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0119 - accuracy: 0.9795\n",
      "Stratified Shuffle Results: 97.63% (0.20%)\n",
      "total time: 30.383320093154907\n"
     ]
    }
   ],
   "source": [
    "## Stratified Shuffle\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "start=time()\n",
    "ss = StratifiedShuffleSplit(n_splits=10)\n",
    "results = cross_val_score(model2, X_train, Y_train, cv=ss)\n",
    "print(\"Stratified Shuffle Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "print(\"total time:\",time()-start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G35jP-COVm4j"
   },
   "source": [
    "## GridSearchCV and Cross-Validation\n",
    "\n",
    "- We perform the `GridSearchCV` to find the optimal optimizers\n",
    "- We determine the best parameter values based on stratified shuffled 5-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "dYlQfQuxVmJe",
    "outputId": "d99829e7-6512-430e-f91b-dfdb27712f7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0402 - accuracy: 0.9310\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0275 - accuracy: 0.9605\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0395 - accuracy: 0.9323\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0300 - accuracy: 0.9485\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0398 - accuracy: 0.9315\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0232 - accuracy: 0.9605\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0400 - accuracy: 0.9308\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0249 - accuracy: 0.9627\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0400 - accuracy: 0.9309\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0305 - accuracy: 0.9533\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0393 - accuracy: 0.9297\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0237 - accuracy: 0.9608\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0382 - accuracy: 0.9311\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0201 - accuracy: 0.9648\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0387 - accuracy: 0.9310\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0274 - accuracy: 0.9540\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0379 - accuracy: 0.9324\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0256 - accuracy: 0.9577\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0389 - accuracy: 0.9311\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0217 - accuracy: 0.9633\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0405 - accuracy: 0.9282\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0236 - accuracy: 0.9647\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0397 - accuracy: 0.9305\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0259 - accuracy: 0.9587\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0405 - accuracy: 0.9285\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0219 - accuracy: 0.9645\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0398 - accuracy: 0.9305\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0311 - accuracy: 0.9557\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0398 - accuracy: 0.9308\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0212 - accuracy: 0.9642\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0392 - accuracy: 0.9298\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0230 - accuracy: 0.9590\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0388 - accuracy: 0.9310\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0232 - accuracy: 0.9580\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0390 - accuracy: 0.9299\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0224 - accuracy: 0.9613\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0391 - accuracy: 0.9302\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0263 - accuracy: 0.9573\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0391 - accuracy: 0.9297\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0221 - accuracy: 0.9638\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0408 - accuracy: 0.9281\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0235 - accuracy: 0.9618\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0408 - accuracy: 0.9296\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0246 - accuracy: 0.9605\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0404 - accuracy: 0.9306\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0271 - accuracy: 0.9593\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0399 - accuracy: 0.9296\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0231 - accuracy: 0.9638\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0403 - accuracy: 0.9299\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0213 - accuracy: 0.9653\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0395 - accuracy: 0.9291\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0239 - accuracy: 0.9612\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0394 - accuracy: 0.9289\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0217 - accuracy: 0.9635\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0401 - accuracy: 0.9289\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0210 - accuracy: 0.9640\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0397 - accuracy: 0.9286\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0225 - accuracy: 0.9600\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0405 - accuracy: 0.9280\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0193 - accuracy: 0.9663\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0384 - accuracy: 0.9313\n",
      "total time: 203.81905102729797\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_shape=(784,)))\n",
    "    model.add(Activation('relu')) # An \"activation\" is just a non-linear function applied to the output\n",
    "    model.add(Dropout(0.2))   # Dropout helps protect the model from memorizing or \"overfitting\" the training data\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax')) # This special \"softmax\" a\n",
    "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy']) \n",
    "    return model\n",
    "start=time()\n",
    "\n",
    "## Define cross-validation method\n",
    "ss = StratifiedShuffleSplit(n_splits=5)\n",
    "\n",
    "## Define Model\n",
    "model3 = KerasClassifier(build_fn=create_model)\n",
    "\n",
    "## Define Hyper-parameter values\n",
    "optimizers = ['rmsprop', 'adam']\n",
    "param_grid = dict(optimizer=optimizers, init=init)\n",
    "\n",
    "## Define GridSearchCV\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=ss)\n",
    "grid_result = grid.fit(X_train, Y_train)\n",
    "print(\"total time:\",time()-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "dgUjjP6ZWqLO",
    "outputId": "cdce9529-6f4f-4b2c-ae34-ef845766eb8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.963000 using {'init': 'uniform', 'optimizer': 'adam'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_init</th>\n",
       "      <th>param_optimizer</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.656565</td>\n",
       "      <td>0.121780</td>\n",
       "      <td>0.524209</td>\n",
       "      <td>0.008416</td>\n",
       "      <td>glorot_uniform</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>{'init': 'glorot_uniform', 'optimizer': 'rmspr...</td>\n",
       "      <td>0.960500</td>\n",
       "      <td>0.948500</td>\n",
       "      <td>0.960500</td>\n",
       "      <td>0.962667</td>\n",
       "      <td>0.953333</td>\n",
       "      <td>0.957100</td>\n",
       "      <td>0.005334</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.022944</td>\n",
       "      <td>0.100696</td>\n",
       "      <td>0.534721</td>\n",
       "      <td>0.013367</td>\n",
       "      <td>glorot_uniform</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'init': 'glorot_uniform', 'optimizer': 'adam'}</td>\n",
       "      <td>0.960833</td>\n",
       "      <td>0.964833</td>\n",
       "      <td>0.954000</td>\n",
       "      <td>0.957667</td>\n",
       "      <td>0.963333</td>\n",
       "      <td>0.960133</td>\n",
       "      <td>0.003912</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.614549</td>\n",
       "      <td>0.093743</td>\n",
       "      <td>0.522084</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>normal</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>{'init': 'normal', 'optimizer': 'rmsprop'}</td>\n",
       "      <td>0.964667</td>\n",
       "      <td>0.958667</td>\n",
       "      <td>0.964500</td>\n",
       "      <td>0.955667</td>\n",
       "      <td>0.964167</td>\n",
       "      <td>0.961533</td>\n",
       "      <td>0.003693</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.639868</td>\n",
       "      <td>0.232617</td>\n",
       "      <td>0.496856</td>\n",
       "      <td>0.013943</td>\n",
       "      <td>normal</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'init': 'normal', 'optimizer': 'adam'}</td>\n",
       "      <td>0.959000</td>\n",
       "      <td>0.958000</td>\n",
       "      <td>0.961333</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>0.963833</td>\n",
       "      <td>0.959900</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.057838</td>\n",
       "      <td>0.092201</td>\n",
       "      <td>0.491186</td>\n",
       "      <td>0.010245</td>\n",
       "      <td>uniform</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>{'init': 'uniform', 'optimizer': 'rmsprop'}</td>\n",
       "      <td>0.961833</td>\n",
       "      <td>0.960500</td>\n",
       "      <td>0.959333</td>\n",
       "      <td>0.963833</td>\n",
       "      <td>0.965333</td>\n",
       "      <td>0.962167</td>\n",
       "      <td>0.002178</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.619616</td>\n",
       "      <td>0.151503</td>\n",
       "      <td>0.484414</td>\n",
       "      <td>0.004364</td>\n",
       "      <td>uniform</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'init': 'uniform', 'optimizer': 'adam'}</td>\n",
       "      <td>0.961167</td>\n",
       "      <td>0.963500</td>\n",
       "      <td>0.964000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.966333</td>\n",
       "      <td>0.963000</td>\n",
       "      <td>0.002224</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
       "0       6.656565      0.121780  ...        0.005334                6\n",
       "1       6.022944      0.100696  ...        0.003912                4\n",
       "2       6.614549      0.093743  ...        0.003693                3\n",
       "3       5.639868      0.232617  ...        0.002389                5\n",
       "4       6.057838      0.092201  ...        0.002178                2\n",
       "5       5.619616      0.151503  ...        0.002224                1\n",
       "\n",
       "[6 rows x 15 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The Best Model\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "## Print all experiment results\n",
    "import pandas as pd\n",
    "results = pd.DataFrame(grid_result.cv_results_)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3898855ef08547e1431b54f16951a8f7adbd4a6e",
    "id": "sxIhttNA-CFa"
   },
   "source": [
    "## References\n",
    "\n",
    "- [`GridSearchCV` documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV)\n",
    "- [Cross-validation: evaluating estimator performance](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation)\n",
    "- [Scoring Parameters](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter)\n",
    "- [GridSearchCV with keras](https://www.kaggle.com/shujunge/gridsearchcv-with-keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6UmngyApuygr"
   },
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "Mv4vu5gguxRO",
    "outputId": "64ddbcf8-f43e-4035-bd63-9d2a1a7893ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow==2.3.0\n",
      "scikit-learn==0.22.2.post1\n",
      "pandas==1.1.2\n",
      "numpy==1.18.5\n"
     ]
    }
   ],
   "source": [
    "# %run ./get_modules.py\n",
    "import pkg_resources\n",
    "import types\n",
    "def get_imports():\n",
    "    for name, val in globals().items():\n",
    "        if isinstance(val, types.ModuleType):\n",
    "            # Split ensures you get root package, \n",
    "            # not just imported function\n",
    "            name = val.__name__.split(\".\")[0]\n",
    "\n",
    "        elif isinstance(val, type):\n",
    "            name = val.__module__.split(\".\")[0]\n",
    "\n",
    "        # Some packages are weird and have different\n",
    "        # imported names vs. system/pip names. Unfortunately,\n",
    "        # there is no systematic way to get pip names from\n",
    "        # a package's imported name. You'll have to add\n",
    "        # exceptions to this list manually!\n",
    "        poorly_named_packages = {\n",
    "            \"PIL\": \"Pillow\",\n",
    "            \"sklearn\": \"scikit-learn\"\n",
    "        }\n",
    "        if name in poorly_named_packages.keys():\n",
    "            name = poorly_named_packages[name]\n",
    "\n",
    "        yield name\n",
    "        \n",
    "        \n",
    "imports = list(set(get_imports()))\n",
    "\n",
    "# The only way I found to get the version of the root package\n",
    "# from only the name of the package is to cross-check the names \n",
    "# of installed packages vs. imported packages\n",
    "requirements = []\n",
    "for m in pkg_resources.working_set:\n",
    "    if m.project_name in imports and m.project_name!=\"pip\":\n",
    "        requirements.append((m.project_name, m.version))\n",
    "\n",
    "for r in requirements:\n",
    "    print(\"{}=={}\".format(*r))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "hyperparameter-tuning.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}