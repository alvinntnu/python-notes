{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TSOdO9g2f_oW"
   },
   "source": [
    "# Network Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEMO_DATA_ROOT = \"../../../RepositoryData/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 963,
     "status": "ok",
     "timestamp": 1601945189657,
     "user": {
      "displayName": "Alvin Chen",
      "photoUrl": "",
      "userId": "12962786962925949010"
     },
     "user_tz": -480
    },
    "id": "luUoc4dHjvRc",
    "outputId": "fe395e9a-157d-4ab2-f87a-3bc36a587151"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "atTV3isuf_oY"
   },
   "source": [
    "## Word Similarities from Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wxyN9qWef_oY"
   },
   "source": [
    "If necessary, install `spacy` and the Chinese language model `zh_core_web_lg` (glove embeddings). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 11393,
     "status": "ok",
     "timestamp": 1601945200098,
     "user": {
      "displayName": "Alvin Chen",
      "photoUrl": "",
      "userId": "12962786962925949010"
     },
     "user_tz": -480
    },
    "id": "dPQYasP5f_oZ",
    "outputId": "7c21747a-3802-4f28-f3c4-9c75bc93a2f3"
   },
   "outputs": [],
   "source": [
    "# !pip install spacy==2.3\n",
    "# !spacy download zh_core_web_lg\n",
    "# !pip install pyvis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Rk6vVgNf_od"
   },
   "source": [
    "Load the packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "executionInfo": {
     "elapsed": 15175,
     "status": "ok",
     "timestamp": 1601945203888,
     "user": {
      "displayName": "Alvin Chen",
      "photoUrl": "",
      "userId": "12962786962925949010"
     },
     "user_tz": -480
    },
    "id": "52do5HIqf_oe",
    "outputId": "2ce2ce22-5bf4-49d1-dfba-a051a06c489b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from cache /var/folders/n7/ltpzwx813c599nfxfb94s_640000gn/T/jieba.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.737 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "nlp_zh = spacy.load('zh_core_web_lg')\n",
    "\n",
    "near_syns = ['覺得','認為','宣稱','表示','強調','顯示', '說明','指出','提出','主張']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABtWC-edf_oh"
   },
   "source": [
    "Inspect the word vectors matrix from the spacy model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 15168,
     "status": "ok",
     "timestamp": 1601945203890,
     "user": {
      "displayName": "Alvin Chen",
      "photoUrl": "",
      "userId": "12962786962925949010"
     },
     "user_tz": -480
    },
    "id": "4GWz729_f_oh",
    "outputId": "024788cd-bdb4-4c7b-bf9e-f91b6d04b8d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spacy GloVe word vectors Shape: (vocab_size, embedding_dim) (500000, 300)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_word_vectors = nlp_zh.vocab.vectors\n",
    "print('Spacy GloVe word vectors Shape: (vocab_size, embedding_dim)',glove_word_vectors.shape)\n",
    "len(glove_word_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9hkC_7Hlf_ok"
   },
   "source": [
    "Pairwise similarities of the words in the near-syns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "executionInfo": {
     "elapsed": 15134,
     "status": "ok",
     "timestamp": 1601945203890,
     "user": {
      "displayName": "Alvin Chen",
      "photoUrl": "",
      "userId": "12962786962925949010"
     },
     "user_tz": -480
    },
    "id": "9WE_eiBkf_ol",
    "outputId": "ceea67f2-ae0a-470e-ce62-b2c409a5fc43"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>覺得</th>\n",
       "      <th>認為</th>\n",
       "      <th>宣稱</th>\n",
       "      <th>表示</th>\n",
       "      <th>強調</th>\n",
       "      <th>顯示</th>\n",
       "      <th>說明</th>\n",
       "      <th>指出</th>\n",
       "      <th>提出</th>\n",
       "      <th>主張</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>覺得</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>認為</th>\n",
       "      <td>0.69</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>宣稱</th>\n",
       "      <td>0.47</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>表示</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>強調</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>顯示</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>說明</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>指出</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>提出</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>主張</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      覺得    認為    宣稱    表示    強調    顯示    說明    指出    提出    主張\n",
       "覺得  1.00  0.69  0.47  0.18  0.55  0.37  0.48  0.16  0.01  0.46\n",
       "認為  0.69  1.00  0.72  0.39  0.77  0.58  0.59  0.45  0.19  0.73\n",
       "宣稱  0.47  0.72  1.00  0.38  0.71  0.58  0.60  0.38  0.20  0.70\n",
       "表示  0.18  0.39  0.38  1.00  0.43  0.27  0.23  0.78  0.48  0.22\n",
       "強調  0.55  0.77  0.71  0.43  1.00  0.55  0.69  0.49  0.28  0.73\n",
       "顯示  0.37  0.58  0.58  0.27  0.55  1.00  0.62  0.30  0.06  0.37\n",
       "說明  0.48  0.59  0.60  0.23  0.69  0.62  1.00  0.29  0.19  0.54\n",
       "指出  0.16  0.45  0.38  0.78  0.49  0.30  0.29  1.00  0.62  0.27\n",
       "提出  0.01  0.19  0.20  0.48  0.28  0.06  0.19  0.62  1.00  0.27\n",
       "主張  0.46  0.73  0.70  0.22  0.73  0.37  0.54  0.27  0.27  1.00"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = nlp_zh.vocab['認為']\n",
    "w2 = nlp_zh.vocab['覺得']\n",
    "\n",
    "# pairwise similarities of near-syns\n",
    "\n",
    "\n",
    "def pairwise_similarity(word_list, nlp):\n",
    "    word_sim_matrix = np.ones(shape=(len(word_list),len(word_list)))\n",
    "    for i, w1 in enumerate(word_list):\n",
    "        #print(str(i) + ' '+w1)\n",
    "        for j, w2 in enumerate(word_list):\n",
    "            if w1 !=w2:\n",
    "                word_sim_matrix[i,j] = nlp.vocab[str(w1)].similarity(nlp.vocab[str(w2)])\n",
    "    return(word_sim_matrix)\n",
    "        \n",
    "pd.DataFrame(data= np.round(pairwise_similarity(near_syns, nlp_zh),2),\n",
    "             index=near_syns,\n",
    "             columns=near_syns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aA08LDBnf_oo"
   },
   "source": [
    "To reduce the computation cost, extract the vocabulary of the Chinense model by excluding:\n",
    "- ascii characters\n",
    "- digits\n",
    "- punctuations\n",
    "\n",
    "And also, consider only two-character words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "executionInfo": {
     "elapsed": 15513,
     "status": "ok",
     "timestamp": 1601945204289,
     "user": {
      "displayName": "Alvin Chen",
      "photoUrl": "",
      "userId": "12962786962925949010"
     },
     "user_tz": -480
    },
    "id": "4luNL7kZf_op",
    "outputId": "623d5ef1-b26f-4cf2-8f20-35fbc88463a0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "544337\n",
      "['2022', '022', '乌拉特后旗', '特后旗', '温差', '湘潭', 'play', '留學', '索取', '透明度', '孤立', '伊始', '安全法', '故居', '中医院', '番茄', '07月', '历任', '預算', '十字', '手柄', '利润率', '133', '涛', 'Office', '宝博', '企稳', '加�', '代辦', '紧缺', '重现', '冲着', '大利', '播种', '随手', '克什克腾旗', '克腾旗', \"'s\", \"'x\", '换来', '受灾', '亮眼', '峦�', '峦', '计数', '操穴', '100米', '00米', '展品', '帶動', '前任', 'a站', '表率', '社科', '供奉', '安检', '吉泽明', '学生会', '三线', '清凉', '取暖', '隐蔽', '无所谓', '不在乎', '粗大', '串联', '切尔西', '時光', '增殖', '宜宾市', '溫暖', '燕子', '燕', '后天', '冒出', '權力', '倫敦', '波司登', '胜地', '值当', '康健', '协和', '朴素', '胸口', '樱花', '樱', '孔明', '少许', '嵌入', '镍', '掘金', '掘', '推�', '项链', '包赢', '制作人', '增产', '交流区', '妆品', '妆', '温恒', '未婚', '非金属', '事前', '台账', '强强', '银行家', '大树', '小哥', '纱', '肤色', '肤', '陡然', '陡', '打水', '電源', '项目部', '樂團', '兩位', '来不及', '邻家', '外星人', '黄网站', '南充', '市直', '带入', '電影院', '摔倒', '礼服', '建造师', '５', '自拍区', '贯通', '沿岸', '透玩', 'LOGO', 'logo', 'OGO', '他家', '领空', '稀少', '13%', '山林', '频w', '算单', '田野', '猜想', '這裏', '增強', '文山', '不俗', '收費', '配电', '利害', '萌', '捡', '开播', '依规', '深知', '株洲', '产视', '\\x07\\x06\\x05', '玩场', '事務', '常州市', 'MB', 'mb', '一早', '乐网', '祖母', '二季度', 'AV天堂', 'V天堂', 'XXxx', '石川', '解散', '天国', '开房', '野狼', '法语', '承德市', '赶来', '光临', '涉事', '著作权', '老人们', '怀化', '节水', '米兜', '腰部', '尤物', '频自', '黑洞', '编导', '永利网', '乾淨', '戀愛', '戀', '私阴', '脱水']\n"
     ]
    }
   ],
   "source": [
    "vocab = list(nlp_zh.vocab.strings)\n",
    "#vocab = [w.text for w in nlp_zh.vocab if np.count_nonzero(w.vector) and not w.is_ascii and not w.is_punct]\n",
    "print(len(vocab))\n",
    "print(vocab[20000:20200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each near-syn, we should find the word similarities between the near-syn and all the other words in the NLP vocabulary.\n",
    "\n",
    "Take the first near-syn for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 84316,
     "status": "ok",
     "timestamp": 1601945273108,
     "user": {
      "displayName": "Alvin Chen",
      "photoUrl": "",
      "userId": "12962786962925949010"
     },
     "user_tz": -480
    },
    "id": "of3z0vWXf_ot"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "target_word = '覺得'\n",
    "word_sim = []\n",
    "# check each word in vocab its simi with target_Word\n",
    "\n",
    "target_word_vocab = nlp_zh.vocab[target_word]\n",
    "for w in vocab:\n",
    "    w_vocab = nlp_zh.vocab[w]\n",
    "    if w_vocab.vector is not None and np.count_nonzero(w_vocab.vector) and not w_vocab.is_ascii and not w_vocab.is_punct and w!=target_word:\n",
    "        word_sim.append((w, target_word_vocab.similarity(w_vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the top 10 words that are similar to the first near syn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "executionInfo": {
     "elapsed": 84717,
     "status": "ok",
     "timestamp": 1601945273516,
     "user": {
      "displayName": "Alvin Chen",
      "photoUrl": "",
      "userId": "12962786962925949010"
     },
     "user_tz": -480
    },
    "id": "-WKx6mtBf_ox",
    "outputId": "cceaf072-d970-4762-fd3d-cfca53aa59bf",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('覺', 0.84788847),\n",
       " ('其實', 0.79569775),\n",
       " ('會覺', 0.788269),\n",
       " ('以為', 0.78638524),\n",
       " ('感覺', 0.7840089),\n",
       " ('看來', 0.7798325),\n",
       " ('畢竟', 0.7633344),\n",
       " ('看起來', 0.7629494),\n",
       " ('因為', 0.7625315),\n",
       " ('討厭', 0.74918205)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(word_sim, key=lambda x:x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o6AEcMJmf_o0"
   },
   "source": [
    "Each `vocab` has several properties defined in *spacy* that are useful for filtering irrelevant words before computing the word similarities\n",
    "\n",
    "```{note}\n",
    "The Chinese spacy language model does not seem to include the word probability information.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "executionInfo": {
     "elapsed": 84704,
     "status": "ok",
     "timestamp": 1601945273517,
     "user": {
      "displayName": "Alvin Chen",
      "photoUrl": "",
      "userId": "12962786962925949010"
     },
     "user_tz": -480
    },
    "id": "ebOQqm_Df_o0",
    "outputId": "7c750e95-dfeb-4dad-da05-96102eb9335e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "#w.is_lower == word.is_lower and w.prob >= -15\n",
    "w1 = nlp_zh.vocab['覺得']\n",
    "w2 = nlp_zh.vocab['ship']\n",
    "\n",
    "print(w2.is_ascii)\n",
    "print(w2.is_currency)\n",
    "print(w2.is_punct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ICi4gX9f_o3"
   },
   "source": [
    "Define functions to extract top-N similar words\n",
    "\n",
    "- Functions taken from [this SO discussion thread](https://stackoverflow.com/questions/57697374/list-most-similar-words-in-spacy-in-pretrained-model)\n",
    "- Deal with the computation efficiency problems (big matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "executionInfo": {
     "elapsed": 84689,
     "status": "ok",
     "timestamp": 1601945273517,
     "user": {
      "displayName": "Alvin Chen",
      "photoUrl": "",
      "userId": "12962786962925949010"
     },
     "user_tz": -480
    },
    "id": "wRk4tR2Ff_o3"
   },
   "outputs": [],
   "source": [
    "import numba\n",
    "from numba import jit\n",
    "\n",
    "@jit(nopython=True)\n",
    "def cosine_similarity_numba(u:np.ndarray, v:np.ndarray):\n",
    "    assert(u.shape[0] == v.shape[0])\n",
    "    uv = 0\n",
    "    uu = 0\n",
    "    vv = 0\n",
    "    for i in range(u.shape[0]):\n",
    "        uv += u[i]*v[i]\n",
    "        uu += u[i]*u[i]\n",
    "        vv += v[i]*v[i]\n",
    "    cos_theta = 1\n",
    "    if uu != 0 and vv != 0:\n",
    "        cos_theta = uv/np.sqrt(uu*vv)\n",
    "    return cos_theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "executionInfo": {
     "elapsed": 84677,
     "status": "ok",
     "timestamp": 1601945273519,
     "user": {
      "displayName": "Alvin Chen",
      "photoUrl": "",
      "userId": "12962786962925949010"
     },
     "user_tz": -480
    },
    "id": "yQT9_566f_o6"
   },
   "outputs": [],
   "source": [
    "## Efficient version\n",
    "def most_similar_v1(word, topn=5):\n",
    "  word = nlp_zh.vocab[str(word)]\n",
    "  queries = [\n",
    "      w for w in nlp_zh.vocab \n",
    "      if np.count_nonzero(w.vector) and not w.is_ascii and not w.is_punct and len(w.text)==2\n",
    "  ]\n",
    "\n",
    "  #by_similarity = sorted(queries, key=lambda w: word.similarity(w), reverse=True)\n",
    "\n",
    "  by_similarity = sorted(queries, key=lambda w: cosine_similarity_numba(w.vector, word.vector), reverse=True)\n",
    "    \n",
    "    \n",
    "  return [(w.text,w.similarity(word)) for w in by_similarity[:topn+1] if w.text != word.text]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "executionInfo": {
     "elapsed": 84668,
     "status": "ok",
     "timestamp": 1601945273519,
     "user": {
      "displayName": "Alvin Chen",
      "photoUrl": "",
      "userId": "12962786962925949010"
     },
     "user_tz": -480
    },
    "id": "gYvlYlUqf_o9"
   },
   "outputs": [],
   "source": [
    "## Naive version\n",
    "\n",
    "def most_similar_v2(word, topn=5):\n",
    "  word = nlp_zh.vocab[str(word)]\n",
    "  queries = [\n",
    "      w for w in nlp_zh.vocab \n",
    "      if np.count_nonzero(w.vector) and not w.is_ascii and not w.is_punct and len(w.text)==2\n",
    "  ]\n",
    "\n",
    "  by_similarity = sorted(queries, key=lambda w: word.similarity(w), reverse=True)\n",
    "  #by_similarity = sorted(queries, key=lambda w: cosine_similarity_numba(w.vector, word.vector), reverse=True)\n",
    "\n",
    "  return [(w.text,w.similarity(word)) for w in by_similarity[:topn+1] if w.text != word.text]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tGfdzOdYUirv"
   },
   "source": [
    "Test the time needed in different versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "executionInfo": {
     "elapsed": 91851,
     "status": "ok",
     "timestamp": 1601945280718,
     "user": {
      "displayName": "Alvin Chen",
      "photoUrl": "",
      "userId": "12962786962925949010"
     },
     "user_tz": -480
    },
    "id": "NdNMqR_2f_pA",
    "outputId": "2885e91c-2a30-4488-f10e-72d266414f34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.42 s, sys: 309 ms, total: 7.73 s\n",
      "Wall time: 14.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('其實', 0.79569775), ('會覺', 0.788269), ('以為', 0.78638524)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "most_similar_v1(\"覺得\", topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "executionInfo": {
     "elapsed": 114432,
     "status": "ok",
     "timestamp": 1601945303318,
     "user": {
      "displayName": "Alvin Chen",
      "photoUrl": "",
      "userId": "12962786962925949010"
     },
     "user_tz": -480
    },
    "id": "K2mRkuQrf_pD",
    "outputId": "8452c679-965c-4022-c9c7-27211a4b6581"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.3 s, sys: 692 ms, total: 30 s\n",
      "Wall time: 29.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('其實', 0.79569775), ('會覺', 0.788269), ('以為', 0.78638524)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "most_similar_v2(\"覺得\", topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VbFtRBziUnE0"
   },
   "source": [
    "## Defining Nodes for the Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oh8ULMBff_pG"
   },
   "source": [
    "- Extract top 1000 similar words for each near-syn\n",
    "- These top 1000 context words will form the basis for the nodes of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 178427,
     "status": "ok",
     "timestamp": 1601945367322,
     "user": {
      "displayName": "Alvin Chen",
      "photoUrl": "",
      "userId": "12962786962925949010"
     },
     "user_tz": -480
    },
    "id": "P9s14dHyf_pH",
    "outputId": "e57b7a98-1bc4-4a9e-8359-477f78497e1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 8s, sys: 619 ms, total: 1min 9s\n",
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "near_syn_topn = dict([(w, most_similar_v1(w, topn=1000)) for w in near_syns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lbsra4nNf_pK"
   },
   "source": [
    "Top 10 similar words for each synonym in the list.\n",
    "\n",
    "For example, the top 10 similar words for 覺得:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "executionInfo": {
     "elapsed": 178419,
     "status": "ok",
     "timestamp": 1601945367323,
     "user": {
      "displayName": "Alvin Chen",
      "photoUrl": "",
      "userId": "12962786962925949010"
     },
     "user_tz": -480
    },
    "id": "edarwJNBf_pL",
    "outputId": "d7bc57a0-119d-4510-a9ba-893b432bb411",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('其實', 0.79569775),\n",
       " ('會覺', 0.788269),\n",
       " ('以為', 0.78638524),\n",
       " ('感覺', 0.7840089),\n",
       " ('看來', 0.7798325),\n",
       " ('畢竟', 0.7633344),\n",
       " ('因為', 0.7625315),\n",
       " ('討厭', 0.74918205),\n",
       " ('總覺', 0.743788),\n",
       " ('們覺', 0.74213)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "near_syn_topn[near_syns[0]][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fvF921fbU86d"
   },
   "source": [
    "Convert the tuples into a list, which is easier to be imported into the graph structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "executionInfo": {
     "elapsed": 178410,
     "status": "ok",
     "timestamp": 1601945367323,
     "user": {
      "displayName": "Alvin Chen",
      "photoUrl": "",
      "userId": "12962786962925949010"
     },
     "user_tz": -480
    },
    "id": "TfrJiArVf_pO"
   },
   "outputs": [],
   "source": [
    "near_syn_topn_list = []\n",
    "for w, s in near_syn_topn.items():\n",
    "    for s_w, s_s in s:\n",
    "        near_syn_topn_list.append((w, s_w, s_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "executionInfo": {
     "elapsed": 178397,
     "status": "ok",
     "timestamp": 1601945367324,
     "user": {
      "displayName": "Alvin Chen",
      "photoUrl": "",
      "userId": "12962786962925949010"
     },
     "user_tz": -480
    },
    "id": "kAbBFyWHf_pR",
    "outputId": "262e5931-4914-4a46-d1f5-da4e33cdb9d2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('覺得', '其實', 0.79569775), ('覺得', '會覺', 0.788269), ('覺得', '以為', 0.78638524), ('覺得', '感覺', 0.7840089), ('覺得', '看來', 0.7798325), ('覺得', '畢竟', 0.7633344), ('覺得', '因為', 0.7625315), ('覺得', '討厭', 0.74918205), ('覺得', '總覺', 0.743788), ('覺得', '們覺', 0.74213)]\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(near_syn_topn_list[:10])\n",
    "print(len(near_syn_topn_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "executionInfo": {
     "elapsed": 178387,
     "status": "ok",
     "timestamp": 1601945367325,
     "user": {
      "displayName": "Alvin Chen",
      "photoUrl": "",
      "userId": "12962786962925949010"
     },
     "user_tz": -480
    },
    "id": "letAzvgaf_pT",
    "outputId": "f6e13f6a-d987-4676-9b3e-222800f9fdf6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "      <th>sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>覺得</td>\n",
       "      <td>其實</td>\n",
       "      <td>0.795698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>覺得</td>\n",
       "      <td>會覺</td>\n",
       "      <td>0.788269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>覺得</td>\n",
       "      <td>以為</td>\n",
       "      <td>0.786385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>覺得</td>\n",
       "      <td>感覺</td>\n",
       "      <td>0.784009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>覺得</td>\n",
       "      <td>看來</td>\n",
       "      <td>0.779832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9069</th>\n",
       "      <td>主張</td>\n",
       "      <td>方針</td>\n",
       "      <td>0.602148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9070</th>\n",
       "      <td>主張</td>\n",
       "      <td>這與</td>\n",
       "      <td>0.601582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9071</th>\n",
       "      <td>主張</td>\n",
       "      <td>迴避</td>\n",
       "      <td>0.601496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9072</th>\n",
       "      <td>主張</td>\n",
       "      <td>體制</td>\n",
       "      <td>0.601390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9073</th>\n",
       "      <td>主張</td>\n",
       "      <td>意見</td>\n",
       "      <td>0.601044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>669 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      w1  w2       sim\n",
       "0     覺得  其實  0.795698\n",
       "1     覺得  會覺  0.788269\n",
       "2     覺得  以為  0.786385\n",
       "3     覺得  感覺  0.784009\n",
       "4     覺得  看來  0.779832\n",
       "...   ..  ..       ...\n",
       "9069  主張  方針  0.602148\n",
       "9070  主張  這與  0.601582\n",
       "9071  主張  迴避  0.601496\n",
       "9072  主張  體制  0.601390\n",
       "9073  主張  意見  0.601044\n",
       "\n",
       "[669 rows x 3 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(near_syn_topn_list,columns=['w1','w2','sim'])\n",
    "df[df['sim']>0.6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SjCXlsa6VDRd"
   },
   "source": [
    "## Define Connections in-between Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j02t2B0gigXd"
   },
   "source": [
    "- While context nodes have already had connections (i.e., edges) to the key nodes (i.e., near-syns), these context nodes may themselves be inter-connected due to their semantic similarity\n",
    "- We again utilize the `spacy` language model to determine their semantic similarities.\n",
    "- These similarities serve as the basis for the edges of the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6E5OGrmLjHCe"
   },
   "source": [
    "We first identify all potential nodes for the network and then compute their pairwise similarities based on `spacy` Glove embeddings.\n",
    "\n",
    "- `nodes_id`: include all the possible nodes of the graph.\n",
    "- `edges_df`: include all the context-key and context-context edges of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 182475,
     "status": "ok",
     "timestamp": 1601945371424,
     "user": {
      "displayName": "Alvin Chen",
      "photoUrl": "",
      "userId": "12962786962925949010"
     },
     "user_tz": -480
    },
    "id": "4KLdrZzGisYr",
    "outputId": "b0411032-30d9-4d81-d046-18bdbe461734"
   },
   "outputs": [],
   "source": [
    "WORD_SIMILARITY_CUTOFF = 0.65 # collexemes and target words\n",
    "df2 = df[df['sim'] > WORD_SIMILARITY_CUTOFF]\n",
    "nodes_id = list(set(list(df2['w2'].values) + list(df2['w1'].values)))\n",
    "\n",
    "# nodes_similarities = pairwise_similarity(nodes_id, nlp_zh)\n",
    "# nodes_similarities_df = pd.DataFrame(nodes_similarities, index=nodes_id,columns=nodes_id)\n",
    "# nodes_similarities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 182475,
     "status": "ok",
     "timestamp": 1601945371424,
     "user": {
      "displayName": "Alvin Chen",
      "photoUrl": "",
      "userId": "12962786962925949010"
     },
     "user_tz": -480
    },
    "id": "4KLdrZzGisYr",
    "outputId": "b0411032-30d9-4d81-d046-18bdbe461734"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180\n",
      "(582, 3)\n"
     ]
    }
   ],
   "source": [
    "## Creating nodes pairwise similarity matrix\n",
    "print(len(nodes_id))\n",
    "m = len(nodes_id)\n",
    "distances = np.zeros((m,m))\n",
    "\n",
    "for i in range(m):\n",
    "    for j in range(m):  \n",
    "        distances[i,j] = nlp_zh.vocab[nodes_id[i]].similarity(nlp_zh.vocab[nodes_id[j]])\n",
    "\n",
    "## Flattening the matrix\n",
    "EMBEDDING_CUTOFF = 0.75\n",
    "\n",
    "#print(node_names)\n",
    "distances_flat = []\n",
    "\n",
    "for i in range(m):\n",
    "    for j in range(m):\n",
    "        if distances[i,j]> EMBEDDING_CUTOFF and i != j:\n",
    "            distances_flat.append((nodes_id[i], nodes_id[j], distances[i,j]))\n",
    "\n",
    "edges_df = pd.DataFrame(distances_flat, columns=['w1','w2','sim'])\n",
    "print(edges_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1lBoqioYWRIf"
   },
   "source": [
    "We then combine the context-key edges with the context-context edges. These edges are the final edges for the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 693
    },
    "executionInfo": {
     "elapsed": 182465,
     "status": "ok",
     "timestamp": 1601945371425,
     "user": {
      "displayName": "Alvin Chen",
      "photoUrl": "",
      "userId": "12962786962925949010"
     },
     "user_tz": -480
    },
    "id": "rv0dNcoQf_pl",
    "outputId": "1634e875-a091-4c00-c251-a077118f6be3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(785, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "      <th>sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>這樣</td>\n",
       "      <td>因為</td>\n",
       "      <td>0.799578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>這樣</td>\n",
       "      <td>還是</td>\n",
       "      <td>0.754334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>這樣</td>\n",
       "      <td>同樣</td>\n",
       "      <td>0.791491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>這樣</td>\n",
       "      <td>這個</td>\n",
       "      <td>0.851545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>這樣</td>\n",
       "      <td>應該</td>\n",
       "      <td>0.806186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>這樣</td>\n",
       "      <td>其實</td>\n",
       "      <td>0.807909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>這樣</td>\n",
       "      <td>畢竟</td>\n",
       "      <td>0.771049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>這樣</td>\n",
       "      <td>這點</td>\n",
       "      <td>0.763548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>這樣</td>\n",
       "      <td>沒有</td>\n",
       "      <td>0.756848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>這樣</td>\n",
       "      <td>當然</td>\n",
       "      <td>0.778150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>這樣</td>\n",
       "      <td>確實</td>\n",
       "      <td>0.770117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>這樣</td>\n",
       "      <td>本來</td>\n",
       "      <td>0.769549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>這樣</td>\n",
       "      <td>這麼</td>\n",
       "      <td>0.816209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>所謂</td>\n",
       "      <td>其實</td>\n",
       "      <td>0.751369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>所謂</td>\n",
       "      <td>並非</td>\n",
       "      <td>0.758192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>納悶</td>\n",
       "      <td>驚訝</td>\n",
       "      <td>0.788380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>納悶</td>\n",
       "      <td>訝異</td>\n",
       "      <td>0.826738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>還是</td>\n",
       "      <td>總之</td>\n",
       "      <td>0.761258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>還是</td>\n",
       "      <td>因為</td>\n",
       "      <td>0.808997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>還是</td>\n",
       "      <td>總是</td>\n",
       "      <td>0.821862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>還是</td>\n",
       "      <td>這樣</td>\n",
       "      <td>0.754334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     w1  w2       sim\n",
       "100  這樣  因為  0.799578\n",
       "101  這樣  還是  0.754334\n",
       "102  這樣  同樣  0.791491\n",
       "103  這樣  這個  0.851545\n",
       "104  這樣  應該  0.806186\n",
       "105  這樣  其實  0.807909\n",
       "106  這樣  畢竟  0.771049\n",
       "107  這樣  這點  0.763548\n",
       "108  這樣  沒有  0.756848\n",
       "109  這樣  當然  0.778150\n",
       "110  這樣  確實  0.770117\n",
       "111  這樣  本來  0.769549\n",
       "112  這樣  這麼  0.816209\n",
       "113  所謂  其實  0.751369\n",
       "114  所謂  並非  0.758192\n",
       "115  納悶  驚訝  0.788380\n",
       "116  納悶  訝異  0.826738\n",
       "117  還是  總之  0.761258\n",
       "118  還是  因為  0.808997\n",
       "119  還是  總是  0.821862\n",
       "120  還是  這樣  0.754334"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_df = edges_df.append(df2).drop_duplicates()\n",
    "print(edges_df.shape)\n",
    "edges_df.loc[100:120,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bJ4vchff_pW"
   },
   "source": [
    "## Creating a Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wWcy1NjGW7pn"
   },
   "source": [
    "- We use `networkx` to first create a graph and compute relevant node-level metrics, e.g., centralities.\n",
    "- We then create two data frames for aesthetic specification of the graph:\n",
    "  - `nodes_df`\n",
    "  - `edges_df`\n",
    "- We use `pyvis` to visualizae the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "executionInfo": {
     "elapsed": 182928,
     "status": "ok",
     "timestamp": 1601945371897,
     "user": {
      "displayName": "Alvin Chen",
      "photoUrl": "",
      "userId": "12962786962925949010"
     },
     "user_tz": -480
    },
    "id": "tMkaVE2of_pW"
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "#import pyvis.options as options\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "#from scipy.spatial.distance import cosine\n",
    "#G = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "executionInfo": {
     "elapsed": 981,
     "status": "ok",
     "timestamp": 1601946309244,
     "user": {
      "displayName": "Alvin Chen",
      "photoUrl": "",
      "userId": "12962786962925949010"
     },
     "user_tz": -480
    },
    "id": "8oivHFLpf_pq"
   },
   "outputs": [],
   "source": [
    "## A function to rescale metrics for plotting\n",
    "def myRescaler(x):\n",
    "    x = np.array(x)\n",
    "    y = np.interp(x, (x.min(), x.max()), (5, 20))\n",
    "    return list(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3kTOXbepXNj4"
   },
   "source": [
    "Create `nodes_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "executionInfo": {
     "elapsed": 1737,
     "status": "ok",
     "timestamp": 1601946310012,
     "user": {
      "displayName": "Alvin Chen",
      "photoUrl": "",
      "userId": "12962786962925949010"
     },
     "user_tz": -480
    },
    "id": "WopuFYt5f_ps"
   },
   "outputs": [],
   "source": [
    "G= nx.from_pandas_edgelist(edges_df, 'w1','w2','sim')\n",
    "\n",
    "nodes_df = pd.DataFrame({'id':list(G.nodes),\n",
    "                         'betweenness': myRescaler(list(nx.betweenness_centrality(G).values())),\n",
    "                         'eigenvector': myRescaler(list(nx.eigenvector_centrality(G).values()))})\n",
    "nodes_df['size']=[5 if i not in near_syns else 10 for i in nodes_id]\n",
    "nodes_df['size2']= [i if i not in near_syns else 30 for i in nodes_df['eigenvector']]\n",
    "nodes_df['group'] = ['KEY' if nodes_df.loc[i,'id'] in near_syns else 'CONTEXT' for i in range(nodes_df.shape[0])]\n",
    "nodes_df['color'] = ['lightpink' if nodes_df.loc[i,'group']=='KEY' else 'lightblue' for i in range(nodes_df.shape[0])]\n",
    "nodes_df['borderWidthSelected'] = list(np.repeat(20.0, nodes_df.shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wZ_HMnrdf_p2"
   },
   "source": [
    "## Visualizing a Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1SQT4uCUXlA5"
   },
   "source": [
    "Plotting the network using `pyvis`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "executionInfo": {
     "elapsed": 2232,
     "status": "ok",
     "timestamp": 1601946772006,
     "user": {
      "displayName": "Alvin Chen",
      "photoUrl": "",
      "userId": "12962786962925949010"
     },
     "user_tz": -480
    },
    "id": "QLlZoPtdf_py"
   },
   "outputs": [],
   "source": [
    "Gvis = Network(\"768px\",\"1600px\", notebook=False,heading=\"Semantic Network\")\n",
    "# # Gvis.from_nx(G)\n",
    "edges_in = list(edges_df.to_records(index=False))\n",
    "#Gvis.add_nodes(list(G.nodes), value=nodes_df['size2'], color=nodes_df['color'], borderWidthSelected = nodes_df['borderWidthSelected'])\n",
    "\n",
    "for i in range(nodes_df.shape[0]):\n",
    "  Gvis.add_node(list(G.nodes)[i], value=nodes_df.loc[i,'size2'], group=nodes_df.loc[i,'group'])#, color=nodes_df.loc[i,'color'], borderWidthSelected = nodes_df.loc[i,'borderWidthSelected'])\n",
    "\n",
    "Gvis.add_edges(edges_in)\n",
    "#Gvis.show_buttons()\n",
    "Gvis.set_options(\"\"\"\n",
    "  var options = {\n",
    "    \"nodes\": {\n",
    "      \"borderWidth\": 0,\n",
    "      \"color\": {\n",
    "        \"highlight\": {\n",
    "          \"border\": \"rgba(221,171,197,1)\",\n",
    "          \"background\": \"rgba(248,178,255,1)\"\n",
    "        }\n",
    "      },\n",
    "      \"shadow\": {\n",
    "        \"enabled\": true\n",
    "      }\n",
    "    },\n",
    "    \"edges\": {\n",
    "      \"color\": {\n",
    "        \"highlight\": \"rgba(255,192,200,1)\",\n",
    "        \"inherit\": false\n",
    "      },\n",
    "      \"smooth\": false\n",
    "    },\n",
    "    \"interaction\": {\n",
    "      \"hover\": true,\n",
    "      \"navigationButtons\": true\n",
    "    },\n",
    "    \"manipulation\": {\n",
    "      \"enabled\": true\n",
    "    },\n",
    "    \"physics\": {\n",
    "      \"barnesHut\": {\n",
    "        \"springLength\": 270\n",
    "      },\n",
    "      \"minVelocity\": 0.75\n",
    "    }\n",
    "  }\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "  # groups: {\n",
    "  #   myGroup: {color:{background:'red'}, borderWidth:3}\n",
    "  # }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "executionInfo": {
     "elapsed": 2222,
     "status": "ok",
     "timestamp": 1601946772007,
     "user": {
      "displayName": "Alvin Chen",
      "photoUrl": "",
      "userId": "12962786962925949010"
     },
     "user_tz": -480
    },
    "id": "-xioFj_lf_p0",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Gvis.show(DEMO_DATA_ROOT + '/reporting_verbs_chinese_Gvis.html')\n",
    "edges_df.to_pickle(DEMO_DATA_ROOT+'/reporting_verbs_chinese_edges_df.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJnNYV8GNkc5"
   },
   "source": [
    "## References\n",
    "\n",
    "- [`vis.js` Documentation](https://visjs.github.io/vis-network/docs/network/index.html)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "network-analysis.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "python-notes",
   "language": "python",
   "name": "python-notes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}