{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dov2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TaggedDocument Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Alvin/opt/anaconda3/envs/ckiptagger/lib/python3.6/site-packages/gensim/test/test_data\n",
      "/Users/Alvin/opt/anaconda3/envs/ckiptagger/lib/python3.6/site-packages/gensim/test/test_data/lee_background.cor\n",
      "/Users/Alvin/opt/anaconda3/envs/ckiptagger/lib/python3.6/site-packages/gensim/test/test_data/lee.cor\n"
     ]
    }
   ],
   "source": [
    "import os, gensim\n",
    "# LEE corpus\n",
    "test_data_dir = '{}'.format(os.sep).join([gensim.__path__[0], 'test', 'test_data'])\n",
    "lee_train_file = test_data_dir + os.sep + 'lee_background.cor'\n",
    "lee_test_file = test_data_dir + os.sep + 'lee.cor'\n",
    "\n",
    "print(test_data_dir)\n",
    "print(lee_train_file)\n",
    "print(lee_test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Alvin/opt/anaconda3/envs/ckiptagger/lib/python3.6/site-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "import smart_open\n",
    "\n",
    "def read_corpus(file_name, tokens_only=False):\n",
    "    with smart_open.smart_open(file_name) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if tokens_only:\n",
    "                yield gensim.utils.simple_preprocess(line)\n",
    "            else:\n",
    "                # For training data, add tags\n",
    "                yield gensim.models.doc2vec.TaggedDocument(gensim.utils.simple_preprocess(line), [i])\n",
    "\n",
    "train_corpus = list(read_corpus(lee_train_file))\n",
    "test_corpus = list(read_corpus(lee_test_file, tokens_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TaggedDocument Format\n",
    "\n",
    "- TaggedDocument(words = List(toke, token,...), tags = int())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['the', 'national', 'road', 'toll', 'for', 'the', 'christmas', 'new', 'year', 'holiday', 'period', 'stands', 'at', 'eight', 'fewer', 'than', 'for', 'the', 'same', 'time', 'last', 'year', 'people', 'have', 'died', 'on', 'new', 'south', 'wales', 'roads', 'with', 'eight', 'fatalities', 'in', 'both', 'queensland', 'and', 'victoria', 'western', 'australia', 'the', 'northern', 'territory', 'and', 'south', 'australia', 'have', 'each', 'recorded', 'three', 'deaths', 'while', 'the', 'act', 'and', 'tasmania', 'remain', 'fatality', 'free'], tags=[2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_corpus[2]\n",
    "\n",
    "## A TaggedDocument(List of Word Tokens, Int of Tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Alvin/.local/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.1 s, sys: 655 ms, total: 11.7 s\n",
      "Wall time: 6.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from gensim.models import Doc2Vec\n",
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=100)\n",
    "model.build_vocab(train_corpus) \n",
    "model.train(train_corpus, total_examples=model.corpus_count, epochs=model.iter)\n",
    "\n",
    "models = [\n",
    "    # PV-DBOW (Skip-Gram equivalent of Word2Vec)\n",
    "    Doc2Vec(dm=0, dbow_words=1, vector_size=200, window=8, min_count=10, epochs=50),\n",
    "    \n",
    "    # PV-DM w/average (CBOW equivalent of Word2Vec)\n",
    "    Doc2Vec(dm=1, dm_mean=1, vector_size=200, window=8, min_count=10, epochs =50),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenated Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train both PV-DBOW and PV-DM and combine the two\n",
    "\n",
    "documents = train_corpus\n",
    "models[0].build_vocab(documents)\n",
    "models[1].reset_from(models[0])\n",
    "\n",
    "for model in models:\n",
    "   model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "new_model = ConcatenatedDoc2Vec((models[0], models[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.9507645964622498), (255, 0.8500384092330933), (48, 0.8422250747680664), (40, 0.8407660126686096), (272, 0.8056083917617798), (8, 0.7634897828102112), (33, 0.7134690284729004), (264, 0.7049052119255066), (10, 0.689674973487854), (9, 0.6800381541252136)]\n"
     ]
    }
   ],
   "source": [
    "inferred_vector = model.infer_vector(train_corpus[0].words)\n",
    "sims = model.docvecs.most_similar([inferred_vector])\n",
    "print(sims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "A thread on how to use `most_similar()` with `ConcatenatedDoc2Vec`: [link](https://stackoverflow.com/questions/54186233/doc2vec-infer-most-similar-vector-from-concatenateddocvecs)\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.9400014281272888), (33, 0.4663400948047638), (48, 0.4372784495353699), (40, 0.42385679483413696), (189, 0.3942781090736389), (264, 0.36402449011802673), (8, 0.3557724356651306), (46, 0.34546542167663574), (181, 0.3342496156692505), (255, 0.3305847644805908)]\n",
      "[(0, 0.9460863471031189), (255, 0.8562828302383423), (40, 0.8317067623138428), (48, 0.829282283782959), (272, 0.8040825724601746), (8, 0.7400796413421631), (33, 0.6973906755447388), (264, 0.6955726146697998), (10, 0.6760033369064331), (9, 0.6593033075332642)]\n"
     ]
    }
   ],
   "source": [
    "# model 1\n",
    "inferred_vector =new_model.models[0].infer_vector(train_corpus[0].words)\n",
    "sims2 = new_model.models[0].docvecs.most_similar([inferred_vector])\n",
    "print(sims2)\n",
    "# model 2\n",
    "inferred_vector =new_model.models[1].infer_vector(train_corpus[0].words)\n",
    "sims3 = new_model.models[1].docvecs.most_similar([inferred_vector])\n",
    "print(sims3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hundreds of people have been forced to vacate their homes in the southern highlands of new south wales as strong winds today pushed huge bushfire towards the town of hill top new blaze near goulburn south west of sydney has forced the closure of the hume highway at about pm aedt marked deterioration in the weather as storm cell moved east across the blue mountains forced authorities to make decision to evacuate people from homes in outlying streets at hill top in the new south wales southern highlands an estimated residents have left their homes for nearby mittagong the new south wales rural fire service says the weather conditions which caused the fire to burn in finger formation have now eased and about fire units in and around hill top are optimistic of defending all properties as more than blazes burn on new year eve in new south wales fire crews have been called to new fire at gunning south of goulburn while few details are available at this stage fire authorities says it has closed the hume highway in both directions meanwhile new fire in sydney west is no longer threatening properties in the cranebrook area rain has fallen in some parts of the illawarra sydney the hunter valley and the north coast but the bureau of meteorology claire richards says the rain has done little to ease any of the hundred fires still burning across the state the falls have been quite isolated in those areas and generally the falls have been less than about five millimetres she said in some places really not significant at all less than millimetre so there hasn been much relief as far as rain is concerned in fact they ve probably hampered the efforts of the firefighters more because of the wind gusts that are associated with those thunderstorms\n",
      "\n",
      "the new south wales state emergency service ses says it has now received calls for help in the wake of monday fierce storms natural disaster areas have been declared throughout sydney and surrounding areas and parts of the state north west in sydney more than homes mainly in the northern suburbs remain without power ses spokeswoman laura goodin says several hundred volunteers will be back in the field this morning we ve had about calls for help of which we ve completed about two thirds we ve had about volunteers in the field being helped out by the royal fire service and the new south wales fire brigades and we re expecting to have most jobs completed by about friday ms goodin said the extensive storm damage has prompted warning about people falsely claiming to work for the ses the warning from fair trading minister john aquilina follows reports from the suburb of hornsby that people claiming to work for the ses are asking for payment from the storm victims mr aquilina has reminded householders that the ses is volunteer organisation and does not charge for its work or employ sub contractors he has suggested residents contact the police if they are approached by such people the government is also warning householders against dealing with unlicensed tradespeople\n",
      "\n",
      "new south wales firefighters are hoping lighter winds will help ease their workload today but are predicting nasty conditions over the weekend while the winds are expected to ease somewhat today the weather bureau says temperatures will be higher more than fires are still burning across new south wales the rural fire service says the change may allow it to concentrate more on preventative action but there is no room for complacency mark sullivan from the rural fire service says while conditions may be little kinder to them today the outlook for the weekend has them worried it certainly appears from the weather forecast with very high temperatures and high winds that it certainly could be nasty couple of days ahead mr sullivan said one of the areas causing greatest concern today is the kilometre long blaze in the lower blue mountains firefighters are also keeping close eye on blaze at spencer north of sydney which yesterday broke through containment lines there are concerns that fire may jump the hawkesbury river backburning continues in the state central west and south of sydney in the shoalhaven in the illawarra firefighters have been able to carry out back burning operations in three areas operations were carried out in parts of mt kembla as well as an area bounded by appin road and the old princes highway at helensburgh an area west of windy gully near cataract dam was also targeted meanwhile illawarra police have arrested three teenagers in relation to bushfires at shellharbour on the south coast of new south wales spokesman says three small fires were extinguished around pm aedt yesterday short time later police arrested three year old boys from shellharbour barrack heights and shell cove all three have been interviewed but no charges have been laid\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Doc 1 seems most similar to Doc 255?\n",
    "print(' '.join(train_corpus[0][0])+'\\n')\n",
    "print(' '.join(train_corpus[255][0])+'\\n')\n",
    "print(' '.join(train_corpus[33][0])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Other vector models \n",
    "\n",
    "# # glove\n",
    "\n",
    "# from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "# glove_input_file = 'glove.6B.100d.txt'\n",
    "# word2vec_output_file = 'glove.6B.100d.txt.word2vec'\n",
    "# glove2word2vec(glove_input_file, word2vec_output_file)\n",
    "\n",
    "# from gensim.models import KeyedVectors\n",
    "# filename = 'glove.6B.100d.txt.word2vec'\n",
    "# model = KeyedVectors.load_word2vec_format(filename, binary=False)\n",
    "\n",
    "# model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n",
    "\n",
    "# from gensim.models.fasttext import FastText\n",
    "\n",
    "# ft_model = FastText(size=100)\n",
    "# ft_model.build_vocab(data)\n",
    "# model_gensim.train(data, total_examples=ft_model.corpus_count, epochs=ft_model.iter)\n",
    "\n",
    "\n",
    "# from gensim.models.wrappers.fasttext import FastText\n",
    "\n",
    "# # Set FastText home to the path to the FastText executable\n",
    "# ft_home = '/home/bhargav/Gensim/fastText/fasttext'\n",
    "# # train the model\n",
    "# model_wrapper = FastText.train(ft_home, train_file)\n",
    "\n",
    "# print('dog' in model.wv.vocab)\n",
    "# print('dogs' in model.wv.vocab)\n",
    "\n",
    "# print('dog' in model)\n",
    "# print('dogs' in model)\n",
    "\n",
    "# from gensim.models.wrappers import Wordrank\n",
    "\n",
    "# wordrank_path = 'wordrank' # path to Wordrank directory\n",
    "# out_dir = 'model' # name of output directory to save data to\n",
    "# data = '../../gensim/test/test_data/lee.cor' # sample corpus\n",
    "\n",
    "# model = Wordrank.train(wordrank_path, data, out_dir, iter=21, dump_period=10)\n",
    "\n",
    "\n",
    "# varembed_vectors = '../../gensim/test/test_data/varembed_leecorpus_vectors.pkl'\n",
    "# model = varembed.VarEmbed.load_varembed_format(vectors=varembed_vectors)\n",
    "\n",
    "\n",
    "# morfessors = '../../gensim/test/test_data/varembed_leecorpus_morfessor.bin'\n",
    "# model = varembed.VarEmbed.load_varembed_format(vectors=varembed_vectors, morfessor_model=morfessors)\n",
    "\n",
    "# import os\n",
    "\n",
    "# poincare_directory = os.path.join(os.getcwd(), 'docs', 'notebooks', 'poincare')\n",
    "# data_directory = os.path.join(poincare_directory, 'data')\n",
    "# wordnet_mammal_file = os.path.join(data_directory, 'wordnet_mammal_hypernyms.tsv')\n",
    "\n",
    "# from gensim.models.poincare import PoincareModel, PoincareKeyedVectors, PoincareRelations\n",
    "# relations = PoincareRelations(file_path=wordnet_mammal_file, delimiter='\\t')\n",
    "# model = PoincareModel(train_data=relations, size=2, burn_in=0)\n",
    "# model.train(epochs=1, print_every=500)\n",
    "\n",
    "# models_directory = os.path.join(poincare_directory, 'models')\n",
    "# test_model_path = os.path.join(models_directory, 'gensim_model_batch_size_10_burn_in_0_epochs_50_neg_20_dim_50')\n",
    "# model = PoincareModel.load(test_model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ckiptagger",
   "language": "python",
   "name": "ckiptagger"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}