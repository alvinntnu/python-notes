{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Tool-Kits (NLTK)\n",
    "\n",
    "- The almightly `nltk` package!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install\n",
    "\n",
    "- Install package in terminal\n",
    "```\n",
    "!pip install nltk\n",
    "```\n",
    "- Download nltk data in python\n",
    "```\n",
    "import nltk\n",
    "nltk.download('all', halt_on_error=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('all', halt_on_error=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpora Data\n",
    "\n",
    "- The package includes a lot of pre-loaded corpora datasets\n",
    "- The default `nltk_data` directory is in `/Users/YOUT_NAME/nltk_data/`\n",
    "- Selective Examples\n",
    "    - Brown Corpus\n",
    "    - Reuters Corpus\n",
    "    - WordNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brown Corpus Total Categories:  15\n",
      "Categories List:  ['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg, brown, reuters\n",
    "\n",
    "# brown corpus\n",
    "## Categories (topics?)\n",
    "print('Brown Corpus Total Categories: ', len(brown.categories()))\n",
    "print('Categories List: ', brown.categories())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.']\n",
      "[['Thirty-three'], ['Scotty', 'did', 'not', 'go', 'back', 'to', 'school', '.'], ...]\n"
     ]
    }
   ],
   "source": [
    "# Sentences\n",
    "print(brown.sents()[0]) ## first sentence\n",
    "print(brown.sents(categories='fiction')) ## first sentence for fiction texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'AT'), ('Fulton', 'NP-TL'), ('County', 'NN-TL'), ('Grand', 'JJ-TL'), ('Jury', 'NN-TL'), ('said', 'VBD'), ('Friday', 'NR'), ('an', 'AT'), ('investigation', 'NN'), ('of', 'IN'), (\"Atlanta's\", 'NP$'), ('recent', 'JJ'), ('primary', 'NN'), ('election', 'NN'), ('produced', 'VBD'), ('``', '``'), ('no', 'AT'), ('evidence', 'NN'), (\"''\", \"''\"), ('that', 'CS'), ('any', 'DTI'), ('irregularities', 'NNS'), ('took', 'VBD'), ('place', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "## Tagged Sentences\n",
    "print(brown.tagged_sents()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Scotty did not go back to school .',\n",
       " 'His parents talked seriously and lengthily to their own doctor and to a specialist at the University Hospital -- Mr. McKinley was entitled to a discount for members of his family -- and it was decided it would be best for him to take the remainder of the term off , spend a lot of time in bed and , for the rest , do pretty much as he chose -- provided , of course , he chose to do nothing too exciting or too debilitating .',\n",
       " 'His teacher and his school principal were conferred with and everyone agreed that , if he kept up with a certain amount of work at home , there was little danger of his losing a term .',\n",
       " 'Scotty accepted the decision with indifference and did not enter the arguments .']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Sentence in natural forms\n",
    "sents = brown.sents(categories='fiction')\n",
    "[' '.join(sent) for sent in sents[1:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Scotty', 'NP'),\n",
       " ('school', 'NN'),\n",
       " ('parents', 'NNS'),\n",
       " ('doctor', 'NN'),\n",
       " ('specialist', 'NN'),\n",
       " ('University', 'NN-TL'),\n",
       " ('Hospital', 'NN-TL'),\n",
       " ('Mr.', 'NP'),\n",
       " ('McKinley', 'NP'),\n",
       " ('discount', 'NN')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get tagged words\n",
    "tagged_words = brown.tagged_words(categories='fiction')\n",
    "\n",
    "#print(tagged_words[1]) ## a tuple\n",
    "\n",
    "## Get all nouns \n",
    "nouns = [(word, tag) for word, tag in tagged_words \n",
    "                      if any (noun_tag in tag for noun_tag in ['NP','NN'])]\n",
    "## Check first ten nouns\n",
    "nouns[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('man', 111),\n",
       " ('time', 99),\n",
       " ('men', 72),\n",
       " ('room', 63),\n",
       " ('way', 62),\n",
       " ('eyes', 60),\n",
       " ('face', 55),\n",
       " ('house', 54),\n",
       " ('head', 54),\n",
       " ('night', 53),\n",
       " ('day', 52),\n",
       " ('hand', 50),\n",
       " ('door', 47),\n",
       " ('life', 44),\n",
       " ('years', 44),\n",
       " ('Mrs.', 41),\n",
       " ('God', 41),\n",
       " ('Kate', 40),\n",
       " ('Mr.', 39),\n",
       " ('people', 39)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creating Freq list\n",
    "nouns_freq = nltk.FreqDist([w for w, t in nouns])\n",
    "sorted(nouns_freq.items(),key=lambda x:x[1], reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('zoo', 2),\n",
       " ('zlotys', 1),\n",
       " ('zenith', 1),\n",
       " ('youth', 5),\n",
       " ('yelling', 1),\n",
       " ('years', 44),\n",
       " ('yearning', 1),\n",
       " (\"year's\", 1),\n",
       " ('year', 9),\n",
       " ('yards', 4),\n",
       " ('yard', 7),\n",
       " ('yachts', 1),\n",
       " ('writing', 2),\n",
       " ('writers', 1),\n",
       " ('writer', 4),\n",
       " ('wrists', 1),\n",
       " ('wrist', 2),\n",
       " ('wrinkles', 1),\n",
       " ('wrinkle', 1),\n",
       " ('wretch', 1)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(nouns_freq.items(),key=lambda x:x[0], reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('man', 111),\n",
       " ('time', 99),\n",
       " ('men', 72),\n",
       " ('room', 63),\n",
       " ('way', 62),\n",
       " ('eyes', 60),\n",
       " ('face', 55),\n",
       " ('house', 54),\n",
       " ('head', 54),\n",
       " ('night', 53)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns_freq.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Thirty-three'], ['Scotty', 'did', 'not', 'go', 'back', 'to', 'school', '.'], ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Accsess data via fileid\n",
    "brown.fileids(categories='fiction')[0]\n",
    "brown.sents(fileids='ck01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WordNet\n",
    "\n",
    "- A dictionary resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('walk.n.01'),\n",
       " Synset('base_on_balls.n.01'),\n",
       " Synset('walk.n.03'),\n",
       " Synset('walk.n.04'),\n",
       " Synset('walk.n.05'),\n",
       " Synset('walk.n.06'),\n",
       " Synset('walk_of_life.n.01'),\n",
       " Synset('walk.v.01'),\n",
       " Synset('walk.v.02'),\n",
       " Synset('walk.v.03'),\n",
       " Synset('walk.v.04'),\n",
       " Synset('walk.v.05'),\n",
       " Synset('walk.v.06'),\n",
       " Synset('walk.v.07'),\n",
       " Synset('walk.v.08'),\n",
       " Synset('walk.v.09'),\n",
       " Synset('walk.v.10')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "word = 'walk'\n",
    "\n",
    "# get synsets\n",
    "word_synsets = wn.synsets(word)\n",
    "word_synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syset ID: walk.v.01 \n",
      "POS Tag: v \n",
      "Definition: use one's feet to advance; advance by steps \n",
      "Examples: [\"Walk, don't run!\", 'We walked instead of driving', 'She walks with a slight limp', 'The patient cannot walk yet', 'Walk over to the cabinet'] \n",
      "\n",
      "Syset ID: walk.v.02 \n",
      "POS Tag: v \n",
      "Definition: accompany or escort \n",
      "Examples: [\"I'll walk you to your car\"] \n",
      "\n",
      "Syset ID: walk.v.03 \n",
      "POS Tag: v \n",
      "Definition: obtain a base on balls \n",
      "Examples: [] \n",
      "\n",
      "Syset ID: walk.v.04 \n",
      "POS Tag: v \n",
      "Definition: traverse or cover by walking \n",
      "Examples: ['Walk the tightrope', 'Paul walked the streets of Damascus', 'She walks 3 miles every day'] \n",
      "\n",
      "Syset ID: walk.v.05 \n",
      "POS Tag: v \n",
      "Definition: give a base on balls to \n",
      "Examples: [] \n",
      "\n",
      "Syset ID: walk.v.06 \n",
      "POS Tag: v \n",
      "Definition: live or behave in a specified manner \n",
      "Examples: ['walk in sadness'] \n",
      "\n",
      "Syset ID: walk.v.07 \n",
      "POS Tag: v \n",
      "Definition: be or act in association with \n",
      "Examples: ['We must walk with our dispossessed brothers and sisters', 'Walk with God'] \n",
      "\n",
      "Syset ID: walk.v.08 \n",
      "POS Tag: v \n",
      "Definition: walk at a pace \n",
      "Examples: ['The horses walked across the meadow'] \n",
      "\n",
      "Syset ID: walk.v.09 \n",
      "POS Tag: v \n",
      "Definition: make walk \n",
      "Examples: ['He walks the horse up the mountain', 'Walk the dog twice a day'] \n",
      "\n",
      "Syset ID: walk.v.10 \n",
      "POS Tag: v \n",
      "Definition: take a walk; go for a walk; walk for pleasure \n",
      "Examples: ['The lovers held hands while walking', 'We like to walk every Sunday'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Get details of each synset\n",
    "for s in word_synsets:\n",
    "    if str(s.name()).startswith('walk.v'):\n",
    "        print(\n",
    "            'Syset ID: %s \\n'\n",
    "            'POS Tag: %s \\n'\n",
    "            'Definition: %s \\n'\n",
    "            'Examples: %s \\n' % (s.name(), s.pos(), s.definition(),s.examples())\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-notes",
   "language": "python",
   "name": "python-notes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}