{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook covers the basics of text tokenization. Tokenization is a method of breaking up a piece of text into smaller chunks, such as paragraphs, sentences, words, segments. It is usually the first step for computational text analytics as well as corpus analyses.\n",
    "\n",
    "In this notebook, we focus on English tokenization. Chinese may require an additional step, i.e., the word segmentation, which can be dealt with in later notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `nltk` provides many useful tools for natural language processing and text analytics. In particular, it is a comprehensive library including many state-of-art ready-made tokenizers for use. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was nothing so very remarkable in that; nor did Alice think it so very much out of the way to hear the Rabbit say to itself, “Oh dear!\n",
      "\n",
      "Oh dear!\n",
      "\n",
      "I shall be late!” (when she thought it over afterwards, it occurred to her that she ought to have wondered at this, but at the time it all seemed quite natural); but when the Rabbit actually took a watch out of its waistcoat-pocket, and looked at it, and then hurried on, Alice started to her feet, for it flashed across her mind that she had never before seen a rabbit with either a waistcoat-pocket, or a watch to take out of it, and burning with curiosity, she ran across the field after it, and fortunately was just in time to see it pop down a large rabbit-hole under the hedge.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "para = '''There was nothing so very remarkable in that; nor did Alice think it so very much out of the way to hear the Rabbit say to itself, “Oh dear! Oh dear! I shall be late!” (when she thought it over afterwards, it occurred to her that she ought to have wondered at this, but at the time it all seemed quite natural); but when the Rabbit actually took a watch out of its waistcoat-pocket, and looked at it, and then hurried on, Alice started to her feet, for it flashed across her mind that she had never before seen a rabbit with either a waistcoat-pocket, or a watch to take out of it, and burning with curiosity, she ran across the field after it, and fortunately was just in time to see it pop down a large rabbit-hole under the hedge.'''\n",
    "\n",
    "for s in sent_tokenize(para):\n",
    "    print(s+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sent_tokenize()` function uses an instance of `PunktSentenceTokenizer` from the `ntlk.tokenize.punkt` module. \n",
    "\n",
    "To process large amount of data, it is recommended to load the pre-trained `PunktSentenceTokenizer` once, and call its `tokenizer()` method for the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.data\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/PY3/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['There was nothing so very remarkable in that; nor did Alice think it so very much out of the way to hear the Rabbit say to itself, “Oh dear!',\n",
       " 'Oh dear!',\n",
       " 'I shall be late!” (when she thought it over afterwards, it occurred to her that she ought to have wondered at this, but at the time it all seemed quite natural); but when the Rabbit actually took a watch out of its waistcoat-pocket, and looked at it, and then hurried on, Alice started to her feet, for it flashed across her mind that she had never before seen a rabbit with either a waistcoat-pocket, or a watch to take out of it, and burning with curiosity, she ran across the field after it, and fortunately was just in time to see it pop down a large rabbit-hole under the hedge.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(para)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `nltk` also provides many pre-trained `PunktSentenceTokenizer` for other European languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README            estonian.pickle   italian.pickle    slovene.pickle\r\n",
      "czech.pickle      finnish.pickle    norwegian.pickle  spanish.pickle\r\n",
      "danish.pickle     french.pickle     polish.pickle     swedish.pickle\r\n",
      "dutch.pickle      german.pickle     portuguese.pickle turkish.pickle\r\n",
      "english.pickle    greek.pickle      russian.pickle\r\n"
     ]
    }
   ],
   "source": [
    "!ls /Users/alvinchen/nltk_data/tokenizers/punkt/PY3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, the `word_tokenize()` function is a wrapper function that calls the `tokenize()` method on a instance of `TreebankWordTokenizer` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['There',\n",
       " 'was',\n",
       " 'nothing',\n",
       " 'so',\n",
       " 'very',\n",
       " 'remarkable',\n",
       " 'in',\n",
       " 'that',\n",
       " ';',\n",
       " 'nor',\n",
       " 'did',\n",
       " 'Alice',\n",
       " 'think',\n",
       " 'it',\n",
       " 'so',\n",
       " 'very',\n",
       " 'much',\n",
       " 'out',\n",
       " 'of',\n",
       " 'the',\n",
       " 'way',\n",
       " 'to',\n",
       " 'hear',\n",
       " 'the',\n",
       " 'Rabbit',\n",
       " 'say',\n",
       " 'to',\n",
       " 'itself',\n",
       " ',',\n",
       " '“',\n",
       " 'Oh',\n",
       " 'dear',\n",
       " '!',\n",
       " 'Oh',\n",
       " 'dear',\n",
       " '!',\n",
       " 'I',\n",
       " 'shall',\n",
       " 'be',\n",
       " 'late',\n",
       " '!',\n",
       " '”',\n",
       " '(',\n",
       " 'when',\n",
       " 'she',\n",
       " 'thought',\n",
       " 'it',\n",
       " 'over',\n",
       " 'afterwards',\n",
       " ',',\n",
       " 'it',\n",
       " 'occurred',\n",
       " 'to',\n",
       " 'her',\n",
       " 'that',\n",
       " 'she',\n",
       " 'ought',\n",
       " 'to',\n",
       " 'have',\n",
       " 'wondered',\n",
       " 'at',\n",
       " 'this',\n",
       " ',',\n",
       " 'but',\n",
       " 'at',\n",
       " 'the',\n",
       " 'time',\n",
       " 'it',\n",
       " 'all',\n",
       " 'seemed',\n",
       " 'quite',\n",
       " 'natural',\n",
       " ')',\n",
       " ';',\n",
       " 'but',\n",
       " 'when',\n",
       " 'the',\n",
       " 'Rabbit',\n",
       " 'actually',\n",
       " 'took',\n",
       " 'a',\n",
       " 'watch',\n",
       " 'out',\n",
       " 'of',\n",
       " 'its',\n",
       " 'waistcoat-pocket',\n",
       " ',',\n",
       " 'and',\n",
       " 'looked',\n",
       " 'at',\n",
       " 'it',\n",
       " ',',\n",
       " 'and',\n",
       " 'then',\n",
       " 'hurried',\n",
       " 'on',\n",
       " ',',\n",
       " 'Alice',\n",
       " 'started',\n",
       " 'to',\n",
       " 'her',\n",
       " 'feet',\n",
       " ',',\n",
       " 'for',\n",
       " 'it',\n",
       " 'flashed',\n",
       " 'across',\n",
       " 'her',\n",
       " 'mind',\n",
       " 'that',\n",
       " 'she',\n",
       " 'had',\n",
       " 'never',\n",
       " 'before',\n",
       " 'seen',\n",
       " 'a',\n",
       " 'rabbit',\n",
       " 'with',\n",
       " 'either',\n",
       " 'a',\n",
       " 'waistcoat-pocket',\n",
       " ',',\n",
       " 'or',\n",
       " 'a',\n",
       " 'watch',\n",
       " 'to',\n",
       " 'take',\n",
       " 'out',\n",
       " 'of',\n",
       " 'it',\n",
       " ',',\n",
       " 'and',\n",
       " 'burning',\n",
       " 'with',\n",
       " 'curiosity',\n",
       " ',',\n",
       " 'she',\n",
       " 'ran',\n",
       " 'across',\n",
       " 'the',\n",
       " 'field',\n",
       " 'after',\n",
       " 'it',\n",
       " ',',\n",
       " 'and',\n",
       " 'fortunately',\n",
       " 'was',\n",
       " 'just',\n",
       " 'in',\n",
       " 'time',\n",
       " 'to',\n",
       " 'see',\n",
       " 'it',\n",
       " 'pop',\n",
       " 'down',\n",
       " 'a',\n",
       " 'large',\n",
       " 'rabbit-hole',\n",
       " 'under',\n",
       " 'the',\n",
       " 'hedge',\n",
       " '.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "word_tokenize(para)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To process large amount of data, please create an instance of `TreebankWordTokenizer` and call its `tokenize()` method for more efficient processing.\n",
    "\n",
    "We will get the same results with the following codes as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['There',\n",
       " 'was',\n",
       " 'nothing',\n",
       " 'so',\n",
       " 'very',\n",
       " 'remarkable',\n",
       " 'in',\n",
       " 'that',\n",
       " ';',\n",
       " 'nor',\n",
       " 'did',\n",
       " 'Alice',\n",
       " 'think',\n",
       " 'it',\n",
       " 'so',\n",
       " 'very',\n",
       " 'much',\n",
       " 'out',\n",
       " 'of',\n",
       " 'the',\n",
       " 'way',\n",
       " 'to',\n",
       " 'hear',\n",
       " 'the',\n",
       " 'Rabbit',\n",
       " 'say',\n",
       " 'to',\n",
       " 'itself',\n",
       " ',',\n",
       " '“',\n",
       " 'Oh',\n",
       " 'dear',\n",
       " '!',\n",
       " 'Oh',\n",
       " 'dear',\n",
       " '!',\n",
       " 'I',\n",
       " 'shall',\n",
       " 'be',\n",
       " 'late',\n",
       " '!',\n",
       " '”',\n",
       " '(',\n",
       " 'when',\n",
       " 'she',\n",
       " 'thought',\n",
       " 'it',\n",
       " 'over',\n",
       " 'afterwards',\n",
       " ',',\n",
       " 'it',\n",
       " 'occurred',\n",
       " 'to',\n",
       " 'her',\n",
       " 'that',\n",
       " 'she',\n",
       " 'ought',\n",
       " 'to',\n",
       " 'have',\n",
       " 'wondered',\n",
       " 'at',\n",
       " 'this',\n",
       " ',',\n",
       " 'but',\n",
       " 'at',\n",
       " 'the',\n",
       " 'time',\n",
       " 'it',\n",
       " 'all',\n",
       " 'seemed',\n",
       " 'quite',\n",
       " 'natural',\n",
       " ')',\n",
       " ';',\n",
       " 'but',\n",
       " 'when',\n",
       " 'the',\n",
       " 'Rabbit',\n",
       " 'actually',\n",
       " 'took',\n",
       " 'a',\n",
       " 'watch',\n",
       " 'out',\n",
       " 'of',\n",
       " 'its',\n",
       " 'waistcoat-pocket',\n",
       " ',',\n",
       " 'and',\n",
       " 'looked',\n",
       " 'at',\n",
       " 'it',\n",
       " ',',\n",
       " 'and',\n",
       " 'then',\n",
       " 'hurried',\n",
       " 'on',\n",
       " ',',\n",
       " 'Alice',\n",
       " 'started',\n",
       " 'to',\n",
       " 'her',\n",
       " 'feet',\n",
       " ',',\n",
       " 'for',\n",
       " 'it',\n",
       " 'flashed',\n",
       " 'across',\n",
       " 'her',\n",
       " 'mind',\n",
       " 'that',\n",
       " 'she',\n",
       " 'had',\n",
       " 'never',\n",
       " 'before',\n",
       " 'seen',\n",
       " 'a',\n",
       " 'rabbit',\n",
       " 'with',\n",
       " 'either',\n",
       " 'a',\n",
       " 'waistcoat-pocket',\n",
       " ',',\n",
       " 'or',\n",
       " 'a',\n",
       " 'watch',\n",
       " 'to',\n",
       " 'take',\n",
       " 'out',\n",
       " 'of',\n",
       " 'it',\n",
       " ',',\n",
       " 'and',\n",
       " 'burning',\n",
       " 'with',\n",
       " 'curiosity',\n",
       " ',',\n",
       " 'she',\n",
       " 'ran',\n",
       " 'across',\n",
       " 'the',\n",
       " 'field',\n",
       " 'after',\n",
       " 'it',\n",
       " ',',\n",
       " 'and',\n",
       " 'fortunately',\n",
       " 'was',\n",
       " 'just',\n",
       " 'in',\n",
       " 'time',\n",
       " 'to',\n",
       " 'see',\n",
       " 'it',\n",
       " 'pop',\n",
       " 'down',\n",
       " 'a',\n",
       " 'large',\n",
       " 'rabbit-hole',\n",
       " 'under',\n",
       " 'the',\n",
       " 'hedge',\n",
       " '.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "tokenizer.tokenize(para)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `nltk` module has implemented other more task-oriented word tokenizers, which differ in terms of their specific handling of the punctuations and contractions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../images/nltk-tokenizer-class.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing different word tokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `TreebankWordTokenizer` follows the Penn Treebank conventions for word tokenization.\n",
    "- `WordPunctTokenizer` splits all punctuations into separate tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "wpt = WordPunctTokenizer()\n",
    "tbwt = TreebankWordTokenizer()\n",
    "\n",
    "sent = \"Isn't this great? I can't tell!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Isn', \"'\", 't', 'this', 'great', '?', 'I', 'can', \"'\", 't', 'tell', '!']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wpt.tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', \"n't\", 'this', 'great', '?', 'I', 'ca', \"n't\", 'tell', '!']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbwt.tokenize(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization using regular expressions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-notes",
   "language": "python",
   "name": "python-notes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}