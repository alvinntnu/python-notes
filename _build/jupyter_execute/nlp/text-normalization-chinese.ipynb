{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Normalization (Chinese)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `text_normalizer_zh.py`\n",
    "- Including functions for:\n",
    "    - word-seg chinese texts\n",
    "    - clean up texts by removing duplicate spaces and line breaks\n",
    "    - remove incompatible weird characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "#from nltk.corpus import wordnet\n",
    "#import collections\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import text_normalizer_zh as tnz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load text_normalizer_zh.py\n",
    "\"\"\"\n",
    "\n",
    "Notes\n",
    "-----\n",
    "\n",
    "    These functions are based on the text normalization functions \n",
    "    provided in Text Analytics with Python 2ed.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "# from nltk.tokenize.toktok import ToktokTokenizer\n",
    "import pandas as pd\n",
    "import jieba\n",
    "\n",
    "## Initialize Trad Chinese dictionary\n",
    "jieba.set_dictionary('../../../RepositoryData/data/jiaba/dict.txt.jiebatw.txt')\n",
    "\n",
    "\n",
    "## Normalize unicode characters\n",
    "def remove_weird_chars(text):\n",
    "    #     ```\n",
    "    #     (NFKD) will apply the compatibility decomposition, i.e.\n",
    "    #     replace all compatibility characters with their equivalents.\n",
    "    #     ```\n",
    "    text = unicodedata.normalize('NFKD', text).encode('utf-8',\n",
    "                                                      'ignore').decode(\n",
    "                                                          'utf-8', 'ignore')\n",
    "    return text\n",
    "\n",
    "\n",
    "## Remove extra linebreaks\n",
    "def remove_extra_linebreaks(text):\n",
    "    lines = text.split(r'\\n+')\n",
    "    return '\\n'.join(\n",
    "        [re.sub(r'[\\s]+', ' ', l).strip() for l in lines if len(l) != 0])\n",
    "\n",
    "\n",
    "## Remove extra medial/trailing/leading spaces\n",
    "def remove_extra_spaces(text):\n",
    "    return re.sub(\"\\\\s+\", \" \", text).strip()\n",
    "\n",
    "\n",
    "## Seg the text into words\n",
    "def seg(text):\n",
    "    text_seg = jieba.cut(text)\n",
    "    out = ' '.join(text_seg)\n",
    "    return out\n",
    "\n",
    "\n",
    "## Remove punctuation/symbols\n",
    "def remove_symbols(text):\n",
    "    \"\"\"\n",
    "    \n",
    "    Unicode 6.0 has 7 character categories, and each category has subcategories:\n",
    "\n",
    "    Letter (L): lowercase (Ll), modifier (Lm), titlecase (Lt), uppercase (Lu), other (Lo)\n",
    "    Mark (M): spacing combining (Mc), enclosing (Me), non-spacing (Mn)\n",
    "    Number (N): decimal digit (Nd), letter (Nl), other (No)\n",
    "    Punctuation (P): connector (Pc), dash (Pd), initial quote (Pi), final quote (Pf), open (Ps), close (Pe), other (Po)\n",
    "    Symbol (S): currency (Sc), modifier (Sk), math (Sm), other (So)\n",
    "    Separator (Z): line (Zl), paragraph (Zp), space (Zs)\n",
    "    Other (C): control (Cc), format (Cf), not assigned (Cn), private use (Co), surrogate (Cs)\n",
    "    \n",
    "    \n",
    "    There are 3 ranges reserved for private use (Co subcategory): \n",
    "    U+E000—U+F8FF (6,400 code points), U+F0000—U+FFFFD (65,534) and U+100000—U+10FFFD (65,534). \n",
    "    Surrogates (Cs subcategory) use the range U+D800—U+DFFF (2,048 code points).\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    ## Brute-force version: list all possible unicode ranges, but this list is not complete.\n",
    "    #   text = re.sub('[\\u0021-\\u002f\\u003a-\\u0040\\u005b-\\u0060\\u007b-\\u007e\\u00a1-\\u00bf\\u2000-\\u206f\\u2013-\\u204a\\u20a0-\\u20bf\\u2100-\\u214f\\u2150-\\u218b\\u2190-\\u21ff\\u2200-\\u22ff\\u2300-\\u23ff\\u2460-\\u24ff\\u2500-\\u257f\\u2580-\\u259f\\u25a0-\\u25ff\\u2600-\\u26ff\\u2e00-\\u2e7f\\u3000-\\u303f\\ufe50-\\ufe6f\\ufe30-\\ufe4f\\ufe10-\\ufe1f\\uff00-\\uffef─◆╱]+','',text)\n",
    "\n",
    "    text = ''.join(ch for ch in text\n",
    "                   if unicodedata.category(ch)[0] not in ['P', 'S'])\n",
    "    return text\n",
    "\n",
    "\n",
    "## Remove numbers\n",
    "def remove_numbers(text):\n",
    "    return re.sub('\\\\d+', \"\", text)\n",
    "\n",
    "\n",
    "## Remove alphabets\n",
    "def remove_alphabets(text):\n",
    "    return re.sub('[a-zA-Z]+', '', text)\n",
    "\n",
    "\n",
    "## Combine every step\n",
    "def normalize_corpus(corpus,\n",
    "                     is_remove_extra_linebreaks=True,\n",
    "                     is_remove_weird_chars=True,\n",
    "                     is_seg=True,\n",
    "                     is_remove_symbols=True,\n",
    "                     is_remove_numbers=True,\n",
    "                     is_remove_alphabets=True):\n",
    "\n",
    "    normalized_corpus = []\n",
    "    # normalize each document in the corpus\n",
    "    for doc in corpus:\n",
    "\n",
    "        if is_remove_extra_linebreaks:\n",
    "            doc = remove_extra_linebreaks(doc)\n",
    "\n",
    "        if is_remove_weird_chars:\n",
    "            doc = remove_weird_chars(doc)\n",
    "\n",
    "        if is_seg:\n",
    "            doc = seg(doc)\n",
    "\n",
    "        if is_remove_symbols:\n",
    "            doc = remove_symbols(doc)\n",
    "\n",
    "        if is_remove_alphabets:\n",
    "            doc = remove_alphabets(doc)\n",
    "\n",
    "        if is_remove_numbers:\n",
    "            doc = remove_numbers(doc)\n",
    "\n",
    "        normalized_corpus.append(remove_extra_spaces(doc))\n",
    "\n",
    "    return normalized_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract an Article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Grab the first article from Google news for demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2018年10月21日，台鐵發生普悠瑪號列車翻覆事故，到今天正好屆滿2周年。據悉，交通部長林佳龍日前主動要求台鐵進行安全報告，不料竟赫然發現，今年5月19日台鐵台中成功站南側，竟因斷軌44公分卻通報不實，讓莒光號及普悠瑪號兩班列車高速通過斷軌處，險再釀重大事故。更離譜的是，該處早在2個月前已出現裂痕卻遲遲未處理，讓林佳龍當場震怒，痛斥台鐵「沒有最扯，只有更扯！」、「兩年前這麼多無辜的生命，不能白白犧牲！」', '相關新聞：台鐵App出包！旅客買了自強號看不到座位\\u3000悲情一路站到目的地', '交通部回應表示，林佳龍已要求台鐵檢討，懲處名單報部核定，提高懲處層級，包括局長在內，一併全面檢討相關責任。', '林佳龍在2019年初上任交通部長後，要求針對普悠瑪列車翻覆事故重啟調查、擴大懲處、提高賠償，家屬陸續接受賠償條件。據了解，今年事故周年紀念前夕，林佳龍要求台鐵局、鐵道局、路政司等單位，向他彙報台鐵的安全策進作為，原是希望藉此激勵台鐵提高安全管理，豈料卻因得知519事故經過而大怒。', '運安會曾在今年5月30日發布「安全通告」，要求台鐵對全台的彎道鋼軌加強檢查，當時曾指出台鐵5月19日發生內軌斷裂、所幸無人傷亡，但並未對外透露事發詳細經過。交通部5月19日當天雖接獲台鐵簡訊通報有鋼軌事故，但稍晚即已緊急修復，恢復雙向通行。', '不過據《蘋果》掌握消息，林佳龍日前主動要求台鐵報告時，台鐵才首度向交通部坦言，今年5月19日晚間18時59分，台鐵第3218次司機員向成功站通報：「鐵軌碰一聲很大聲，好像是斷軌。」站務人員通知道班後共同前往查看，但竟然未依SOP向調度員通報，導致後續有兩班列車包括2次莒光號、288次普悠瑪自強號，高速通過該地點。直到調度員自行從無線電群組聽到成功站的通話，得知有鋼軌斷裂，才在19時27分發布行車命令封鎖該線，改單線雙向行車，過程相當驚險。', '隨後成功道班趕至現場緊急搶修，發現鋼軌斷裂44公分，先以1公尺短軌緊急更換，21時26分完成搶修才恢復雙線行車，當晚收班後再連夜換新鋼軌。隔天台鐵通報運安會立案調查，也才有10天之後的安全通告。', '據了解，台鐵追查後發現，成功道班領班早在今年3月3日，就發現該處鋼軌出現裂紋，發現後及通知相關人員處理，進行臨時補強措施；依標準作業程序，當晚就應該抽換新的鋼軌，不料相關人員竟置之不理，此案就此石沉大海，直到5月19日因司機員察覺有異進通報，才發現事態嚴重，兩個多月來的行車安全猶如「命繫一軌」。', '據與會者透露，林佳龍聽完報告後，對於台鐵事前未積極防範、事發未確實通報、事後未主動向交通部專案報告等情形極為不滿，對於發現鋼軌裂痕竟然石沈大海兩個多月更是痛罵「離譜至極！」會中更罕見地措詞強硬質問台鐵：「普悠瑪翻覆事故快兩周年了，這樣叫做有記取教訓嗎？」', '知情人士也透露，林佳龍在會中說，怕的不只是一個斷軌沒有處理好，而是如果沒有痛定思痛，下次不知道哪一段斷軌會發生更大的事故，「顯示台鐵的改革根本不及格！」他要求台鐵提高懲處層級，也要針對相關疏失、以及運安會要求加強全台鋼軌安全檢測的作為，進行相關檢討報告。', '台鐵人員表示，3月時發現軌道有裂痕，並非沒有處理，現場人員先採魚尾鈑夾住加固，考量當時現場有其他工程正在施作，現場人員規劃先抽換道岔後，再來更換新鋼軌，導致時間拖比較久，該案目前運安會已經立案調查。', '交通部回應表示，根據台鐵就519斷軌事件初步調查情形，涉及鋼軌檢修、突發通報、安全管理等疏失，台鐵日前報告後，部長有五點指示，第一、台鐵務必全力配合運安會調查，誠實為上策，如再有隱瞞，絕不寬貸；第二、懲處名單報部核定，提高懲處層級，包括局長在內，一併全面檢討相關責任。', '第三、林佳龍要求針對519事件成立檢討專案，檢視鋼軌檢修作業流程及通報機制，並落實相關人員布達及訓練；四、針對運安會要求對全台的彎道鋼軌加強檢查，台鐵應於最快時間內完成，並向交通部及運安會報告檢修及改善情形；五、只有安全，才有台鐵，台鐵務必記取教訓、痛定思痛，否則難以重建人民信任。此案目前正由運安會調查，交通部及台鐵局將全力配合調查。（李姿慧／台北報導）']\n"
     ]
    }
   ],
   "source": [
    "url = 'https://news.google.com/topics/CAAqJQgKIh9DQkFTRVFvSUwyMHZNRFptTXpJU0JYcG9MVlJYS0FBUAE?hl=zh-TW&gl=TW&ceid=TW%3Azh-Hant'\n",
    "r = requests.get(url)\n",
    "web_content = r.text\n",
    "soup = BeautifulSoup(web_content, 'lxml')\n",
    "title = soup.find_all('a', class_='DY5T1d')\n",
    "first_art_link = title[0]['href'].replace('.', 'https://news.google.com', 1)\n",
    "\n",
    "#print(first_art_link)\n",
    "art_request = requests.get(first_art_link)\n",
    "art_request.encoding = 'utf8'\n",
    "soup_art = BeautifulSoup(art_request.text, 'lxml')\n",
    "\n",
    "art_content = soup_art.find_all('p')\n",
    "art_texts = [p.text for p in art_content]\n",
    "print(art_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Normalized results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /Users/Alvin/GoogleDrive/_MySyncDrive/RepositoryData/data/jiaba/dict.txt.jiebatw.txt ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dumping model to file cache /var/folders/n7/ltpzwx813c599nfxfb94s_640000gn/T/jieba.u1b52b47246a0f2e6497af6bbe107adac.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 2.027 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['年 月 日 台鐵 發生 普悠瑪號 列車 翻覆 事故 到 今天 正好 屆滿 周年 據悉 交通部長 林佳龍 日前 主動 要求 台鐵 進行 安全 報告 不料 竟 赫然 發現 今年 月 日 台鐵 台中 成功 站 南側 竟因 斷軌 公分 卻 通報 不實 讓 莒光號 及 普悠瑪號 兩班 列車 高速 通過 斷軌 處 險 再 釀 重大 事故 更 離譜 的 是 該處 早 在 個 月 前 已 出現 裂痕 卻 遲遲 未 處理 讓 林佳龍 當場 震怒 痛斥 台鐵 沒有 最扯 只有 更 扯 兩年 前 這麼多 無辜 的 生命 不能 白白 犧牲 相關 新聞 台鐵 出包 旅客 買 了 自強號 看不到 座位 悲情 一路 站到 目的地 交通部 回應 表示 林佳龍 已 要求 台鐵 檢討 懲處 名單 報部 核定 提高 懲處 層級 包括 局長 在內 一併 全面 檢討 相關 責任 林佳龍 在 年初 上任 交通部長 後 要求 針對 普悠瑪 列車 翻覆 事故 重啟 調查 擴大 懲處 提高 賠償 家屬 陸續 接受 賠償 條件 據了解 今年 事故 周年 紀念 前夕 林佳龍 要求 台鐵局 鐵道局 路政司 等 單位 向 他 彙報 台鐵 的 安全 策進 作為 原是 希望 藉 此 激勵 台鐵 提高 安全 管理 豈料 卻 因 得知 事故 經過 而 大怒 運安會 曾 在 今年 月 日 發布 安全 通告 要求 台鐵 對 全台 的 彎道 鋼軌 加強 檢查 當時 曾 指出 台鐵 月 日 發生 內軌 斷裂 所幸 無 人 傷亡 但 並未 對外 透露 事發 詳細 經過 交通部 月 日 當天 雖 接獲 台鐵 簡訊 通報 有 鋼軌 事故 但 稍 晚 即已 緊急 修復 恢復 雙向 通行 不過 據 蘋果 掌握 消息 林佳龍 日前 主動 要求 台鐵 報告 時 台鐵 才 首度 向 交通部 坦言 今年 月 日 晚間 時 分 台鐵 第 次 司機員 向 成功 站 通報 鐵軌 碰一聲 很 大聲 好像 是 斷軌 站務 人員 通知 道班 後 共同 前往 查看 但 竟然 未依 向 調度員 通報 導致 後續 有 兩班 列車 包括 次 莒光號 次 普悠瑪 自強號 高速 通過 該 地點 直到 調度員 自行 從 無線電 群組 聽到 成功 站 的 通話 得知 有 鋼軌 斷裂 才 在 時 分 發布 行車 命令 封鎖 該線 改 單線 雙向 行車 過程 相當 驚險 隨後 成功 道班 趕至 現場 緊急 搶修 發現 鋼軌 斷裂 公分 先以 公尺 短軌 緊急 更換 時 分 完成 搶修 才 恢復 雙線 行車 當晚 收班 後 再 連夜 換新 鋼軌 隔天 台鐵 通報 運安會 立案 調查 也 才 有 天 之後 的 安全 通告 據了解 台鐵 追查 後 發現 成功 道班 領班 早 在 今年 月 日 就 發現 該處 鋼軌 出現 裂紋 發現 後 及 通知 相關 人員 處理 進行 臨時 補強 措施 依 標準 作業 程序 當晚 就 應該 抽換 新 的 鋼軌 不料 相關 人員 竟 置之不理 此案 就此 石沉 大海 直到 月 日因 司機員 察覺 有異 進 通報 才 發現 事態 嚴重 兩個 多 月 來 的 行車 安全 猶如 命 繫 一 軌 據 與會 者 透露 林佳龍 聽完 報告 後 對於 台鐵 事前 未 積極 防範 事發 未 確實 通報 事後未 主動 向 交通部 專案 報告 等 情形 極為 不滿 對於 發現 鋼軌 裂痕 竟然 石沈大海 兩個 多 月 更 是 痛罵 離譜 至極 會 中 更 罕見 地 措詞 強硬 質問 台鐵 普悠瑪 翻覆 事故 快 兩 周年 了 這樣 叫做 有 記取 教訓 嗎 知情 人士 也 透露 林佳龍 在 會 中 說 怕 的 不 只是 一個 斷軌 沒有 處理好 而是 如果 沒有 痛定思痛 下次 不 知道 哪 一段 斷軌 會 發生 更大 的 事故 顯示 台鐵 的 改革 根本 不 及格 他 要求 台鐵 提高 懲處 層級 也 要 針對 相關 疏失 以及 運安會 要求 加強 全台 鋼軌 安全 檢測 的 作為 進行 相關 檢討 報告 台鐵 人員 表示 月 時 發現 軌道 有 裂痕 並非 沒有 處理 現場 人員 先採 魚尾 鈑 夾住 加固 考量 當時 現場 有 其 他 工程 正在 施作 現場 人員 規劃 先 抽換 道岔 後 再來 更換 新 鋼軌 導致 時間 拖 比較 久 該 案 目前 運安會 已經 立案 調查 交通部 回應 表示 根據 台鐵 就 斷軌 事件 初步 調查 情形 涉及 鋼軌 檢修 突發 通報 安全 管理 等 疏失 台鐵 日前 報告 後 部長 有五點 指示 第一 台鐵 務必 全力 配合 運安會 調查 誠實 為 上策 如 再 有 隱瞞 絕不 寬貸 第二 懲處 名單 報部 核定 提高 懲處 層級 包括 局長 在內 一併 全面 檢討 相關 責任 第三 林佳龍 要求 針對 事件 成立 檢討 專案 檢視 鋼軌 檢修 作業 流程 及 通報 機制 並 落實 相關 人員 布達 及 訓練 四 針對 運安會 要求 對 全台 的 彎道 鋼軌 加強 檢查 台鐵 應 於 最快 時間 內 完成 並向 交通部 及 運安會 報告 檢修 及 改善 情形 五 只有 安全 才 有 台鐵 台鐵 務必 記取 教訓 痛定思痛 否則 難以 重建 人民 信任 此案 目前 正由 運安會 調查 交通部 及 台鐵局 將 全力 配合 調查 李姿慧 台北 報導']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tnz.normalize_corpus([' '.join(art_texts)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-notes",
   "language": "python",
   "name": "python-notes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}