{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Normalization (Chinese)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `text_normalizer_zh.py`\n",
    "- Including functions for:\n",
    "    - word-seg chinese texts\n",
    "    - clean up texts by removing duplicate spaces and line breaks\n",
    "    - remove incompatible weird characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "#from nltk.corpus import wordnet\n",
    "#import collections\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import text_normalizer_zh as tnz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load text_normalizer_zh.py\n",
    "\"\"\"\n",
    "\n",
    "Notes\n",
    "-----\n",
    "\n",
    "    These functions are based on the text normalization functions \n",
    "    provided in Text Analytics with Python 2ed.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "# from nltk.tokenize.toktok import ToktokTokenizer\n",
    "import pandas as pd\n",
    "import jieba\n",
    "\n",
    "## Initialize Trad Chinese dictionary\n",
    "jieba.set_dictionary('../../../RepositoryData/data/jiaba/dict.txt.jiebatw.txt')\n",
    "\n",
    "\n",
    "## Normalize unicode characters\n",
    "def remove_weird_chars(text):\n",
    "    #     ```\n",
    "    #     (NFKD) will apply the compatibility decomposition, i.e.\n",
    "    #     replace all compatibility characters with their equivalents.\n",
    "    #     ```\n",
    "    text = unicodedata.normalize('NFKD', text).encode('utf-8',\n",
    "                                                      'ignore').decode(\n",
    "                                                          'utf-8', 'ignore')\n",
    "    return text\n",
    "\n",
    "\n",
    "## Remove extra linebreaks\n",
    "def remove_extra_linebreaks(text):\n",
    "    lines = text.split(r'\\n+')\n",
    "    return '\\n'.join(\n",
    "        [re.sub(r'[\\s]+', ' ', l).strip() for l in lines if len(l) != 0])\n",
    "\n",
    "\n",
    "## Remove extra medial/trailing/leading spaces\n",
    "def remove_extra_spaces(text):\n",
    "    return re.sub(\"\\\\s+\", \" \", text).strip()\n",
    "\n",
    "\n",
    "## Seg the text into words\n",
    "def seg(text):\n",
    "    text_seg = jieba.cut(text)\n",
    "    out = ' '.join(text_seg)\n",
    "    return out\n",
    "\n",
    "\n",
    "## Remove punctuation/symbols\n",
    "def remove_symbols(text):\n",
    "    \"\"\"\n",
    "    \n",
    "    Unicode 6.0 has 7 character categories, and each category has subcategories:\n",
    "\n",
    "    Letter (L): lowercase (Ll), modifier (Lm), titlecase (Lt), uppercase (Lu), other (Lo)\n",
    "    Mark (M): spacing combining (Mc), enclosing (Me), non-spacing (Mn)\n",
    "    Number (N): decimal digit (Nd), letter (Nl), other (No)\n",
    "    Punctuation (P): connector (Pc), dash (Pd), initial quote (Pi), final quote (Pf), open (Ps), close (Pe), other (Po)\n",
    "    Symbol (S): currency (Sc), modifier (Sk), math (Sm), other (So)\n",
    "    Separator (Z): line (Zl), paragraph (Zp), space (Zs)\n",
    "    Other (C): control (Cc), format (Cf), not assigned (Cn), private use (Co), surrogate (Cs)\n",
    "    \n",
    "    \n",
    "    There are 3 ranges reserved for private use (Co subcategory): \n",
    "    U+E000—U+F8FF (6,400 code points), U+F0000—U+FFFFD (65,534) and U+100000—U+10FFFD (65,534). \n",
    "    Surrogates (Cs subcategory) use the range U+D800—U+DFFF (2,048 code points).\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    ## Brute-force version: list all possible unicode ranges, but this list is not complete.\n",
    "    #   text = re.sub('[\\u0021-\\u002f\\u003a-\\u0040\\u005b-\\u0060\\u007b-\\u007e\\u00a1-\\u00bf\\u2000-\\u206f\\u2013-\\u204a\\u20a0-\\u20bf\\u2100-\\u214f\\u2150-\\u218b\\u2190-\\u21ff\\u2200-\\u22ff\\u2300-\\u23ff\\u2460-\\u24ff\\u2500-\\u257f\\u2580-\\u259f\\u25a0-\\u25ff\\u2600-\\u26ff\\u2e00-\\u2e7f\\u3000-\\u303f\\ufe50-\\ufe6f\\ufe30-\\ufe4f\\ufe10-\\ufe1f\\uff00-\\uffef─◆╱]+','',text)\n",
    "\n",
    "    text = ''.join(ch for ch in text\n",
    "                   if unicodedata.category(ch)[0] not in ['P', 'S'])\n",
    "    return text\n",
    "\n",
    "\n",
    "## Remove numbers\n",
    "def remove_numbers(text):\n",
    "    return re.sub('\\\\d+', \"\", text)\n",
    "\n",
    "\n",
    "## Remove alphabets\n",
    "def remove_alphabets(text):\n",
    "    return re.sub('[a-zA-Z]+', '', text)\n",
    "\n",
    "\n",
    "## Combine every step\n",
    "def normalize_corpus(corpus,\n",
    "                     is_remove_extra_linebreaks=True,\n",
    "                     is_remove_weird_chars=True,\n",
    "                     is_seg=True,\n",
    "                     is_remove_symbols=True,\n",
    "                     is_remove_numbers=True,\n",
    "                     is_remove_alphabets=True):\n",
    "\n",
    "    normalized_corpus = []\n",
    "    # normalize each document in the corpus\n",
    "    for doc in corpus:\n",
    "\n",
    "        if is_remove_extra_linebreaks:\n",
    "            doc = remove_extra_linebreaks(doc)\n",
    "\n",
    "        if is_remove_weird_chars:\n",
    "            doc = remove_weird_chars(doc)\n",
    "\n",
    "        if is_seg:\n",
    "            doc = seg(doc)\n",
    "\n",
    "        if is_remove_symbols:\n",
    "            doc = remove_symbols(doc)\n",
    "\n",
    "        if is_remove_alphabets:\n",
    "            doc = remove_alphabets(doc)\n",
    "\n",
    "        if is_remove_numbers:\n",
    "            doc = remove_numbers(doc)\n",
    "\n",
    "        normalized_corpus.append(remove_extra_spaces(doc))\n",
    "\n",
    "    return normalized_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract an Article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Grab the first article from Google news for demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['被網友封為「村長」的國民黨桃園市議員詹江村，昨被周刊爆料帶女粉絲上汽車旅館硬上，女子控訴詹射後不理；對此，詹江村昨天到桃園市警局桃園警分局對爆料女子提告妨害名譽；爆料女子今天也到新北市永和警分局提告詹涉嫌妨害性自主，警方已依規定受理，近期也將通知詹江村到案說明。', '\\n', '\\r\\n綽號「村長」的桃園市議員詹江村昨被周刊爆料，去年8月帶女粉絲上汽車旅館硬上得逞，事後詹「射後不理」讓女生心寒，詹江村昨天否認女粉絲指控，同時也向桃園警方提告爆料女子妨害名譽。', '\\n', '\\r\\n爆料女子認為詹敢做不敢承認，今天下午也檢具相關證據，前往新北市永和警分局報案，對詹江村提告涉嫌妨害性自主。警方已依規定受理，為釐清相關案情，不排除近期內通知詹江村到案說明。桃園市議員詹江村。圖／報系資料照', '\\n                    新竹縣新豐鄉一棟磚造平房昨天凌晨發生火警，廿五歲姜姓女子因為起火點就在隔房雜物間，大火困住房門，加上鐵窗無法逃生，雖在窗...                  ', '\\n                    四十一歲葉姓男子昨天中午駕駛滿載廢土的聯結車，行經國道一號路竹北上路段突擦撞前方小客車後翻覆，車體和滿車砂土正好壓中另一...                  ', '\\n                    9月底，在高雄經營水產行的蔡姓男子，駕貨車在88線快速道路，超車側撞騎大型重機鄭姓男子，鄭摔倒地身上多處擦傷，影像曝光引發眾怒，許多人大罵根本是謀殺。交通部長林佳龍把這種惡意逼車者，視為全民公敵，瑞芳分局去年起在台二線抓逼車，多次目睹逼車實況，邊蒐證邊冷汗直流。                  ', '\\n                    台北市大安區22日傳出瓦斯外洩，晚間消防人員會同瓦斯公司尋找洩漏點，目前已經針對可能的瓦斯洩漏範圍警戒。                  ', '\\n                    濁水溪南岸今天下午再傳火警，雲林縣消防局已派員前往滅火，濃煙隨著東北季風籠罩雲林縣崙背鄉，空氣品質亮橘燈，雲林縣衛生局提...                  ', '\\n                    27歲林姓男子稍早駕駛一輛保時捷行徑新北市淡水區淡金路時，因不明原因失控後自撞路中分隔島，卡在車內無法動彈，最後由消防人...                  ', '\\n                    桃園市議員「村長」詹江村被女粉絲J女指控被帶到摩鐵硬上得逞，還「射後不理」，詹駁斥女方控訴，昨天還上警局提告妨害名譽，由...                  ', '\\n                    花蓮鳳林鎮與壽豐鄉今天分別發生2起車禍，下午2時許，台9線約222.6公里附近，一輛小貨車擦撞一輛機車，導致騎機車的86...                  ', '\\n                    新北市消防局今天上午11時39分獲報，中和區連城路與景平路交叉路口有瓦斯漏氣，消防人車已封閉四個路段路口，包括景平路與泰...                  ', '\\n                    被網友封為「村長」的國民黨桃園市議員詹江村，昨被周刊爆料帶女粉絲上汽車旅館硬上，女子控訴詹射後不理；對此，詹江村昨天到桃...                  ', '\\n                    電影芝加哥七人案驚世審判（The Trial of the Chicago 7）最近在影視串流平台網飛Netflix上架，在電影中非常搶戲的人權律師威廉‧庫斯特樂 (William Kunstler)，1986年差一點成為「白狼」張安樂在紐約受審時的辯護律師，庫斯特樂成功地迫使檢方放棄對同案另一被告的起訴，隨後再來檢視張安樂已經進入審判程序的案情後，認為幫不上太多忙，沒有接下張安樂辯護律師，張後來也遭判刑十多年。                  ', '\\n                    台南市政府警察局推動新局徽Logo設計，市警局今下午頒獎，首獎作品將作為市警局專屬意象標誌，市警局下午也頒發警政工作六大...                  ', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n']\n"
     ]
    }
   ],
   "source": [
    "url = 'https://news.google.com/topics/CAAqJQgKIh9DQkFTRVFvSUwyMHZNRFptTXpJU0JYcG9MVlJYS0FBUAE?hl=zh-TW&gl=TW&ceid=TW%3Azh-Hant'\n",
    "r = requests.get(url)\n",
    "web_content = r.text\n",
    "soup = BeautifulSoup(web_content, 'lxml')\n",
    "title = soup.find_all('a', class_='DY5T1d')\n",
    "first_art_link = title[0]['href'].replace('.', 'https://news.google.com', 1)\n",
    "\n",
    "#print(first_art_link)\n",
    "art_request = requests.get(first_art_link)\n",
    "art_request.encoding = 'utf8'\n",
    "soup_art = BeautifulSoup(art_request.text, 'lxml')\n",
    "\n",
    "art_content = soup_art.find_all('p')\n",
    "art_texts = [p.text for p in art_content]\n",
    "print(art_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Normalized results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /Users/Alvin/GoogleDrive/_MySyncDrive/RepositoryData/data/jiaba/dict.txt.jiebatw.txt ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from cache /var/folders/n7/ltpzwx813c599nfxfb94s_640000gn/T/jieba.u1b52b47246a0f2e6497af6bbe107adac.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.563 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['被 網友 封為 村長 的 國民黨 桃園市 議員 詹江村 昨被 周刊 爆料 帶女 粉絲 上 汽車 旅館 硬上 女子 控訴 詹射 後 不理 對此 詹江村 昨天 到 桃園市 警局 桃園 警分局 對 爆料 女子 提告 妨害 名譽 爆料 女子 今天 也 到 新 北市 永和 警分局 提告 詹 涉嫌 妨害性 自主 警方 已依 規定 受理 近期 也將 通知 詹江村 到案 說明 綽號 村長 的 桃園市 議員 詹江村 昨被 周刊 爆料 去年 月 帶 女 粉絲 上 汽車 旅館 硬上 得逞 事 後 詹 射 後 不理 讓 女生 心寒 詹江村 昨天 否認 女 粉絲 指控 同時 也 向 桃園 警方 提告 爆料 女子 妨害 名譽 爆料 女子 認為 詹敢 做 不敢 承認 今天 下午 也 檢具 相關 證據 前往 新 北市 永和 警分局 報案 對 詹江村 提告 涉嫌 妨害性 自主 警方 已依 規定 受理 為 釐清 相關 案情 不 排除 近期 內 通知 詹江村 到案 說明 桃園市 議員 詹江村 圖 報系 資料 照 新竹縣 新豐鄉 一棟 磚造 平房 昨天 凌晨 發生 火警 廿五歲 姜姓 女子 因為 起火點 就 在 隔房 雜物 間 大火 困住 房門 加上 鐵窗 無法 逃生 雖 在 窗 四十一歲 葉姓 男子 昨天 中午 駕駛 滿載 廢土 的 聯結車 行經 國道 一號 路竹 北上 路段 突 擦撞 前方 小 客車 後 翻覆 車體 和 滿車 砂土 正好 壓中 另 一 月底 在 高雄 經營 水產 行 的 蔡姓 男子 駕 貨車 在 線 快速 道路 超車 側撞 騎 大型 重機 鄭姓 男子 鄭 摔倒 地身 上 多處 擦傷 影像 曝光 引發 眾怒 許多 人 大罵 根本 是 謀殺 交通部長 林佳龍 把 這種 惡意 逼車 者 視為 全民 公敵 瑞芳 分局 去年 起 在 台二 線 抓 逼車 多次 目睹 逼車 實況 邊 蒐證 邊 冷汗 直流 台北市 大安區 日 傳出 瓦斯 外洩 晚間 消防 人員 會同 瓦斯 公司 尋找 洩漏 點 目前 已經 針對 可能 的 瓦斯 洩漏 範圍 警戒 濁水溪 南岸 今天 下午 再傳 火警 雲林縣 消防局 已 派員 前往 滅火 濃煙 隨著 東北 季風 籠罩 雲林縣 崙背鄉 空氣 品質 亮橘 燈 雲林縣 衛生局 提 歲 林姓 男子 稍早 駕駛 一輛 保時捷 行徑 新 北市 淡水區 淡金路 時 因 不明 原因 失控 後 自 撞路 中 分隔島 卡在 車 內 無法 動彈 最後 由 消防 人 桃園市 議員 村長 詹江村 被 女 粉絲 女 指控 被 帶到 摩鐵 硬上 得逞 還 射 後 不理 詹 駁斥 女方 控訴 昨天 還上 警局 提告 妨害 名譽 由 花蓮 鳳林鎮 與 壽豐鄉 今天 分別 發生 起 車禍 下午 時許 台 線約 公里 附近 一輛 小 貨車 擦撞 一輛 機車 導致 騎 機車 的 新 北市 消防局 今天 上午 時 分 獲報 中和區 連城路 與 景平路 交叉 路口 有 瓦斯 漏氣 消防 人車 已 封閉 四個 路段 路口 包括 景平路 與 泰 被 網友 封為 村長 的 國民黨 桃園市 議員 詹江村 昨被 周刊 爆料 帶女 粉絲 上 汽車 旅館 硬上 女子 控訴 詹射 後 不理 對此 詹江村 昨天 到桃 電影 芝加哥 七人 案 驚世 審判 最近 在 影視 串流 平台 網飛 上架 在 電影 中 非常 搶戲 的 人權 律師 威廉 庫 斯特 樂 年 差一點 成為 白狼 張安樂 在 紐約 受 審時 的 辯護 律師 庫 斯特 樂 成功 地 迫使 檢方 放棄 對 同案 另 一 被告 的 起訴 隨後 再來 檢視 張安樂 已經 進入 審判 程序 的 案情 後 認為 幫不上 太多 忙 沒有 接下 張安樂 辯護 律師 張 後來 也 遭 判刑 十多年 台南市 政府 警察局 推動 新 局徽 設計 市警局 今下午 頒獎 首獎 作品 將 作為 市警局 專屬 意象 標誌 市警局 下午 也 頒發 警政 工作 六大']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tnz.normalize_corpus([' '.join(art_texts)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-notes",
   "language": "python",
   "name": "python-notes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}