{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Normalization (Chinese)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `text_normalizer_zh.py`\n",
    "- Including functions for:\n",
    "    - word-seg chinese texts\n",
    "    - clean up texts by removing duplicate spaces and line breaks\n",
    "    - remove incompatible weird characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "#from nltk.corpus import wordnet\n",
    "#import collections\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from bs4 import BeautifulSoup\n",
    "import requests \n",
    "import pandas as pd\n",
    "import text_normalizer_zh as tnz\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load text_normalizer_zh.py\n",
    "import unicodedata\n",
    "import re\n",
    "#from nltk.corpus import wordnet\n",
    "#import collections\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from bs4 import BeautifulSoup\n",
    "import requests \n",
    "import pandas as pd\n",
    "\n",
    "## Normalize unicode characters\n",
    "def remove_weird_chars(text):\n",
    "#     ```\n",
    "#     (NFKD) will apply the compatibility decomposition, i.e. \n",
    "#     replace all compatibility characters with their equivalents. \n",
    "#     ```\n",
    "    text = unicodedata.normalize('NFKD', text).encode('utf-8', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text\n",
    "\n",
    "\n",
    "## Remove duplicate spaces\n",
    "def remove_extra_linebreaks(text):\n",
    "    lines = text.split(r'\\n+')\n",
    "    return '\\n'.join([re.sub(r'[\\s]+',' ', l).strip() for l in lines if len(l)!=0])\n",
    "\n",
    "\n",
    "def remove_extra_spaces(text):\n",
    "    return re.sub(\"\\\\s+\",\" \", text).strip()\n",
    "\n",
    "import jieba\n",
    "jieba.set_dictionary('../../../RepositoryData/data/jiaba/dict.txt.jiebatw.txt')\n",
    "\n",
    "## Word Segmentation\n",
    "def seg(text, return_list = False):\n",
    "    text_seg = jieba.cut(text)\n",
    "    if return_list:\n",
    "        out = [w for w in text_seg]\n",
    "    else:\n",
    "        out = ' '.join(text_seg)\n",
    "    return out\n",
    "\n",
    "\n",
    "def remove_symbols(text):\n",
    "    text = re.sub('[\\u0021-\\u002f\\u003a-\\u0040\\u005b-\\u0060\\u007b-\\u007e\\u00a1-\\u00bf\\u2000-\\u206f\\u2013-\\u204a\\u20a0-\\u20bf\\u2100-\\u214f\\u2150-\\u218b\\u2190-\\u21ff\\u2200-\\u22ff\\u2300-\\u23ff\\u2460-\\u24ff\\u2500-\\u257f\\u2580-\\u259f\\u25a0-\\u25ff\\u2600-\\u26ff\\u2e00-\\u2e7f\\u3000-\\u303f\\ufe50-\\ufe6f\\ufe30-\\ufe4f\\ufe10-\\ufe1f\\uff00-\\uffef─◆╱]+','',text)\n",
    "    return text\n",
    "\n",
    "def remove_numbers(text):\n",
    "    return re.sub('\\\\d+',\"\", text)\n",
    "\n",
    "def remove_alphabets(text):\n",
    "    return re.sub('[a-zA-Z]+','', text)\n",
    "\n",
    "def normalize_corpus(corpus, is_remove_extra_linebreaks=True,\n",
    "                    is_remove_weird_chars=True,\n",
    "                    is_seg=True,\n",
    "                    is_remove_symbols=True,\n",
    "                    is_remove_numbers=True,\n",
    "                    is_remove_alphabets=True,\n",
    "                    is_return_list = False):\n",
    "    \n",
    "    normalized_corpus = []\n",
    "    # normalize each document in the corpus\n",
    "    for doc in corpus:\n",
    "        \n",
    "        if is_remove_extra_linebreaks:\n",
    "            doc = remove_extra_linebreaks(doc)\n",
    "            \n",
    "        if is_remove_weird_chars:\n",
    "            doc = remove_weird_chars(doc)\n",
    "           \n",
    "        if is_seg:\n",
    "            doc=seg(doc, is_return_list)\n",
    "            \n",
    "        if is_remove_symbols:\n",
    "            doc=remove_symbols(doc)\n",
    "            \n",
    "        if is_remove_alphabets:\n",
    "            doc=remove_alphabets(doc)\n",
    "            \n",
    "        if is_remove_numbers:\n",
    "            doc=remove_numbers(doc)\n",
    "            \n",
    "        normalized_corpus.append(remove_extra_spaces(doc))\n",
    "        \n",
    "    return normalized_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract an Article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Grab the first article from Google news for demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['今年國慶焰火昨晚在台南登場，湧入逾50萬人遊客，交通接駁嚴重打結，不少人在網路開轟，台南市長黃偉哲下午受訪時表示，千錯萬錯，都由他承擔，將加強檢討、改進，未來還有大型活動時，疏散計畫列為第一優先。', '\\n', '\\r\\n山上花園水道博物館第70萬名遊客下午出爐，黃偉哲前往頒獎給幸運兒，對媒體詢問，國慶焰火交通疏運網路上批評聲音，黃偉哲強調，「會自我檢討」。', '\\n', '\\r\\n黃偉哲說，昨晚國慶焰火100分，但地上交通以及相關設施等，遊客來得太多，是預估的2倍以上，衝擊交通，只能打70分，市政府團隊還是要努力。', '\\n', '\\r\\n黃偉哲指出，昨晚的活動，警察認真維持治安，沒有重大案件，交通指揮至深夜，相當辛苦；清潔方面，環保局的同仁與志工們一樣很努力，忙到今天凌晨4點多，大家都很用心。', '\\n', '\\r\\n黃偉哲表示，千錯萬錯，都是市政府，要自己改進、檢討，未來舉辦大型活動，交通疏運計畫列為第一優先，完成最妥善部署，希望做得更好。', '\\n                    昨天是雙十國慶日，不過有網友發現在Google搜尋「中華民國建立時間」，跳出來的時間竟然不是1912年1月1日，而是1949年12月7日，也就是中華民國政權遷往台灣的時間。                  ', '\\n                    今年國慶焰火昨晚在台南登場，湧入逾50萬人遊客，交通接駁嚴重打結，不少人在網路開轟，台南市長黃偉哲下午受訪時表示，千錯萬...                  ', '\\n                    前總統馬英九出席國民黨國慶升旗活動時，質疑民進黨真心誠意慶祝國慶嗎？新北市長侯友宜今天接受媒體訪問時說，中華民國「養我、...                  ', '\\n                    國慶日剛過，蔡英文總統在臉書分享相關知識，提醒大家不要再稱禮賓人員是「金釵」。蔡總統說，今年國慶，大家可能都有看到穿著制...                  ', '\\n                    在紐約僑界促成下，宣傳台灣觀光的形象廣告連兩年雙十節登上時報廣場大型螢幕。駐紐約辦事處長李光章形容，這為中華民國109歲...                  ', '\\n                    台灣基進立委陳柏惟昨說，雙十正好吃霜食，祝大家「霜食節快樂」。前立委孫大千在臉書表示，擔任中華民國立委連句生日快樂都不敢...                  ', '\\n                    波士頓市政府慶祝雙十國慶，今天循例在市府廣場升起中華民國國旗，展現對台友好。駐波士頓辦事處因應疫情改採線上慶祝，在臉書專...                  ', '\\n                    受疫情影響，駐洛杉磯辦事處今年改在線上舉行雙十國慶活動。20多名美國政要、南加州僑領及友邦代表以視訊方式現身，祝中華民國...                  ', '\\n                    紐約曼哈頓華埠今天歡慶中華民國109年雙十國慶，受疫情限制，活動簡化為升國旗、向國父銅像獻花及國慶茶會。雖少了封街遊行，...                  ', '\\n                    兩岸關係為貿易環境埋下隱憂，蔡英文總統昨（10）日於國慶大會演說時，主動向陸方拋出邀請，她表示，只要北京當局有心化解對立...                  ', '\\n                    昨天雙十國慶大會，面對新冠病毒威脅，蔡英文總統在演說時特別感謝防疫英雄，大會除由防疫英雄領唱國歌外，也安排「防疫英雄車隊...                  ', '\\n                    針對總統蔡英文昨在國慶演說提出，兩岸的穩定是雙方共同責任，國內學者多認為蔡總統的用詞謹慎、避免刺激中國大陸，但大陸學者多...                  ', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n']\n"
     ]
    }
   ],
   "source": [
    "url = 'https://news.google.com/topics/CAAqJQgKIh9DQkFTRVFvSUwyMHZNRFptTXpJU0JYcG9MVlJYS0FBUAE?hl=zh-TW&gl=TW&ceid=TW%3Azh-Hant'\n",
    "r = requests.get(url)\n",
    "web_content = r.text\n",
    "soup = BeautifulSoup(web_content,'lxml')\n",
    "title = soup.find_all('a', class_='DY5T1d')\n",
    "first_art_link = title[0]['href'].replace('.','https://news.google.com',1)\n",
    "\n",
    "#print(first_art_link)\n",
    "art_request = requests.get(first_art_link)\n",
    "art_request.encoding='utf8'\n",
    "soup_art = BeautifulSoup(art_request.text,'lxml')\n",
    "\n",
    "art_content = soup_art.find_all('p')\n",
    "art_texts = [p.text for p in art_content]\n",
    "print(art_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Normalized results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /Users/Alvin/GoogleDrive/_MySyncDrive/RepositoryData/data/jiaba/dict.txt.jiebatw.txt ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from cache /var/folders/n7/ltpzwx813c599nfxfb94s_640000gn/T/jieba.u1b52b47246a0f2e6497af6bbe107adac.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.603 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['今年 國慶 焰火 昨晚 在 台南 登場 湧入 逾 萬人 遊客 交通 接駁 嚴重 打結 不少 人 在 網路 開轟 台南 市長 黃偉哲 下午 受訪 時 表示 千錯萬錯 都 由 他 承擔 將 加強 檢討 改進 未來 還有 大型 活動 時 疏散 計畫 列為 第一 優先 山上 花園 水道 博物館 第 萬名 遊客 下午 出爐 黃偉哲 前往 頒獎給 幸運兒 對 媒體 詢問 國慶 焰火 交通 疏運 網路 上 批評 聲音 黃偉哲 強調 會 自我 檢討 黃偉哲 說 昨晚 國慶 焰火 分 但 地上 交通 以及 相關 設施 等 遊客 來得 太多 是 預估 的 倍 以上 衝擊 交通 只能 打 分 市政府 團隊 還是 要 努力 黃偉哲 指出 昨晚 的 活動 警察 認真 維持 治安 沒有 重大 案件 交通 指揮 至 深夜 相當 辛苦 清潔 方面 環保局 的 同仁 與 志工 們 一樣 很 努力 忙 到 今天 凌晨 點多 大家 都 很 用心 黃偉哲 表示 千錯萬錯 都 是 市政府 要 自己 改進 檢討 未來 舉辦 大型 活動 交通 疏運 計畫 列為 第一 優先 完成 最 妥善 部署 希望 做 得 更 好 昨天 是 雙十國慶日 不過 有 網友 發現 在 搜尋 中華民國 建立 時間 跳出來 的 時間 竟然 不是 年 月 日 而是 年 月 日 也 就是 中華民國 政權 遷往 台灣 的 時間 今年 國慶 焰火 昨晚 在 台南 登場 湧入 逾 萬人 遊客 交通 接駁 嚴重 打結 不少 人 在 網路 開轟 台南 市長 黃偉哲 下午 受訪 時 表示 千錯萬 前總統 馬英九 出席 國民黨 國慶 升旗 活動 時 質疑 民進黨 真心誠意 慶祝 國慶 嗎 新北 市長 侯友宜 今天 接受 媒體 訪問 時 說 中華民國 養 我 國慶日 剛過 蔡英文 總統 在 臉書 分享 相關 知識 提醒 大家 不要 再稱 禮賓 人員 是 金釵 蔡 總統 說 今年 國慶 大家 可能 都 有 看到 穿著 制 在 紐約 僑界 促成 下 宣傳 台灣 觀光 的 形象 廣告 連兩年 雙十節 登上 時報 廣場 大型 螢幕 駐 紐約 辦事處 長 李光章 形容 這為 中華民國 歲 台灣 基進 立委 陳 柏惟 昨說 雙十 正好 吃霜食 祝 大家 霜 食節 快樂 前立委 孫大千 在 臉書 表示 擔任 中華民國 立委 連句 生日快樂 都 不敢 波士頓 市政府 慶祝 雙十國慶 今天 循例 在 市府 廣場 升起 中華民國 國旗 展現 對台 友好 駐 波士頓 辦事處 因應 疫情 改採 線上 慶祝 在 臉書 專 受 疫情 影響 駐 洛杉磯 辦事處 今年 改在 線上 舉行 雙十國慶 活動 多名 美國 政要 南加州 僑領 及 友邦 代表 以 視訊 方式 現身 祝 中華民國 紐約 曼哈頓 華埠 今天 歡慶 中華民國 年 雙十國慶 受 疫情 限制 活動 簡化為 升 國旗 向 國父 銅像 獻花 及 國慶 茶會 雖少 了 封街 遊行 兩岸 關係 為 貿易 環境 埋下 隱憂 蔡英文 總統 昨 日 於 國慶 大會 演說 時 主動 向 陸方 拋出 邀請 她 表示 只要 北京 當局 有心 化解 對立 昨天 雙十國慶 大會 面對 新冠 病毒 威脅 蔡英文 總統 在 演說 時 特別 感謝 防疫 英雄 大會 除 由 防疫 英雄 領唱 國歌 外 也 安排 防疫 英雄 車隊 針對 總統 蔡英文 昨在 國慶 演說 提出 兩岸 的 穩定 是 雙方 共同 責任 國內 學者 多 認為 蔡 總統 的 用詞 謹慎 避免 刺激 中國 大陸 但 大陸 學者 多']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tnz.normalize_corpus([' '.join(art_texts)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-notes",
   "language": "python",
   "name": "python-notes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}