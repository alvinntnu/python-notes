{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Normalization (Chinese)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `text_normalizer_zh.py`\n",
    "- Including functions for:\n",
    "    - word-seg chinese texts\n",
    "    - clean up texts by removing duplicate spaces and line breaks\n",
    "    - remove incompatible weird characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "#from nltk.corpus import wordnet\n",
    "#import collections\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import text_normalizer_zh as tnz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load text_normalizer_zh.py\n",
    "\"\"\"\n",
    "\n",
    "Notes\n",
    "-----\n",
    "\n",
    "    These functions are based on the text normalization functions \n",
    "    provided in Text Analytics with Python 2ed.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "# from nltk.tokenize.toktok import ToktokTokenizer\n",
    "import pandas as pd\n",
    "import jieba\n",
    "\n",
    "## Initialize Trad Chinese dictionary\n",
    "jieba.set_dictionary('../../../RepositoryData/data/jiaba/dict.txt.jiebatw.txt')\n",
    "\n",
    "\n",
    "## Normalize unicode characters\n",
    "def remove_weird_chars(text):\n",
    "    #     ```\n",
    "    #     (NFKD) will apply the compatibility decomposition, i.e.\n",
    "    #     replace all compatibility characters with their equivalents.\n",
    "    #     ```\n",
    "    text = unicodedata.normalize('NFKD', text).encode('utf-8',\n",
    "                                                      'ignore').decode(\n",
    "                                                          'utf-8', 'ignore')\n",
    "    return text\n",
    "\n",
    "\n",
    "## Remove extra linebreaks\n",
    "def remove_extra_linebreaks(text):\n",
    "    lines = text.split(r'\\n+')\n",
    "    return '\\n'.join(\n",
    "        [re.sub(r'[\\s]+', ' ', l).strip() for l in lines if len(l) != 0])\n",
    "\n",
    "\n",
    "## Remove extra medial/trailing/leading spaces\n",
    "def remove_extra_spaces(text):\n",
    "    return re.sub(\"\\\\s+\", \" \", text).strip()\n",
    "\n",
    "\n",
    "## Seg the text into words\n",
    "def seg(text):\n",
    "    text_seg = jieba.cut(text)\n",
    "    out = ' '.join(text_seg)\n",
    "    return out\n",
    "\n",
    "\n",
    "## Remove punctuation/symbols\n",
    "def remove_symbols(text):\n",
    "    \"\"\"\n",
    "    \n",
    "    Unicode 6.0 has 7 character categories, and each category has subcategories:\n",
    "\n",
    "    Letter (L): lowercase (Ll), modifier (Lm), titlecase (Lt), uppercase (Lu), other (Lo)\n",
    "    Mark (M): spacing combining (Mc), enclosing (Me), non-spacing (Mn)\n",
    "    Number (N): decimal digit (Nd), letter (Nl), other (No)\n",
    "    Punctuation (P): connector (Pc), dash (Pd), initial quote (Pi), final quote (Pf), open (Ps), close (Pe), other (Po)\n",
    "    Symbol (S): currency (Sc), modifier (Sk), math (Sm), other (So)\n",
    "    Separator (Z): line (Zl), paragraph (Zp), space (Zs)\n",
    "    Other (C): control (Cc), format (Cf), not assigned (Cn), private use (Co), surrogate (Cs)\n",
    "    \n",
    "    \n",
    "    There are 3 ranges reserved for private use (Co subcategory): \n",
    "    U+E000—U+F8FF (6,400 code points), U+F0000—U+FFFFD (65,534) and U+100000—U+10FFFD (65,534). \n",
    "    Surrogates (Cs subcategory) use the range U+D800—U+DFFF (2,048 code points).\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    ## Brute-force version: list all possible unicode ranges, but this list is not complete.\n",
    "    #   text = re.sub('[\\u0021-\\u002f\\u003a-\\u0040\\u005b-\\u0060\\u007b-\\u007e\\u00a1-\\u00bf\\u2000-\\u206f\\u2013-\\u204a\\u20a0-\\u20bf\\u2100-\\u214f\\u2150-\\u218b\\u2190-\\u21ff\\u2200-\\u22ff\\u2300-\\u23ff\\u2460-\\u24ff\\u2500-\\u257f\\u2580-\\u259f\\u25a0-\\u25ff\\u2600-\\u26ff\\u2e00-\\u2e7f\\u3000-\\u303f\\ufe50-\\ufe6f\\ufe30-\\ufe4f\\ufe10-\\ufe1f\\uff00-\\uffef─◆╱]+','',text)\n",
    "\n",
    "    text = ''.join(ch for ch in text\n",
    "                   if unicodedata.category(ch)[0] not in ['P', 'S'])\n",
    "    return text\n",
    "\n",
    "\n",
    "## Remove numbers\n",
    "def remove_numbers(text):\n",
    "    return re.sub('\\\\d+', \"\", text)\n",
    "\n",
    "\n",
    "## Remove alphabets\n",
    "def remove_alphabets(text):\n",
    "    return re.sub('[a-zA-Z]+', '', text)\n",
    "\n",
    "\n",
    "## Combine every step\n",
    "def normalize_corpus(corpus,\n",
    "                     is_remove_extra_linebreaks=True,\n",
    "                     is_remove_weird_chars=True,\n",
    "                     is_seg=True,\n",
    "                     is_remove_symbols=True,\n",
    "                     is_remove_numbers=True,\n",
    "                     is_remove_alphabets=True):\n",
    "\n",
    "    normalized_corpus = []\n",
    "    # normalize each document in the corpus\n",
    "    for doc in corpus:\n",
    "\n",
    "        if is_remove_extra_linebreaks:\n",
    "            doc = remove_extra_linebreaks(doc)\n",
    "\n",
    "        if is_remove_weird_chars:\n",
    "            doc = remove_weird_chars(doc)\n",
    "\n",
    "        if is_seg:\n",
    "            doc = seg(doc)\n",
    "\n",
    "        if is_remove_symbols:\n",
    "            doc = remove_symbols(doc)\n",
    "\n",
    "        if is_remove_alphabets:\n",
    "            doc = remove_alphabets(doc)\n",
    "\n",
    "        if is_remove_numbers:\n",
    "            doc = remove_numbers(doc)\n",
    "\n",
    "        normalized_corpus.append(remove_extra_spaces(doc))\n",
    "\n",
    "    return normalized_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract an Article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Grab the first article from Google news for demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['萊克多巴胺美豬明年進口台灣，台中等多個縣市食安自治條例規定萊克多巴胺零檢出，也有其他縣市打算比照辦理，但衛福部卻發文指出與母法抵觸，應配合修正；行政院函文則表示有抵觸中央法規疑慮，應提出意見說明。衛福部表示，正在重新簽辦發文，內容將與行政院一致。', '\\n', '\\r\\n立法院今天審查農委會101年9月7日農防字第1011473960號公告，多名立委要求衛福部說明地方萊克多巴胺零檢出的自治條例跟中央法規抵觸問題。衛福部次長薛瑞元原本指出，中央訂定的萊客多巴胺殘留容許量從明年1月1日開始生效，因此地方政府現在若訂定零檢出仍為有效，但要開始檢討，否則到明年將會抵觸母法而無效。', '\\n', '\\r\\n根據衛福部9月30日發給地方政府的函，明確指出動物用藥殘留標準已經過中央發布，「自治法規如有與該標準抵觸情形，應配合修正」，並說明動物用藥殘留標準所定殘留容許量屬食品安全衛生標準，具全國一致性質，自治法規不得為較嚴格或寬鬆之規定。', '\\n', '\\r\\n不過行政院10月26日發給台中市府函文態度則較保守，僅表示地方萊克多巴胺的零檢出自治條例有抵制中央法規疑慮，應於一個月內提出意見說明。', '\\n', '\\r\\n立委林奕華質疑，衛福部發文給地方是直接要求修正自治條例，跟中央說法有所不同，且釋字738號早就說明中央法令是最低標準，地方可以訂定較嚴格標準，且地方自治條例經過議會三讀通過，根本沒問題。', '\\n', '\\r\\n薛瑞元表示，之前是請地方檢討，不過現在正在重新簽辦發文，內文將與行政院一樣。至於釋字738號是說地方可以因地制宜規定，但既然中央的食安法已經有規定，就應該遵守。', '\\n                    政府開放進口萊克多巴胺美豬，有十一縣市擬訂定自治條例要求萊劑零檢出，本報昨天報導地方政府近日收到行政院和衛福部函文，行政...                  ', '\\n                    行政院函文要求地方修改萊劑零檢出的食安自治條例，台中市長盧秀燕、新北市長侯友宜等藍營縣市首長重申堅持零檢出，台北市長柯文...                  ', '\\n                    民進黨立委林淑芬日前針對萊豬議題提案修正「學校衛生法」，明定學校禁用萊豬及其加工品，該案將在周五院會闖關。但傳出在黨團壓...                  ', '\\n                    政府宣布明年開放進口萊克多巴胺美豬，且開放全豬，但我國並未針對豬雜碎進行專家諮議會議，稅則號列也不如開放美牛時完整。衛福...                  ', '\\n                    萊豬進口風波不斷，地方縣市陸續在自治條例訂定「零檢出」規範。行政院日前與衛福部相繼發函「提醒」，要求零檢出的縣市可能有牴...                  ', '\\n                    萊克多巴胺美豬叩關，雖然立法院還在審查相關行政命令，但蔡政府決定明年元旦開放的政策恐已無轉圜。各地方政府紛紛訂出自治條例...                  ', '\\n                    國民黨縣市首長主張萊劑零檢出槓上中央，民進黨執政縣市首長態度趨保守，強調依中央規定。不過，民進黨完全執政的嘉義縣，因民進...                  ', '\\n                    萊克多巴胺美豬叩關，雖然立法院還在審查相關行政命令，但蔡政府決定明年元旦開放的政策恐已無轉圜。各地方政府紛紛訂出自治條例...                  ', '\\n                    針對台北市長柯文哲質疑明年元旦起，全世界含萊劑豬肉都可進口台灣一事。農委會主委陳吉仲今天晚間駁斥此說法，強調全球僅13個...                  ', '\\n                    萊豬大戰！全台有部分縣市政府自治條例規定萊劑零檢出並制定相關罰則，行政院發公文指零檢出牴觸中央法規，屏東縣食品安全自治條...                  ', '\\n                    新北市議會今天進行政黨質詢，新北市議員陳偉杰質疑行政院發公文給台中市政府要求檢視「食品安全衛生管理自治條例」是「殺雞儆猴...                  ', '\\n                    萊豬明年1月開放進口，台中等多個縣市食安自治條例規定萊劑不得檢出，但衛福部發文指出與母法抵觸，應配合修正，行政院函文較保守，要求地方提出意見說明。衛福部今天下午表示，正在重新簽辦發文，內容將與行政院一致。                  ', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n']\n"
     ]
    }
   ],
   "source": [
    "url = 'https://news.google.com/topics/CAAqJQgKIh9DQkFTRVFvSUwyMHZNRFptTXpJU0JYcG9MVlJYS0FBUAE?hl=zh-TW&gl=TW&ceid=TW%3Azh-Hant'\n",
    "r = requests.get(url)\n",
    "web_content = r.text\n",
    "soup = BeautifulSoup(web_content, 'lxml')\n",
    "title = soup.find_all('a', class_='DY5T1d')\n",
    "first_art_link = title[0]['href'].replace('.', 'https://news.google.com', 1)\n",
    "\n",
    "#print(first_art_link)\n",
    "art_request = requests.get(first_art_link)\n",
    "art_request.encoding = 'utf8'\n",
    "soup_art = BeautifulSoup(art_request.text, 'lxml')\n",
    "\n",
    "art_content = soup_art.find_all('p')\n",
    "art_texts = [p.text for p in art_content]\n",
    "print(art_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Normalized results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /Users/Alvin/GoogleDrive/_MySyncDrive/RepositoryData/data/jiaba/dict.txt.jiebatw.txt ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from cache /var/folders/n7/ltpzwx813c599nfxfb94s_640000gn/T/jieba.u1b52b47246a0f2e6497af6bbe107adac.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.547 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['萊克 多巴胺 美豬 明年 進口 台灣 台中 等 多個 縣市 食安 自治 條例 規定 萊克 多巴胺 零 檢出 也 有 其 他 縣市 打算 比照 辦理 但 衛福部 卻 發文 指出 與 母法 抵觸 應 配合 修正 行政院 函文 則 表示 有 抵觸 中央 法規 疑慮 應 提出 意見 說明 衛福部 表示 正在 重新 簽辦 發文 內容 將與 行政院 一致 立法院 今天 審查 農委會 年 月 日 農防字 第 號 公告 多名 立委 要求 衛福部 說明 地方 萊克 多巴胺 零 檢出 的 自治 條例 跟 中央 法規 抵觸 問題 衛福部 次長 薛瑞元 原本 指出 中央 訂定 的 萊客 多巴胺 殘留 容許量 從 明年 月 日 開始 生效 因此 地方 政府 現在 若 訂定 零 檢出 仍為 有效 但 要 開始 檢討 否則 到 明年 將會 抵觸 母法 而 無效 根據 衛福部 月 日 發給 地方 政府 的 函 明確 指出 動物 用藥 殘留 標準 已 經過 中央 發布 自治 法規 如有 與 該 標準 抵觸 情形 應 配合 修正 並 說明 動物 用藥 殘留 標準 所定 殘留 容許量 屬 食品 安全 衛生 標準 具 全國 一致 性質 自治 法規 不得 為 較 嚴格 或 寬鬆 之 規定 不過 行政院 月 日 發給 台中 市府 函文 態度 則較 保守 僅 表示 地方 萊克 多巴胺 的 零 檢出 自治 條例 有 抵制 中央 法規 疑慮 應 於 一個 月 內 提出 意見 說明 立委 林奕華 質疑 衛福部 發文 給 地方 是 直接 要求 修正 自治 條例 跟 中央 說法 有所 不同 且 釋字 號早 就 說明 中央 法令 是 最 低 標準 地方 可以 訂定 較 嚴格 標準 且 地方 自治 條例 經過 議會 三讀通過 根本 沒 問題 薛瑞元 表示 之前 是 請 地方 檢討 不過 現在 正在 重新 簽辦 發文 內文 將與 行政院 一樣 至於 釋字 號是 說 地方 可以 因地制宜 規定 但 既然 中央 的 食安法 已經 有 規定 就 應該 遵守 政府 開放 進口 萊克 多巴胺 美豬 有十一 縣市 擬 訂定 自治 條例 要求 萊劑 零 檢出 本報 昨天 報導 地方 政府 近日 收到 行政院 和 衛福部 函文 行政 行政院 函文 要求 地方 修改 萊劑 零 檢出 的 食安 自治 條例 台中 市長 盧秀燕 新北 市長 侯友宜 等 藍營 縣市 首長 重申 堅持 零 檢出 台北市 長柯 文 民進黨 立委 林淑芬 日前 針對 萊豬 議題 提案 修正 學校 衛生法 明定 學校 禁用 萊豬 及 其 加工品 該 案將 在 周五 院會 闖關 但 傳出 在 黨團 壓 政府 宣布 明年 開放 進口 萊克 多巴胺 美豬 且 開放 全豬 但 我國 並未 針對 豬 雜碎 進行 專家 諮議 會議 稅則號 列 也 不如 開放 美牛 時 完整 衛福 萊 豬進口 風波 不斷 地方 縣市 陸續 在 自治 條例 訂定 零 檢出 規範 行政院 日前 與 衛福部 相繼 發函 提醒 要求 零 檢出 的 縣市 可能 有 牴 萊克 多巴胺 美豬 叩關 雖然 立法院 還在 審查 相關 行政 命令 但 蔡 政府 決定 明年 元旦 開放 的 政策 恐已 無 轉圜 各 地方 政府 紛紛 訂出 自治 條例 國民黨 縣市 首長 主張 萊劑 零 檢出 槓上 中央 民進黨 執政 縣市 首長 態度 趨 保守 強調 依 中央 規定 不過 民進黨 完全 執政 的 嘉義縣 因 民進 萊克 多巴胺 美豬 叩關 雖然 立法院 還在 審查 相關 行政 命令 但 蔡 政府 決定 明年 元旦 開放 的 政策 恐已 無 轉圜 各 地方 政府 紛紛 訂出 自治 條例 針對 台北市長 柯文哲 質疑 明年 元旦 起 全世界 含 萊劑 豬肉 都 可 進口 台灣 一 事 農委會 主委 陳 吉仲 今天 晚間 駁斥 此 說法 強調 全球 僅 個 萊豬 大戰 全台 有 部分 縣市政府 自治 條例 規定 萊劑 零 檢出 並 制定 相關 罰則 行政院 發 公文 指零 檢出 牴觸 中央 法規 屏東縣 食品 安全 自治條 新北 市議會 今天 進行 政黨 質詢 新北 市議員陳 偉杰 質疑 行政院 發 公文 給 台中市 政府 要求 檢視 食品 安全 衛生 管理 自治 條例 是 殺雞儆猴 萊豬 明年 月 開放 進口 台中 等 多個 縣市 食安 自治 條例 規定 萊劑 不得 檢出 但 衛福部 發文 指出 與 母法 抵觸 應 配合 修正 行政院 函文 較 保守 要求 地方 提出 意見 說明 衛福部 今天 下午 表示 正在 重新 簽辦 發文 內容 將與 行政院 一致']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tnz.normalize_corpus([' '.join(art_texts)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-notes",
   "language": "python",
   "name": "python-notes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}