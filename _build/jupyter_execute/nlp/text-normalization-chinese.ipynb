{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Normalization (Chinese)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `text_normalizer_zh.py`\n",
    "- Including functions for:\n",
    "    - word-seg chinese texts\n",
    "    - clean up texts by removing duplicate spaces and line breaks\n",
    "    - remove incompatible weird characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "#from nltk.corpus import wordnet\n",
    "#import collections\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import text_normalizer_zh as tnz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load text_normalizer_zh.py\n",
    "\"\"\"\n",
    "\n",
    "Notes\n",
    "-----\n",
    "\n",
    "    These functions are based on the text normalization functions \n",
    "    provided in Text Analytics with Python 2ed.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "# from nltk.tokenize.toktok import ToktokTokenizer\n",
    "import pandas as pd\n",
    "import jieba\n",
    "\n",
    "## Initialize Trad Chinese dictionary\n",
    "jieba.set_dictionary('../../../RepositoryData/data/jiaba/dict.txt.jiebatw.txt')\n",
    "\n",
    "\n",
    "## Normalize unicode characters\n",
    "def remove_weird_chars(text):\n",
    "    #     ```\n",
    "    #     (NFKD) will apply the compatibility decomposition, i.e.\n",
    "    #     replace all compatibility characters with their equivalents.\n",
    "    #     ```\n",
    "    text = unicodedata.normalize('NFKD', text).encode('utf-8',\n",
    "                                                      'ignore').decode(\n",
    "                                                          'utf-8', 'ignore')\n",
    "    return text\n",
    "\n",
    "\n",
    "## Remove extra linebreaks\n",
    "def remove_extra_linebreaks(text):\n",
    "    lines = text.split(r'\\n+')\n",
    "    return '\\n'.join(\n",
    "        [re.sub(r'[\\s]+', ' ', l).strip() for l in lines if len(l) != 0])\n",
    "\n",
    "\n",
    "## Remove extra medial/trailing/leading spaces\n",
    "def remove_extra_spaces(text):\n",
    "    return re.sub(\"\\\\s+\", \" \", text).strip()\n",
    "\n",
    "\n",
    "## Seg the text into words\n",
    "def seg(text):\n",
    "    text_seg = jieba.cut(text)\n",
    "    out = ' '.join(text_seg)\n",
    "    return out\n",
    "\n",
    "\n",
    "## Remove punctuation/symbols\n",
    "def remove_symbols(text):\n",
    "    \"\"\"\n",
    "    \n",
    "    Unicode 6.0 has 7 character categories, and each category has subcategories:\n",
    "\n",
    "    Letter (L): lowercase (Ll), modifier (Lm), titlecase (Lt), uppercase (Lu), other (Lo)\n",
    "    Mark (M): spacing combining (Mc), enclosing (Me), non-spacing (Mn)\n",
    "    Number (N): decimal digit (Nd), letter (Nl), other (No)\n",
    "    Punctuation (P): connector (Pc), dash (Pd), initial quote (Pi), final quote (Pf), open (Ps), close (Pe), other (Po)\n",
    "    Symbol (S): currency (Sc), modifier (Sk), math (Sm), other (So)\n",
    "    Separator (Z): line (Zl), paragraph (Zp), space (Zs)\n",
    "    Other (C): control (Cc), format (Cf), not assigned (Cn), private use (Co), surrogate (Cs)\n",
    "    \n",
    "    \n",
    "    There are 3 ranges reserved for private use (Co subcategory): \n",
    "    U+E000—U+F8FF (6,400 code points), U+F0000—U+FFFFD (65,534) and U+100000—U+10FFFD (65,534). \n",
    "    Surrogates (Cs subcategory) use the range U+D800—U+DFFF (2,048 code points).\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    ## Brute-force version: list all possible unicode ranges, but this list is not complete.\n",
    "    #   text = re.sub('[\\u0021-\\u002f\\u003a-\\u0040\\u005b-\\u0060\\u007b-\\u007e\\u00a1-\\u00bf\\u2000-\\u206f\\u2013-\\u204a\\u20a0-\\u20bf\\u2100-\\u214f\\u2150-\\u218b\\u2190-\\u21ff\\u2200-\\u22ff\\u2300-\\u23ff\\u2460-\\u24ff\\u2500-\\u257f\\u2580-\\u259f\\u25a0-\\u25ff\\u2600-\\u26ff\\u2e00-\\u2e7f\\u3000-\\u303f\\ufe50-\\ufe6f\\ufe30-\\ufe4f\\ufe10-\\ufe1f\\uff00-\\uffef─◆╱]+','',text)\n",
    "\n",
    "    text = ''.join(ch for ch in text\n",
    "                   if unicodedata.category(ch)[0] not in ['P', 'S'])\n",
    "    return text\n",
    "\n",
    "\n",
    "## Remove numbers\n",
    "def remove_numbers(text):\n",
    "    return re.sub('\\\\d+', \"\", text)\n",
    "\n",
    "\n",
    "## Remove alphabets\n",
    "def remove_alphabets(text):\n",
    "    return re.sub('[a-zA-Z]+', '', text)\n",
    "\n",
    "\n",
    "## Combine every step\n",
    "def normalize_corpus(corpus,\n",
    "                     is_remove_extra_linebreaks=True,\n",
    "                     is_remove_weird_chars=True,\n",
    "                     is_seg=True,\n",
    "                     is_remove_symbols=True,\n",
    "                     is_remove_numbers=True,\n",
    "                     is_remove_alphabets=True):\n",
    "\n",
    "    normalized_corpus = []\n",
    "    # normalize each document in the corpus\n",
    "    for doc in corpus:\n",
    "\n",
    "        if is_remove_extra_linebreaks:\n",
    "            doc = remove_extra_linebreaks(doc)\n",
    "\n",
    "        if is_remove_weird_chars:\n",
    "            doc = remove_weird_chars(doc)\n",
    "\n",
    "        if is_seg:\n",
    "            doc = seg(doc)\n",
    "\n",
    "        if is_remove_symbols:\n",
    "            doc = remove_symbols(doc)\n",
    "\n",
    "        if is_remove_alphabets:\n",
    "            doc = remove_alphabets(doc)\n",
    "\n",
    "        if is_remove_numbers:\n",
    "            doc = remove_numbers(doc)\n",
    "\n",
    "        normalized_corpus.append(remove_extra_spaces(doc))\n",
    "\n",
    "    return normalized_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract an Article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Grab the first article from Google news for demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '\\r\\n中天換照案聽證會剛結束，但NCC表示，聽證會中，中天著重於和NCC「攻防」，許多問題都沒有釐清，因此最快下周會邀請中天代表到每周三的例行委員會補充陳述。另外，前立委黃國昌晚間在臉書爆料「旺中微信群組截圖」，NCC官員指出，會持續蒐集資訊，這些群組截圖也會作為參考。', '\\n', '\\r\\n中天換照案聽證會周一落幕，會中中天代表律師方伯勳針對違規案件數、裁罰不公等部分進行說明，但NCC官員表示，可能律師誤會當天是要「攻防戰」，關於聽證會設定的八大議題，包括是否已履行前次換照承諾、對過去營運不善情事未來如何確保改善、負責人是否影響新聞製播等，反而沒有完整說明。', '\\n', '\\r\\n為了釐清所有議題，NCC擬再請中天代表到會說明，最快於下周三例行委員會邀請。官員表示，沒有設定來說明的代表人必須是神旺投資董事長蔡衍明，律師出席也可以；官員指出，中天代表在聽證會上提到有自請四位「鑑定人」，雖然與聽證制度不符，但NCC也歡迎這幾位專家學者提供意見。', '\\n', '\\r\\nNCC發言人翁柏宗表示，將持續蒐集相關資資料。黃國昌晚間在個人粉絲團中張貼出疑似旺中集團管理階層的微信群組截圖，官員指出，這些資訊NCC「當然會列入參考」。', '\\n', '\\r\\nNCC官員表示，聽證會周一結束後，就要等NCC委員會將該換照案排進議程、再次審理，之後才會再評估是否要開第二次聽證會或公聽會，並在中天執照到期日十二月十一日前，做出是否准許換照的決定。', '\\n', '\\n', '\\n', '\\n', '\\n                    中天新聞台換照又有新進展。國家通訊傳播委員會（ＮＣＣ）昨天表示，由於中天新聞台在周一的聽證會中，著重於和ＮＣＣ「攻防」，...                  ', '\\n                    「請大家驗明真象，還給我蔡衍明一個公道。這一切的爆料打壓手法，根本就是穿鑿附會！」針對時代力量前立委黃國昌今天晚間在臉書...                  ', '\\n                    前立委黃國昌晚間在臉書爆料「旺中微信群組截圖」，流出內容提到民進黨前秘書長羅文嘉指旺中集團收受「對立政府」資助，群組內指...                  ', '\\n                    中天換照案聽證會剛結束，但NCC表示，聽證會中，中天著重於和NCC「攻防」，許多問題都沒有釐清，因此最快下周會邀請中天代...                  ', '\\n                    網路媒體「上報」報導，關於中天換照案，府院黨在10月中曾開會討論，且分為鷹派、鴿派討論如何處置，並達成有共識決定不碰此案...                  ', '\\n                    中天電視台換照作業，NCC首創聽證措施，留美法律博士高思博認為名為聽證，其實是在公審中天所擁有的新聞立場；質疑應居於中立...                  ', '\\n                    新北市議會國民黨團今進行聯合總質詢，一開場就針對中天電視台換照議題，要求新北市長侯友宜表態，並拿出連署板，邀侯現場簽名連...                  ', '\\n                    網路媒體「上報」報導，府院黨在10月中已有共識，千萬不能碰中天新聞台換照案，只能等國家通訊傳播委員會（NCC）決定再善後...                  ', '\\n                    中天新聞台年底是否撤照引發社會關注，國民黨主席江啟臣今天再次在中常會提醒民進黨，不應該用雙重標準來處理政治立場不同的新聞...                  ', '\\n                    中天電視台執照將於年底到期，由於中天新聞台的新聞內容，數度挑動台灣統獨敏感神經，媒體主管機關國家通訊傳播委員會（NCC）為減輕爭議，召開史上最長換照聽證會，會中NCC與中天雙方針對媒體適格性等8大主題進行攻防；但，聽證會後並未釐清相關爭議，會後反加深打壓異己或維護民主的二元攻防。                  ', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n']\n"
     ]
    }
   ],
   "source": [
    "url = 'https://news.google.com/topics/CAAqJQgKIh9DQkFTRVFvSUwyMHZNRFptTXpJU0JYcG9MVlJYS0FBUAE?hl=zh-TW&gl=TW&ceid=TW%3Azh-Hant'\n",
    "r = requests.get(url)\n",
    "web_content = r.text\n",
    "soup = BeautifulSoup(web_content, 'lxml')\n",
    "title = soup.find_all('a', class_='DY5T1d')\n",
    "first_art_link = title[0]['href'].replace('.', 'https://news.google.com', 1)\n",
    "\n",
    "#print(first_art_link)\n",
    "art_request = requests.get(first_art_link)\n",
    "art_request.encoding = 'utf8'\n",
    "soup_art = BeautifulSoup(art_request.text, 'lxml')\n",
    "\n",
    "art_content = soup_art.find_all('p')\n",
    "art_texts = [p.text for p in art_content]\n",
    "print(art_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Normalized results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /Users/Alvin/GoogleDrive/_MySyncDrive/RepositoryData/data/jiaba/dict.txt.jiebatw.txt ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from cache /var/folders/n7/ltpzwx813c599nfxfb94s_640000gn/T/jieba.u1b52b47246a0f2e6497af6bbe107adac.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.558 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['中天 換照 案 聽證會 剛 結束 但 表示 聽證會 中 中天 著重 於 和 攻防 許多 問題 都 沒有 釐清 因此 最 快 下周 會 邀請 中天 代表 到 每 周三 的 例行 委員會 補充 陳述 另外 前立委 黃國昌 晚間 在 臉書 爆料 旺中 微信 群組 截圖 官員 指出 會 持續 蒐集 資訊 這些 群組 截圖 也 會 作為 參考 中天 換照 案 聽證會 周一 落幕 會 中 中天 代表 律師 方伯勳 針對 違規 案件數 裁罰 不公 等 部分 進行 說明 但 官員 表示 可能 律師 誤會 當天 是 要 攻防戰 關於 聽證會 設定 的 八大 議題 包括 是否 已 履行 前次 換照 承諾 對 過去 營運 不善 情事 未來 如何 確保 改善 負責人 是否 影響 新聞 製播 等 反而 沒有 完整 說明 為了 釐清 所有 議題 擬再 請 中天 代表 到 會 說明 最 快於 下 周三 例行 委員會 邀請 官員 表示 沒有 設定 來 說明 的 代表人 必須 是 神旺 投資 董事長 蔡衍明 律師 出席 也 可以 官員 指出 中天 代表 在 聽證會 上 提到 有 自請 四位 鑑定人 雖然 與 聽證 制度 不符 但 也 歡迎 這幾位 專家 學者 提供 意見 發言人 翁柏宗 表示 將 持續 蒐集 相關 資 資料 黃國昌 晚間 在 個 人 粉絲團 中 張貼 出 疑似 旺中 集團 管理 階層 的 微信 群組 截圖 官員 指出 這些 資訊 當然 會 列入 參考 官員 表示 聽證會 周一 結束 後 就 要 等 委員會 將該 換照 案 排進 議程 再次 審理 之後 才 會 再 評估 是否 要開 第二次 聽證會 或 公聽會 並在 中天 執照 到期日 十二月 十一日 前 做出 是否 准許 換照 的 決定 中天 新聞台 換照 又 有 新進展 國家 通訊 傳播 委員會 昨天 表示 由於 中天 新聞台 在 周一 的 聽證會 中 著重 於 和 攻防 請 大家 驗明 真象 還給 我 蔡衍明 一個 公道 這一 切 的 爆料 打壓 手法 根本 就是 穿鑿附會 針對 時代 力量 前立委 黃國昌 今天 晚間 在 臉書 前立委 黃國昌 晚間 在 臉書 爆料 旺中 微信 群組 截圖 流出 內容 提到 民進黨 前 秘書長 羅文嘉 指 旺中 集團 收受 對立 政府 資助 群組 內指 中天 換照 案 聽證會 剛 結束 但 表示 聽證會 中 中天 著重 於 和 攻防 許多 問題 都 沒有 釐清 因此 最 快 下周 會 邀請 中天 代 網路 媒體 上報 報導 關於 中天 換照 案 府院 黨 在 月 中 曾 開會 討論 且 分為 鷹派 鴿派 討論 如何 處置 並 達成 有 共識 決定 不 碰 此案 中天 電視台 換照 作業 首創 聽證 措施 留美 法律 博士 高思博 認為 名為 聽證 其實 是 在 公審 中天 所 擁有 的 新聞 立場 質疑 應 居於 中立 新北 市議會 國民黨團 今 進行 聯合 總質詢 一 開場 就 針對 中天 電視台 換照 議題 要求 新北 市長 侯友宜 表態 並 拿出 連署 板 邀侯 現場 簽名 連 網路 媒體 上報 報導 府院 黨 在 月 中 已 有 共識 千萬 不能 碰 中天 新聞台 換照 案 只能 等 國家 通訊 傳播 委員會 決定 再 善後 中天 新聞台 年底 是否 撤照 引發 社會 關注 國民黨 主席 江啟臣 今天 再次 在 中常會 提醒 民進黨 不應該 用 雙重 標準 來 處理 政治 立場 不同 的 新聞 中天 電視台 執照 將於 年底 到期 由於 中天 新聞台 的 新聞 內容 數度 挑動 台灣 統獨 敏感 神經 媒體 主管 機關 國家 通訊 傳播 委員會 為 減輕 爭議 召開 史上 最長 換照 聽證會 會 中 與 中天 雙方 針對 媒體 適格性 等 大 主題 進行 攻防 但 聽證會 後 並未 釐清 相關 爭議 會後反 加深 打壓 異己 或 維護 民主 的 二元 攻防']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tnz.normalize_corpus([' '.join(art_texts)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-notes",
   "language": "python",
   "name": "python-notes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}