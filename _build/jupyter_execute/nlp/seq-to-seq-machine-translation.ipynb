{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Translation (Sequence-to-Sequence)\n",
    "\n",
    "- Character-based machine translation using seq-to-seq model\n",
    "- This is based on:\n",
    "    - [A ten-minute introduction to sequence-to-sequence learning in Keras](https://keras.io/examples/nlp/lstm_seq2seq/)\n",
    "    - [Day 18:機器翻譯(Machine Translation](https://ithelp.ithome.com.tw/articles/10194403)\n",
    "- Data: \n",
    "    - [English to French sentence pairs](http://www.manythings.org/anki/fra-eng.zip)\n",
    "    - [Paired Datasets of Other languages](http://www.manythings.org/anki/)\n",
    "- References\n",
    "    - [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215)\n",
    "    - [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](https://arxiv.org/abs/1406.1078)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 100  # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "num_samples = 10000  # Number of samples to train on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 10000\n",
      "Number of unique input tokens: 73\n",
      "Number of unique output tokens: 2640\n",
      "Max sequence length for inputs: 31\n",
      "Max sequence length for outputs: 22\n"
     ]
    }
   ],
   "source": [
    "# Path to the data txt file on disk.\n",
    "data_path = '../../../RepositoryData/data/cmn.txt'\n",
    "\n",
    "# Vectorize the data.\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text = line.split('\\t')\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "\n",
    "# Sort Dictionary\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "\n",
    "# Find maxinum sent lengths \n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "print('Number of samples:', len(input_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create char index dictionary\n",
    "## char as the key and index as the value\n",
    "input_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "\n",
    "# Initialize encoder/decoder\n",
    "\n",
    "\n",
    "## Both input output are three dimensional tensors,\n",
    "## consisting of each sentence, with all words encoded in one-hot.\n",
    "\n",
    "## Input tensor dimensions: [input_batch_size, input_sequence_length, input_vecob/char_size]\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "\n",
    "## Output tensor dimensions: [output_batch_size, output_sequence_length, output_vecob/char_size]\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode input and output texts\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
    "    decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n",
    "    decoder_target_data[i, t:, target_token_index[' ']] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define Model\n",
    "\n",
    "\n",
    "## Set up encoder\n",
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens)) # one word at a time, with vocab_size dimension, i.e., one-hot encoding\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c] # concatenate the states_h and states_c from encoder ?\n",
    "\n",
    "## the encoder_states shape: [state_h + state+c, latent_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens)) # one word at a time, with vocab_size dimension,\n",
    "\n",
    "# We set up our decoder to return full output sequences, (i.e, `return_sequences=True`)\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "\n",
    "## softmax the decoder outputs to get prob of target language word\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "import pydot\n",
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run training\n",
    "# model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "# model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "#           validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "# model.save('../data/s2s-cmn.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 73)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None, 2640)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 256), (None, 337920      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 256),  2966528     input_2[0][0]                    \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 2640)   678480      lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 3,982,928\n",
      "Trainable params: 3,982,928\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If the model is loaded via external files\n",
    "## Load the encoder_model, decoder_model this way\n",
    "from keras.models import load_model\n",
    "model.load_weights('../../../RepositoryData/data/s2s-cmn.h5')\n",
    "\n",
    "\n",
    "\n",
    "## Create Inference model\n",
    "encoder_inputs = model.input[0] #input_1\n",
    "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output # lstm_1\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "\n",
    "decoder_inputs = model.input[1] #input_2\n",
    "decoder_state_input_h = Input(shape=(latent_dim,),name='input_3') # state_h\n",
    "decoder_state_input_c = Input(shape=(latent_dim,),name='input_4') # state_c\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c] # concat state_h and state_c\n",
    "\n",
    "decoder_lstm = model.layers[3]\n",
    "\n",
    "## In training, we use `decoder_ouputs` only.\n",
    "## In inferencing, we need `decoder_c, and decoder_h`\n",
    "## because these c and h form the basis for next decoder input\n",
    "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h_dec, state_c_dec]\n",
    "decoder_dense = model.layers[4]\n",
    "decoder_outputs=decoder_dense(decoder_outputs)\n",
    "\n",
    "\n",
    "## Inference Model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs, # target sentence + encoder output h+c\n",
    "    [decoder_outputs] + decoder_states) # decoder predicted char + decoder predicted h+c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: 你好。\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: 你好。\n",
      "\n",
      "-\n",
      "Input sentence: Run.\n",
      "Decoded sentence: 你用跑的。\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: 等等！\n",
      "\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: 你好。\n",
      "\n",
      "-\n",
      "Input sentence: I try.\n",
      "Decoded sentence: 让我来。\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: 我赢了。\n",
      "\n",
      "-\n",
      "Input sentence: Oh no!\n",
      "Decoded sentence: 不会吧。\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: 乾杯!\n",
      "\n",
      "-\n",
      "Input sentence: He ran.\n",
      "Decoded sentence: 他跑了。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    \n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    \n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.0\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    \n",
    "    while not stop_condition:\n",
    "        # inference starts at the first target char\n",
    "        # first target char + encoder output h + c\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        ## Choose the output char of the argmax prob\n",
    "        ## one-hot decode the char and append to the `decoded_sentence`\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        ## everytime the target_seq is the cur_t char, one char a time\n",
    "        ## the shape should be [1, ,1 vocab_size]\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.0\n",
    "\n",
    "        # Update states\n",
    "        ## the h and c output from decoder at cur_t\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "for seq_index in range(10):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-notes",
   "language": "python",
   "name": "python-notes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}