{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lexical Bundles\n",
    "\n",
    "This section talks about how to identify recurring multiword sequences from texts, which has received a lot of attention in recent years in language studies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import reuters\n",
    "from nltk import ngrams\n",
    "from collections import Counter, defaultdict\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demonstration, we use the `reuters` corpus as our data source, which has been made available in the `nltk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"ASIAN EXPORTERS FEAR DAMAGE FROM U . S .- JAPAN RIFT Mounting trade friction between the U . S . And Japan has raised fears among many of Asia ' s exporting nations that the row could inflict far - reaching economic damage , businessmen and officials said .\", 'They told Reuter correspondents in Asian capitals a U . S . Move against Japan might boost protectionist sentiment in the U . S . And lead to curbs on American imports of their products .', \"But some exporters said that while the conflict would hurt them in the long - run , in the short - term Tokyo ' s loss might be their gain .\", \"The U . S . Has said it will impose 300 mln dlrs of tariffs on imports of Japanese electronics goods on April 17 , in retaliation for Japan ' s alleged failure to stick to a pact not to sell semiconductors on world markets at below cost .\", 'Unofficial Japanese estimates put the impact of the tariffs at 10 billion dlrs and spokesmen for major electronics firms said they would virtually halt exports of products hit by the new taxes .']\n"
     ]
    }
   ],
   "source": [
    "## A quick look at the first five sentences\n",
    "print([' '.join(sent) for sent in reuters.sents()[:5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexical Bundles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lexical bundles refer to any contiguous multiword sequences from the texts. Normally, research on lexical bundles examine the multiword sequences of sizes from four- to seven-word sequences.\n",
    "\n",
    "The idea of lexical bundles is essentially the ngrams in NLP, which `N` refers to the size of the multiword sequence.\n",
    "\n",
    "To extract a meaningful set of lexical bundles, we need to consider at least two important distributional criteria:\n",
    "\n",
    "- **Frequency** of the bundle: how often does the sequence occur in the entire corpus?\n",
    "- **Range** of the bundle: in how many different texts/documents does the sequence occur in the entire corpus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10788"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Number of documents in `reuters`\n",
    "len(reuters.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a placeholder for 4gram bundles statistics\n",
    "bundles_4 = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "bundles_range = defaultdict(lambda: defaultdict(lambda: 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('They', 'told', 'Reuter', 'correspondents'),\n",
       " ('told', 'Reuter', 'correspondents', 'in'),\n",
       " ('Reuter', 'correspondents', 'in', 'Asian'),\n",
       " ('correspondents', 'in', 'Asian', 'capitals'),\n",
       " ('in', 'Asian', 'capitals', 'a'),\n",
       " ('Asian', 'capitals', 'a', 'U'),\n",
       " ('capitals', 'a', 'U', '.'),\n",
       " ('a', 'U', '.', 'S'),\n",
       " ('U', '.', 'S', '.'),\n",
       " ('.', 'S', '.', 'Move'),\n",
       " ('S', '.', 'Move', 'against'),\n",
       " ('.', 'Move', 'against', 'Japan'),\n",
       " ('Move', 'against', 'Japan', 'might'),\n",
       " ('against', 'Japan', 'might', 'boost'),\n",
       " ('Japan', 'might', 'boost', 'protectionist'),\n",
       " ('might', 'boost', 'protectionist', 'sentiment'),\n",
       " ('boost', 'protectionist', 'sentiment', 'in'),\n",
       " ('protectionist', 'sentiment', 'in', 'the'),\n",
       " ('sentiment', 'in', 'the', 'U'),\n",
       " ('in', 'the', 'U', '.'),\n",
       " ('the', 'U', '.', 'S'),\n",
       " ('U', '.', 'S', '.'),\n",
       " ('.', 'S', '.', 'And'),\n",
       " ('S', '.', 'And', 'lead'),\n",
       " ('.', 'And', 'lead', 'to'),\n",
       " ('And', 'lead', 'to', 'curbs'),\n",
       " ('lead', 'to', 'curbs', 'on'),\n",
       " ('to', 'curbs', 'on', 'American'),\n",
       " ('curbs', 'on', 'American', 'imports'),\n",
       " ('on', 'American', 'imports', 'of'),\n",
       " ('American', 'imports', 'of', 'their'),\n",
       " ('imports', 'of', 'their', 'products'),\n",
       " ('of', 'their', 'products', '.')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[n for n in ngrams(reuters.sents()[1],n=4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.1 s, sys: 1.15 s, total: 20.2 s\n",
      "Wall time: 21.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Count frequency of co-occurance  \n",
    "for fid in reuters.fileids():\n",
    "    temp = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "    for sentence in reuters.sents(fileids=fid):\n",
    "        for w1, w2, w3, w4 in ngrams(sentence, n=4, pad_right=False, pad_left=False):\n",
    "            ## filter\n",
    "            if re.match(r'\\w+',w1) and re.match(r'\\w+',w2) and re.match(r'\\w+',w3) and re.match(r'\\w+', w4):\n",
    "                bundles_4[(w1, w2, w3)][w4] += 1\n",
    "                temp[(w1, w2, w3)][w4] += 1\n",
    "    # range value\n",
    "    for key, value in temp.items():\n",
    "        for k in value.keys():\n",
    "            bundles_range[key][k] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('ASIAN', 'EXPORTERS', 'FEAR'),\n",
       "  defaultdict(<function __main__.<lambda>.<locals>.<lambda>()>,\n",
       "              {'DAMAGE': 1})),\n",
       " (('EXPORTERS', 'FEAR', 'DAMAGE'),\n",
       "  defaultdict(<function __main__.<lambda>.<locals>.<lambda>()>, {'FROM': 1})),\n",
       " (('FEAR', 'DAMAGE', 'FROM'),\n",
       "  defaultdict(<function __main__.<lambda>.<locals>.<lambda>()>, {'U': 1})),\n",
       " (('JAPAN', 'RIFT', 'Mounting'),\n",
       "  defaultdict(<function __main__.<lambda>.<locals>.<lambda>()>, {'trade': 1})),\n",
       " (('RIFT', 'Mounting', 'trade'),\n",
       "  defaultdict(<function __main__.<lambda>.<locals>.<lambda>()>,\n",
       "              {'friction': 1}))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(bundles_4.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('ASIAN', 'EXPORTERS', 'FEAR'),\n",
       "  defaultdict(<function __main__.<lambda>.<locals>.<lambda>()>,\n",
       "              {'DAMAGE': 1})),\n",
       " (('EXPORTERS', 'FEAR', 'DAMAGE'),\n",
       "  defaultdict(<function __main__.<lambda>.<locals>.<lambda>()>, {'FROM': 1})),\n",
       " (('FEAR', 'DAMAGE', 'FROM'),\n",
       "  defaultdict(<function __main__.<lambda>.<locals>.<lambda>()>, {'U': 1})),\n",
       " (('JAPAN', 'RIFT', 'Mounting'),\n",
       "  defaultdict(<function __main__.<lambda>.<locals>.<lambda>()>, {'trade': 1})),\n",
       " (('RIFT', 'Mounting', 'trade'),\n",
       "  defaultdict(<function __main__.<lambda>.<locals>.<lambda>()>,\n",
       "              {'friction': 1}))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(bundles_range.items())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to data frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For more intuitive reading of the bundles data, we can create a data frame with the distributional information of each bundle type.\n",
    "- Most importantly, we can filter and sort our bundle data nicely and easily with the functionality provided with the data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create three lists:\n",
    "\n",
    "- `w1_w2_w3`: the first three words in the bundle\n",
    "- `w4`: the last word in the bundle\n",
    "- `freq`: freq of the bundle\n",
    "- `range`: range of the bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.19 s, sys: 81.7 ms, total: 1.27 s\n",
      "Wall time: 3.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "\n",
    "w1_w2_w3 = []\n",
    "w4 = []\n",
    "freq = []\n",
    "rangev = []\n",
    "for _w123 in bundles_4.keys():\n",
    "    for _w4 in bundles_4[_w123].keys():\n",
    "        w1_w2_w3.append('_'.join(_w123))\n",
    "        w4.append(_w4)\n",
    "        freq.append(bundles_4[_w123][_w4])\n",
    "        rangev.append(bundles_range[_w123][_w4])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the lengths of the four lists before combining them into a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "691190\n",
      "691190\n",
      "691190\n"
     ]
    }
   ],
   "source": [
    "print(len(w1_w2_w3))\n",
    "print(len(w4))\n",
    "print(len(freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the bundle data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w123</th>\n",
       "      <th>w4</th>\n",
       "      <th>freq</th>\n",
       "      <th>range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASIAN_EXPORTERS_FEAR</td>\n",
       "      <td>DAMAGE</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EXPORTERS_FEAR_DAMAGE</td>\n",
       "      <td>FROM</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FEAR_DAMAGE_FROM</td>\n",
       "      <td>U</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JAPAN_RIFT_Mounting</td>\n",
       "      <td>trade</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RIFT_Mounting_trade</td>\n",
       "      <td>friction</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    w123        w4  freq  range\n",
       "0   ASIAN_EXPORTERS_FEAR    DAMAGE     1      1\n",
       "1  EXPORTERS_FEAR_DAMAGE      FROM     1      1\n",
       "2       FEAR_DAMAGE_FROM         U     1      1\n",
       "3    JAPAN_RIFT_Mounting     trade     1      1\n",
       "4    RIFT_Mounting_trade  friction     1      1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bundles_df =pd.DataFrame(list(zip(w1_w2_w3, w4, freq, rangev)),\n",
    "                        columns=['w123','w4','freq','range'])\n",
    "bundles_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter bundles whose `range` >= 10 and arrange the data frame according to bundles' `range` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w123</th>\n",
       "      <th>w4</th>\n",
       "      <th>freq</th>\n",
       "      <th>range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5717</th>\n",
       "      <td>Securities_and_Exchange</td>\n",
       "      <td>Commission</td>\n",
       "      <td>275</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4813</th>\n",
       "      <td>said_in_a</td>\n",
       "      <td>statement</td>\n",
       "      <td>264</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5714</th>\n",
       "      <td>the_Securities_and</td>\n",
       "      <td>Exchange</td>\n",
       "      <td>258</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47163</th>\n",
       "      <td>3RD_QTR_NET</td>\n",
       "      <td>Shr</td>\n",
       "      <td>233</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7112</th>\n",
       "      <td>The_company_said</td>\n",
       "      <td>the</td>\n",
       "      <td>230</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46330</th>\n",
       "      <td>mln_Nine_mths</td>\n",
       "      <td>Shr</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7103</th>\n",
       "      <td>The_company_said</td>\n",
       "      <td>it</td>\n",
       "      <td>213</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6357</th>\n",
       "      <td>at_the_end</td>\n",
       "      <td>of</td>\n",
       "      <td>250</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51576</th>\n",
       "      <td>4TH_QTR_NET</td>\n",
       "      <td>Shr</td>\n",
       "      <td>178</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60176</th>\n",
       "      <td>with_the_Securities</td>\n",
       "      <td>and</td>\n",
       "      <td>162</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25083</th>\n",
       "      <td>cts_prior_Pay</td>\n",
       "      <td>April</td>\n",
       "      <td>161</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11887</th>\n",
       "      <td>pct_of_the</td>\n",
       "      <td>total</td>\n",
       "      <td>162</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40339</th>\n",
       "      <td>QTR_LOSS_Shr</td>\n",
       "      <td>loss</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24004</th>\n",
       "      <td>Inc_said_it</td>\n",
       "      <td>has</td>\n",
       "      <td>141</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26751</th>\n",
       "      <td>1ST_QTR_NET</td>\n",
       "      <td>Shr</td>\n",
       "      <td>137</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49905</th>\n",
       "      <td>QTR_JAN_31</td>\n",
       "      <td>NET</td>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60168</th>\n",
       "      <td>a_filing_with</td>\n",
       "      <td>the</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>said_it_expects</td>\n",
       "      <td>to</td>\n",
       "      <td>136</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33141</th>\n",
       "      <td>JAN_31_NET</td>\n",
       "      <td>Shr</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9673</th>\n",
       "      <td>The_Bank_of</td>\n",
       "      <td>England</td>\n",
       "      <td>129</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          w123          w4  freq  range\n",
       "5717   Securities_and_Exchange  Commission   275    271\n",
       "4813                 said_in_a   statement   264    260\n",
       "5714        the_Securities_and    Exchange   258    254\n",
       "47163              3RD_QTR_NET         Shr   233    233\n",
       "7112          The_company_said         the   230    211\n",
       "46330            mln_Nine_mths         Shr   203    203\n",
       "7103          The_company_said          it   213    197\n",
       "6357                at_the_end          of   250    178\n",
       "51576              4TH_QTR_NET         Shr   178    178\n",
       "60176      with_the_Securities         and   162    162\n",
       "25083            cts_prior_Pay       April   161    157\n",
       "11887               pct_of_the       total   162    156\n",
       "40339             QTR_LOSS_Shr        loss   142    142\n",
       "24004              Inc_said_it         has   141    141\n",
       "26751              1ST_QTR_NET         Shr   137    137\n",
       "49905               QTR_JAN_31         NET   133    133\n",
       "60168            a_filing_with         the   130    130\n",
       "21944          said_it_expects          to   136    130\n",
       "33141               JAN_31_NET         Shr   129    129\n",
       "9673               The_Bank_of     England   129    126"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bundles_df[(bundles_df['range']>=10)].sort_values(['range'], ascending=[False]).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify bundles with w4 being either `in` or `to`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w123</th>\n",
       "      <th>w4</th>\n",
       "      <th>freq</th>\n",
       "      <th>range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>said_it_expects</td>\n",
       "      <td>to</td>\n",
       "      <td>136</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33219</th>\n",
       "      <td>said_it_agreed</td>\n",
       "      <td>to</td>\n",
       "      <td>113</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42141</th>\n",
       "      <td>said_it_plans</td>\n",
       "      <td>to</td>\n",
       "      <td>84</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88616</th>\n",
       "      <td>agreed_in_principle</td>\n",
       "      <td>to</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45606</th>\n",
       "      <td>letter_of_intent</td>\n",
       "      <td>to</td>\n",
       "      <td>72</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85882</th>\n",
       "      <td>it_has_agreed</td>\n",
       "      <td>to</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60690</th>\n",
       "      <td>a_definitive_agreement</td>\n",
       "      <td>to</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62568</th>\n",
       "      <td>cts_a_share</td>\n",
       "      <td>in</td>\n",
       "      <td>65</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37697</th>\n",
       "      <td>dlrs_a_share</td>\n",
       "      <td>in</td>\n",
       "      <td>54</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>who_asked_not</td>\n",
       "      <td>to</td>\n",
       "      <td>41</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>in_an_effort</td>\n",
       "      <td>to</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85883</th>\n",
       "      <td>it_has_agreed</td>\n",
       "      <td>in</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25651</th>\n",
       "      <td>will_be_used</td>\n",
       "      <td>to</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42760</th>\n",
       "      <td>5_mln_dlrs</td>\n",
       "      <td>in</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2215</th>\n",
       "      <td>in_the_year</td>\n",
       "      <td>to</td>\n",
       "      <td>42</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29471</th>\n",
       "      <td>transaction_is_subject</td>\n",
       "      <td>to</td>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65576</th>\n",
       "      <td>will_be_able</td>\n",
       "      <td>to</td>\n",
       "      <td>33</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60148</th>\n",
       "      <td>raised_its_stake</td>\n",
       "      <td>in</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33220</th>\n",
       "      <td>said_it_agreed</td>\n",
       "      <td>in</td>\n",
       "      <td>32</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54249</th>\n",
       "      <td>dlrs_per_share</td>\n",
       "      <td>in</td>\n",
       "      <td>32</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         w123  w4  freq  range\n",
       "21944         said_it_expects  to   136    130\n",
       "33219          said_it_agreed  to   113    111\n",
       "42141           said_it_plans  to    84     82\n",
       "88616     agreed_in_principle  to    75     75\n",
       "45606        letter_of_intent  to    72     71\n",
       "85882           it_has_agreed  to    48     48\n",
       "60690  a_definitive_agreement  to    48     48\n",
       "62568             cts_a_share  in    65     47\n",
       "37697            dlrs_a_share  in    54     45\n",
       "769             who_asked_not  to    41     40\n",
       "1603             in_an_effort  to    38     38\n",
       "85883           it_has_agreed  in    35     35\n",
       "25651            will_be_used  to    34     34\n",
       "42760              5_mln_dlrs  in    33     33\n",
       "2215              in_the_year  to    42     33\n",
       "29471  transaction_is_subject  to    34     32\n",
       "65576            will_be_able  to    33     31\n",
       "60148        raised_its_stake  in    31     31\n",
       "33220          said_it_agreed  in    32     31\n",
       "54249          dlrs_per_share  in    32     29"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bundles_df[(bundles_df['range']>=10) & (bundles_df['w4'].isin(['in','to']))].sort_values(['range'], ascending=[False]).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restructure dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## filter and sort\n",
    "\n",
    "# ## remove ngrams with non-word characters\n",
    "# bundles_4_2 = {(w1,w2,w3):value for (w1,w2,w3), value in bundles_4.items() if \n",
    "#                re.match(r'\\w+',w1) and re.match(r'\\w+',w2) and re.match(r'\\w+',w3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(bundles_4))\n",
    "# print(len(bundle_4_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## remove ngrams whose freq < 5 and w4 with non-word characters\n",
    "# bundles_4_3 = {}\n",
    "# for w1_w2_w3 in bundles_4_2:\n",
    "#     bundles_4_3[w1_w2_w3] = {w4:v for w4, v in bundles_4[w1_w2_w3].items() if v >= 5 and re.match(r'\\w+',w4)}\n",
    "\n",
    "# ## clean up dictionary\n",
    "# bundles_4_3 = {key:value for key,value in bundles_4_3.items() if len(value)!=0}\n",
    "    \n",
    "# print(list(bundles_4_3.items())[:5])\n",
    "# print(len(bundles_4_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  # From raw frequencies to forward transitional probabilities\n",
    "# for w1_w2_w3 in bundles_4:\n",
    "#     total_count = float(sum(bundles_4[w1_w2_w3].values()))\n",
    "#     for w4 in bundles_4[w1_w2_w3]:\n",
    "#         bundles_4[w1_w2_w3][w4] /= total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## flatten the dictionary\n",
    "# bundles_4_4 = {}\n",
    "# for w1_w2_w3 in bundles_4_3:\n",
    "#     for w4 in bundles_4_3[w1_w2_w3]:\n",
    "#         ngram = list(w1_w2_w3)+[w4]\n",
    "#         bundles_4_4[tuple(ngram)] = bundles_4_3[w1_w2_w3][w4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(bundles_4_4.items(), key=lambda x:x[1],reverse=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-notes",
   "language": "python",
   "name": "python-notes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
