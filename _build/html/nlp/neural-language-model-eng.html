

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Neural Language Model of English &#8212; Python Notes for Linguistics</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mycss.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'nlp/neural-language-model-eng';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
    
    
      
    
    
    <img src="../_static/ntnu-word-2.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../_static/ntnu-word-2.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Python Basics</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../python-basics/python-basics.html">Python Basics</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../python-basics/data-structure.html">Data Structure</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python-basics/program-structure.html">Program Structure</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python-basics/regex.html">Regular Expression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python-basics/input-output.html">Input and Output</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python-basics/oop.html">Object-Oriented Programming</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python-basics/docstrings.html">Docstrings Format</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../python-basics/jupyter.html">Jupyter</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../python-basics/jupyter-notebook.html">Jupyer Notebook</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python-basics/notebook-to-slides.html">Notebook to Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python-basics/google-colab.html">Google Colaboratory (Colab)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python-basics/google-colab-r.html">Google Colab R</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../python-basics/data-science.html">Data Science Tools</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../python-basics/numpy.html">Numpy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python-basics/pandas.html">Pandas</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python-basics/pickle.html">Object Serialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python-basics/data-visualization-1.html">Data Visualization I</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python-basics/data-visualization-2.html">Data Visualization 2</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../python-basics/advanced-skills.html">Advanced Skills</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../python-basics/magic-r.html">Magic R</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python-basics/python-tricks.html">Python Tricks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python-basics/web-applications.html">Web Applications</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python-basics/google-drive-ubuntu.html">Google Drive with Ubuntu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python-basics/productive-tech.html">Phythonic Productivity Techniques</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python-basics/miscellaneous-notes.html">Miscellaneous Notes</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Corpus Processing with Python</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../corpus/corpus-processing.html">Corpus Linguistics with Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../corpus/nltk.html">Natural Language Tool-Kits (NLTK)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../corpus/web-crawler.html">Web Crawler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../corpus/web-crawler-dcard.html">Web Crawler (Dcard)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../corpus/unicode.html">Unicode</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../corpus/corpus-linguistics-methods.html">Corpus Lingustics Methods</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../corpus/lexical-bundles.html">Lexical Bundles</a></li>
<li class="toctree-l2"><a class="reference internal" href="../corpus/tokenization.html">Tokenization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../corpus/wordnet.html">WordNet</a></li>
<li class="toctree-l2"><a class="reference internal" href="../corpus/word-cloud.html">Word Cloud</a></li>
<li class="toctree-l2"><a class="reference internal" href="../corpus/patterns-constructions.html">Patterns and Constructions</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../corpus/structured-corpus-processing.html">Structured Corpus Processing</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../corpus/bnc.html">BNC-XML</a></li>
<li class="toctree-l2"><a class="reference internal" href="../corpus/childes.html">CHILDES Corpus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../corpus/praat-textgrid.html">Praat TextGrid Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../corpus/vectorizing-text.html">Vectorizing Texts</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../corpus/chinese-processing.html">Chinese Processing</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../corpus/jieba.html">Chinese Word Segmentation (jieba)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../corpus/ckiptagger.html">Chinese Word Segmentation (ckiptagger)</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Statistics with Python</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../statistical-analyses/statistical-analyses.html">Statistical Analyses</a></li>
<li class="toctree-l1"><a class="reference internal" href="../statistical-analyses/descriptive-statistics.html">Descriptive Statistics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../statistical-analyses/analytic-statistics.html">Analytic Statistics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../statistical-analyses/network-analysis.html">Network Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../statistical-analyses/network-analysis-igraph.html">Network Analysis Using Igraph</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">NLP with Python</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="nlp.html">Natural Language Processing with Python</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="nlp-primer.html">Natural Language Processing: A Primer</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="nlp-pipeline.html">NLP Pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="nlp-spacy.html">Natural Language Processing (spaCy)</a></li>
<li class="toctree-l2"><a class="reference internal" href="nlp-spacy-zh.html">Chinese Natural Language Processing (spaCy)</a></li>
<li class="toctree-l2"><a class="reference internal" href="nlp-ckipnlp.html">Natural Language Processing (ckipnlp)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="text-normalization-intro.html">Text Normalization</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="text-normalization-eng.html">Text Normalization (English)</a></li>
<li class="toctree-l2"><a class="reference internal" href="text-normalization-chinese.html">Text Normalization (Chinese)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="ml-overview.html">Machine Learning Overview</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="ml-sklearn-regression.html">Machine Learning with Sklearn – Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="ml-sklearn-classification.html">Machine Learning with Sci-Kit Learn</a></li>
<li class="toctree-l2"><a class="reference internal" href="naive-bayes.html">Naive Bayes</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="sentiment-analysis-ml.html">Sentiment Analysis with Traditional Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="neural-network-from-scratch.html">Neural Network From Scratch</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="language-model.html">Language Model</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="neural-language-model-primer.html">Neural Language Model: A Start</a></li>
<li class="toctree-l2"><a class="reference internal" href="neural-language-model-zh.html">Neural Language Model of Chinese</a></li>
<li class="toctree-l2"><a class="reference internal" href="text-gen-lstm-v1.html">Text Generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpt2.html">Transformer-based Language Model - GPT2</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="word-embeddings.html">Word Embeddings</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="word2vec.html">Word2Vec</a></li>
<li class="toctree-l2"><a class="reference internal" href="doc2vec.html">Dov2Vec</a></li>
<li class="toctree-l2"><a class="reference internal" href="word-embeddings-autoencoder.html">Generate Text Embeddings Using AutoEncoder</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="transfer-learning-sent-encoding.html">Universal Sentence Embeddings</a></li>
<li class="toctree-l1"><a class="reference internal" href="sentiment-analysis-dl.html">Sentiment Analysis with Deep Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="sentiment-analysis-lstm-v1.html">Sentiment Analysis with LSTM</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="seq-to-seq-types.html">Intutions for Types of Sequence-to-Sequence Models</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="seq-to-seq-types-date.html">Types of Seqeunce Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="seq-to-seq-m21-sentiment-attention.html">Sequence Model (many-to-one) with Attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="seq-to-seq-attention-addition.html">Seqeunce Model with Attention for Addition Learning</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="seq-to-seq-machine-translation.html">Machine Translation (Sequence-to-Sequence)</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="seq-to-seq-machine-translation-attention.html">Machine Translation with Attention (Thushan)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="hyperparameter-tuning.html">Hyper-Parameter Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="sentiment-analysis-using-bert-chinese.html">Sentiment Analysis Using BERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="ktrain-tutorial-explaining-predictions.html">Explainable AI</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Appendix</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../appendix/todo.html">To-do List</a></li>
<li class="toctree-l1"><a class="reference internal" href="../appendix/references.html">References</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/alvinntnu/python-notes/blob/master/nlp/neural-language-model-eng.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/nlp/neural-language-model-eng.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>

</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Neural Language Model of English</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="neural-language-model-of-english">
<h1>Neural Language Model of English<a class="headerlink" href="#neural-language-model-of-english" title="Permalink to this headline">#</a></h1>
<ul class="simple">
<li><p><a class="reference external" href="https://machinelearningmastery.com/how-to-develop-a-word-level-neural-language-model-in-keras/">How to development a word-level neural language model in keras</a></p></li>
<li><p>English texts</p></li>
<li><p>Word-based neural language model based on word sequences of 50 words</p></li>
<li><p>Use the republic texts</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">string</span>


<span class="c1"># load doc into memory</span>
<span class="k">def</span> <span class="nf">load_doc</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
    <span class="c1"># open the file as read only</span>
    <span class="n">file</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span>
    <span class="c1"># read all text</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">file</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
    <span class="c1"># close the file</span>
    <span class="n">file</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">text</span>


<span class="c1"># turn a doc into clean tokens</span>
<span class="k">def</span> <span class="nf">clean_doc</span><span class="p">(</span><span class="n">doc</span><span class="p">):</span>
    <span class="c1"># replace &#39;--&#39; with a space &#39; &#39;</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="n">doc</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="s1">&#39; &#39;</span><span class="p">)</span>
    <span class="c1"># split into tokens by white space</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">doc</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="c1"># remove punctuation from each token</span>
    <span class="n">table</span> <span class="o">=</span> <span class="nb">str</span><span class="o">.</span><span class="n">maketrans</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">string</span><span class="o">.</span><span class="n">punctuation</span><span class="p">)</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="o">.</span><span class="n">translate</span><span class="p">(</span><span class="n">table</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">]</span>
    <span class="c1"># remove remaining tokens that are not alphabetic</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tokens</span> <span class="k">if</span> <span class="n">word</span><span class="o">.</span><span class="n">isalpha</span><span class="p">()]</span>
    <span class="c1"># make lower case</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">word</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">tokens</span>


<span class="c1"># save tokens to file, one dialog per line</span>
<span class="k">def</span> <span class="nf">save_doc</span><span class="p">(</span><span class="n">lines</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
    <span class="n">data</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">lines</span><span class="p">)</span>
    <span class="n">file</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span>
    <span class="n">file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">file</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>


<span class="c1"># load document</span>
<span class="n">in_filename</span> <span class="o">=</span> <span class="s1">&#39;republic_clean.txt&#39;</span>
<span class="n">doc</span> <span class="o">=</span> <span class="n">load_doc</span><span class="p">(</span><span class="n">in_filename</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">doc</span><span class="p">[:</span><span class="mi">200</span><span class="p">])</span>

<span class="c1"># clean document</span>
<span class="n">tokens</span> <span class="o">=</span> <span class="n">clean_doc</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tokens</span><span class="p">[:</span><span class="mi">200</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Total Tokens: </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Unique Tokens: </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">tokens</span><span class="p">)))</span>

<span class="c1"># organize into sequences of tokens</span>
<span class="n">length</span> <span class="o">=</span> <span class="mi">50</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">sequences</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">length</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)):</span>
    <span class="c1"># select sequence of tokens</span>
    <span class="n">seq</span> <span class="o">=</span> <span class="n">tokens</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="n">length</span><span class="p">:</span><span class="n">i</span><span class="p">]</span>
    <span class="c1"># convert into a line</span>
    <span class="n">line</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">seq</span><span class="p">)</span>
    <span class="c1"># store</span>
    <span class="n">sequences</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Total Sequences: </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">sequences</span><span class="p">))</span>

<span class="c1"># save sequences to file</span>
<span class="n">out_filename</span> <span class="o">=</span> <span class="s1">&#39;republic_sequences.txt&#39;</span>
<span class="n">save_doc</span><span class="p">(</span><span class="n">sequences</span><span class="p">,</span> <span class="n">out_filename</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The Project Gutenberg EBook of The Republic, by Plato

This eBook is for the use of anyone anywhere at no cost and with
almost no restrictions whatsoever.  You may copy it, give it away or
re-use it u
[&#39;the&#39;, &#39;project&#39;, &#39;gutenberg&#39;, &#39;ebook&#39;, &#39;of&#39;, &#39;the&#39;, &#39;republic&#39;, &#39;by&#39;, &#39;plato&#39;, &#39;this&#39;, &#39;ebook&#39;, &#39;is&#39;, &#39;for&#39;, &#39;the&#39;, &#39;use&#39;, &#39;of&#39;, &#39;anyone&#39;, &#39;anywhere&#39;, &#39;at&#39;, &#39;no&#39;, &#39;cost&#39;, &#39;and&#39;, &#39;with&#39;, &#39;almost&#39;, &#39;no&#39;, &#39;restrictions&#39;, &#39;whatsoever&#39;, &#39;you&#39;, &#39;may&#39;, &#39;copy&#39;, &#39;it&#39;, &#39;give&#39;, &#39;it&#39;, &#39;away&#39;, &#39;or&#39;, &#39;reuse&#39;, &#39;it&#39;, &#39;under&#39;, &#39;the&#39;, &#39;terms&#39;, &#39;of&#39;, &#39;the&#39;, &#39;project&#39;, &#39;gutenberg&#39;, &#39;license&#39;, &#39;included&#39;, &#39;with&#39;, &#39;this&#39;, &#39;ebook&#39;, &#39;or&#39;, &#39;online&#39;, &#39;at&#39;, &#39;wwwgutenbergorg&#39;, &#39;title&#39;, &#39;the&#39;, &#39;republic&#39;, &#39;author&#39;, &#39;plato&#39;, &#39;translator&#39;, &#39;b&#39;, &#39;jowett&#39;, &#39;posting&#39;, &#39;date&#39;, &#39;august&#39;, &#39;ebook&#39;, &#39;release&#39;, &#39;date&#39;, &#39;october&#39;, &#39;last&#39;, &#39;updated&#39;, &#39;june&#39;, &#39;language&#39;, &#39;english&#39;, &#39;start&#39;, &#39;of&#39;, &#39;this&#39;, &#39;project&#39;, &#39;gutenberg&#39;, &#39;ebook&#39;, &#39;the&#39;, &#39;republic&#39;, &#39;produced&#39;, &#39;by&#39;, &#39;sue&#39;, &#39;asscher&#39;, &#39;the&#39;, &#39;republic&#39;, &#39;by&#39;, &#39;plato&#39;, &#39;translated&#39;, &#39;by&#39;, &#39;benjamin&#39;, &#39;jowett&#39;, &#39;note&#39;, &#39;the&#39;, &#39;republic&#39;, &#39;by&#39;, &#39;plato&#39;, &#39;jowett&#39;, &#39;etext&#39;, &#39;introduction&#39;, &#39;and&#39;, &#39;analysis&#39;, &#39;the&#39;, &#39;republic&#39;, &#39;of&#39;, &#39;plato&#39;, &#39;is&#39;, &#39;the&#39;, &#39;longest&#39;, &#39;of&#39;, &#39;his&#39;, &#39;works&#39;, &#39;with&#39;, &#39;the&#39;, &#39;exception&#39;, &#39;of&#39;, &#39;the&#39;, &#39;laws&#39;, &#39;and&#39;, &#39;is&#39;, &#39;certainly&#39;, &#39;the&#39;, &#39;greatest&#39;, &#39;of&#39;, &#39;them&#39;, &#39;there&#39;, &#39;are&#39;, &#39;nearer&#39;, &#39;approaches&#39;, &#39;to&#39;, &#39;modern&#39;, &#39;metaphysics&#39;, &#39;in&#39;, &#39;the&#39;, &#39;philebus&#39;, &#39;and&#39;, &#39;in&#39;, &#39;the&#39;, &#39;sophist&#39;, &#39;the&#39;, &#39;politicus&#39;, &#39;or&#39;, &#39;statesman&#39;, &#39;is&#39;, &#39;more&#39;, &#39;ideal&#39;, &#39;the&#39;, &#39;form&#39;, &#39;and&#39;, &#39;institutions&#39;, &#39;of&#39;, &#39;the&#39;, &#39;state&#39;, &#39;are&#39;, &#39;more&#39;, &#39;clearly&#39;, &#39;drawn&#39;, &#39;out&#39;, &#39;in&#39;, &#39;the&#39;, &#39;laws&#39;, &#39;as&#39;, &#39;works&#39;, &#39;of&#39;, &#39;art&#39;, &#39;the&#39;, &#39;symposium&#39;, &#39;and&#39;, &#39;the&#39;, &#39;protagoras&#39;, &#39;are&#39;, &#39;of&#39;, &#39;higher&#39;, &#39;excellence&#39;, &#39;but&#39;, &#39;no&#39;, &#39;other&#39;, &#39;dialogue&#39;, &#39;of&#39;, &#39;plato&#39;, &#39;has&#39;, &#39;the&#39;, &#39;same&#39;, &#39;largeness&#39;, &#39;of&#39;, &#39;view&#39;, &#39;and&#39;, &#39;the&#39;, &#39;same&#39;, &#39;perfection&#39;, &#39;of&#39;, &#39;style&#39;, &#39;no&#39;, &#39;other&#39;, &#39;shows&#39;, &#39;an&#39;, &#39;equal&#39;, &#39;knowledge&#39;, &#39;of&#39;]
Total Tokens: 216791
Unique Tokens: 10454
Total Sequences: 216740
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">array</span>
<span class="kn">from</span> <span class="nn">pickle</span> <span class="kn">import</span> <span class="n">dump</span>
<span class="kn">from</span> <span class="nn">keras.preprocessing.text</span> <span class="kn">import</span> <span class="n">Tokenizer</span>
<span class="kn">from</span> <span class="nn">keras.utils</span> <span class="kn">import</span> <span class="n">to_categorical</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">LSTM</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Embedding</span>

<span class="c1"># load doc into memory</span>
<span class="k">def</span> <span class="nf">load_doc</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
	<span class="c1"># open the file as read only</span>
	<span class="n">file</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span>
	<span class="c1"># read all text</span>
	<span class="n">text</span> <span class="o">=</span> <span class="n">file</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
	<span class="c1"># close the file</span>
	<span class="n">file</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
	<span class="k">return</span> <span class="n">text</span>

<span class="c1"># load</span>
<span class="n">in_filename</span> <span class="o">=</span> <span class="s1">&#39;republic_sequences.txt&#39;</span>
<span class="n">doc</span> <span class="o">=</span> <span class="n">load_doc</span><span class="p">(</span><span class="n">in_filename</span><span class="p">)</span>
<span class="n">lines</span> <span class="o">=</span> <span class="n">doc</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># integer encode sequences of words</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span>
<span class="n">tokenizer</span><span class="o">.</span><span class="n">fit_on_texts</span><span class="p">(</span><span class="n">lines</span><span class="p">)</span>
<span class="n">sequences</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">texts_to_sequences</span><span class="p">(</span><span class="n">lines</span><span class="p">)</span>
<span class="c1"># vocabulary size</span>
<span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">word_index</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>

<span class="c1"># separate into input and output</span>
<span class="n">sequences</span> <span class="o">=</span> <span class="n">array</span><span class="p">(</span><span class="n">sequences</span><span class="p">)</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">sequences</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">sequences</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">)</span>  <span class="c1"># one-hot encode y</span>
<span class="n">seq_length</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># define model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span>
                    <span class="n">input_length</span><span class="o">=</span><span class="n">seq_length</span><span class="p">))</span>  <span class="c1"># word ebmedding layer</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>  <span class="c1"># LSTM 1</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">100</span><span class="p">))</span>  <span class="c1"># LSTM 2</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
<span class="c1"># compile model</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span>
              <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
<span class="c1"># fit model</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model: &quot;sequential&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding (Embedding)        (None, 50, 50)            522750    
_________________________________________________________________
lstm (LSTM)                  (None, 50, 100)           60400     
_________________________________________________________________
lstm_1 (LSTM)                (None, 100)               80400     
_________________________________________________________________
dense (Dense)                (None, 100)               10100     
_________________________________________________________________
dense_1 (Dense)              (None, 10455)             1055955   
=================================================================
Total params: 1,729,605
Trainable params: 1,729,605
Non-trainable params: 0
_________________________________________________________________
None
424/424 [==============================] - 236s 557ms/step - loss: 6.4235 - accuracy: 0.0734
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tensorflow.python.keras.callbacks.History at 0x7f8f39670790&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># save the model to file</span>
<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;model.h5&#39;</span><span class="p">)</span>
<span class="c1"># save the tokenizer</span>
<span class="n">dump</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">,</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;tokenizer.pkl&#39;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">random</span> <span class="kn">import</span> <span class="n">randint</span>
<span class="kn">from</span> <span class="nn">pickle</span> <span class="kn">import</span> <span class="n">load</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>
<span class="kn">from</span> <span class="nn">keras.preprocessing.sequence</span> <span class="kn">import</span> <span class="n">pad_sequences</span>


<span class="c1"># load doc into memory</span>
<span class="k">def</span> <span class="nf">load_doc</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
    <span class="c1"># open the file as read only</span>
    <span class="n">file</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span>
    <span class="c1"># read all text</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">file</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
    <span class="c1"># close the file</span>
    <span class="n">file</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">text</span>


<span class="c1"># generate a sequence from a language model</span>
<span class="k">def</span> <span class="nf">generate_seq</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">seq_length</span><span class="p">,</span> <span class="n">seed_text</span><span class="p">,</span> <span class="n">n_words</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
    <span class="n">in_text</span> <span class="o">=</span> <span class="n">seed_text</span>
    <span class="c1"># generate a fixed number of words</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_words</span><span class="p">):</span>
        <span class="c1"># encode the text as integer</span>
        <span class="n">encoded</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">texts_to_sequences</span><span class="p">([</span><span class="n">in_text</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1"># truncate sequences to a fixed length</span>
        <span class="n">encoded</span> <span class="o">=</span> <span class="n">pad_sequences</span><span class="p">([</span><span class="n">encoded</span><span class="p">],</span> <span class="n">maxlen</span><span class="o">=</span><span class="n">seq_length</span><span class="p">,</span> <span class="n">truncating</span><span class="o">=</span><span class="s1">&#39;pre&#39;</span><span class="p">)</span>
        <span class="c1"># predict probabilities for each word</span>
        <span class="n">yhat</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_classes</span><span class="p">(</span><span class="n">encoded</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="c1"># map predicted word index to word</span>
        <span class="n">out_word</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
        <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">word_index</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">index</span> <span class="o">==</span> <span class="n">yhat</span><span class="p">:</span>
                <span class="n">out_word</span> <span class="o">=</span> <span class="n">word</span>
                <span class="k">break</span>
        <span class="c1"># append to input</span>
        <span class="n">in_text</span> <span class="o">+=</span> <span class="s1">&#39; &#39;</span> <span class="o">+</span> <span class="n">out_word</span>
        <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">out_word</span><span class="p">)</span>
    <span class="k">return</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>


<span class="c1"># load cleaned text sequences</span>
<span class="n">in_filename</span> <span class="o">=</span> <span class="s1">&#39;republic_sequences.txt&#39;</span>
<span class="n">doc</span> <span class="o">=</span> <span class="n">load_doc</span><span class="p">(</span><span class="n">in_filename</span><span class="p">)</span>
<span class="n">lines</span> <span class="o">=</span> <span class="n">doc</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">seq_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">lines</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">())</span> <span class="o">-</span> <span class="mi">1</span>

<span class="c1"># load the model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s1">&#39;model.h5&#39;</span><span class="p">)</span>

<span class="c1"># load the tokenizer</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s1">&#39;tokenizer.pkl&#39;</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">))</span>

<span class="c1"># select a seed text</span>
<span class="n">seed_text</span> <span class="o">=</span> <span class="n">lines</span><span class="p">[</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">lines</span><span class="p">))]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">seed_text</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># generate new text</span>
<span class="n">generated</span> <span class="o">=</span> <span class="n">generate_seq</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">seq_length</span><span class="p">,</span> <span class="n">seed_text</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">generated</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python-notes",
            path: "./nlp"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python-notes'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Alvin Chen
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2020 Alvin Chen.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>