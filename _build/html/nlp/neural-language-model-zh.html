

<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Neural Language Model of Chinese &#8212; Python Notes for Linguistics</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="../_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="../_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mycss.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-dropdown.css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Text Generation" href="text-gen-lstm-v1.html" />
    <link rel="prev" title="Neural Language Model: A Start" href="neural-language-model-primer.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/ntnu03.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Python Notes for Linguistics</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../python-basics/python-basics.html">
   Python Basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../corpus/corpus-processing.html">
   Corpus Linguistics with Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../statistical-analyses/statistical-analyses.html">
   Statistical Analyses
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="reference internal" href="nlp.html">
   Natural Language Processing with Python
  </a>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="nlp-spacy.html">
     Natural Language Processing (spaCy)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="nlp-spacy-zh.html">
     Chinese Natural Language Processing (spaCy)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="nlp-ckipnlp.html">
     Natural Language Processing (ckipnlp)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="text-normalization-eng.html">
     Text Normalization (English)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="text-normalization-chinese.html">
     Text Normalization (Chinese)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="sklearn.html">
     Machine Learning with Sci-Kit Learn
    </a>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="naive-bayes.html">
       Naive Bayes
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="sentiment-analysis-ml.html">
       Sentiment Analysis with Traditional Machine Learning
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="neural-network-from-scratch.html">
     Neural Network From Scratch
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="reference internal" href="language-model.html">
     Language Model
    </a>
    <ul class="current">
     <li class="toctree-l3">
      <a class="reference internal" href="neural-language-model-primer.html">
       Neural Language Model: A Start
      </a>
     </li>
     <li class="toctree-l3 current active">
      <a class="current reference internal" href="#">
       Neural Language Model of Chinese
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="text-gen-lstm-v1.html">
       Text Generation
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="gpt2.html">
       Transformer-based Language Model - GPT2
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="word-embeddings.html">
     Word Embeddings
    </a>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="word2vec-chinese.html">
       Word Embeddings with Chinese Texts
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="word2vec.html">
       Word2Vec
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="doc2vec.html">
       Dov2Vec
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="transfer-learning-sent-encoding.html">
       Universal Sentence Embeddings
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="sentiment-analysis-dl.html">
     Sentiment Analysis with Deep Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="sentiment-analysis-lstm-v1.html">
     Sentiment Analysis with LSTM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="seq-to-seq-types.html">
     Intutions for Types of Sequence-to-Sequence Models
    </a>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="seq-to-seq-types-date.html">
       Types of Seqeunce Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="seq-to-seq-m21-sentiment-attention.html">
       Sequence Model (many-to-one) with Attention
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="seq-to-seq-attention-addition.html">
       Seqeunce Model with Attention for Addition Learning
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="seq-to-seq-machine-translation.html">
     Machine Translation (Sequence-to-Sequence)
    </a>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="seq-to-seq-machine-translation-attention.html">
       Machine Translation with Attention (Thushan)
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="hyperparameter-tuning.html">
     Hyper-Parameter Tuning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="sentiment-analysis-using-bert-chinese.html">
     Sentiment Analysis Using BERT
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ktrain-tutorial-explaining-predictions.html">
     Explainable AI
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../appendix/todo.html">
   To-do List
  </a>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  <div style="text-align:left">
    <a href="https://alvinchen.myftp.org/" target='_blank'>Alvin Chen's Homepage</a>
</div>

</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/nlp/neural-language-model-zh.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/alvinntnu/python-notes/master?urlpath=tree/nlp/neural-language-model-zh.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/alvinntnu/python-notes/blob/master/nlp/neural-language-model-zh.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#line-based-language-model">
   Line-based Language Model
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#text-to-sequences">
     Text to Sequences
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#word-id-to-texts">
     Word ID to Texts
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#padding">
     Padding
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#train-and-test-sets">
     Train and Test Sets
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#define-model">
     Define Model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#train-model">
     Train Model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#save-model">
     Save Model
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#load-model">
   Load Model
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#generate-sequence">
     Generate Sequence
    </a>
   </li>
  </ul>
 </li>
</ul>

        </nav>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="neural-language-model-of-chinese">
<h1>Neural Language Model of Chinese<a class="headerlink" href="#neural-language-model-of-chinese" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><p><a class="reference external" href="https://machinelearningmastery.com/how-to-develop-a-word-level-neural-language-model-in-keras/">How to development a word-level neural language model in keras</a></p></li>
<li><p>Chinese texts</p></li>
<li><p>Word-based neural language model based on:</p>
<ul>
<li><p>character sequences</p></li>
<li><p>word sequences</p></li>
</ul>
</li>
<li><p>Use two novels by Jing-Yong</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">drive</span>
<span class="n">drive</span><span class="o">.</span><span class="n">mount</span><span class="p">(</span><span class="s1">&#39;/content/drive&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mounted at /content/drive
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#import sys</span>
<span class="c1">#sys.path.insert(1, &#39;/content/drive/My Drive/_MySyncDrive/Repository/python-notes/nlp&#39;)</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="s1">&#39;/content/drive/My Drive/_MySyncDrive/Repository/python-notes/nlp&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">string</span>
<span class="kn">import</span> <span class="nn">text_normalizer_zh</span> <span class="k">as</span> <span class="nn">tn</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="c1"># load doc into memory</span>
<span class="k">def</span> <span class="nf">load_doc</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
    <span class="c1"># open the file as read only</span>
    <span class="n">file</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
    <span class="c1"># read all text</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">file</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
    <span class="c1"># close the file</span>
    <span class="n">file</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">text</span>


<span class="c1"># turn a doc into clean tokens</span>
<span class="k">def</span> <span class="nf">clean_doc_paras</span><span class="p">(</span><span class="n">doc</span><span class="p">):</span>
    <span class="c1"># get content paragraphs only</span>
    <span class="n">paras</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">doc</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">sep</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)[</span><span class="mi">7</span><span class="p">:]</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;  &#39;</span><span class="p">)]</span>
    <span class="n">paras</span> <span class="o">=</span> <span class="p">[</span><span class="n">tn</span><span class="o">.</span><span class="n">remove_symbols</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">paras</span><span class="p">]</span>
    <span class="n">paras</span> <span class="o">=</span> <span class="p">[</span><span class="n">tn</span><span class="o">.</span><span class="n">remove_extra_spaces</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">paras</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">paras</span>

<span class="k">def</span> <span class="nf">clean_doc_lines</span><span class="p">(</span><span class="n">doc</span><span class="p">):</span>
    <span class="c1"># get content paragraphs only</span>
    <span class="n">paras</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;[</span><span class="se">\n</span><span class="s2">，。]&quot;</span><span class="p">,</span> <span class="n">doc</span><span class="p">)[</span><span class="mi">7</span><span class="p">:]</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;  &#39;</span><span class="p">)]</span>
    <span class="n">paras</span> <span class="o">=</span> <span class="p">[</span><span class="n">tn</span><span class="o">.</span><span class="n">remove_symbols</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">paras</span><span class="p">]</span>
    <span class="n">paras</span> <span class="o">=</span> <span class="p">[</span><span class="n">tn</span><span class="o">.</span><span class="n">remove_extra_spaces</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">paras</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">paras</span>


<span class="c1"># save tokens to file, one dialog per line</span>
<span class="k">def</span> <span class="nf">save_doc</span><span class="p">(</span><span class="n">lines</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
    <span class="n">data</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">lines</span><span class="p">)</span>
    <span class="n">file</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span>
    <span class="n">file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">file</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># load document</span>
<span class="n">in_filename</span> <span class="o">=</span> <span class="s2">&quot;../../../RepositoryData/data/jingyong-part-cht-utf8.txt&quot;</span>
<span class="n">doc</span><span class="o">=</span><span class="n">load_doc</span><span class="p">(</span><span class="n">in_filename</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">doc</span><span class="p">[:</span><span class="mi">200</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>『金庸作品集/作者:金庸』
『狀態:已完結』
『內容簡介:
    金庸的所有的書&amp;lt;/p&amp;gt;
』
愛下電子書Txt版閱讀,下載和分享更多電子書請訪問:http://www.ixdzs.com,手機訪問:http://m.ixdzs.com,E-mail:support@ixdzs.com
------章節內容開始-------
天龍八部
第一章 青衫磊落險峰行
    青光閃動，一柄青鋼
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># clean document</span>
<span class="n">paras</span> <span class="o">=</span> <span class="n">clean_doc_lines</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">paras</span><span class="p">[:</span><span class="mi">20</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Total Paragraphs: </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">paras</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Unique Tokens: </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">paras</span><span class="p">))))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;青光閃動&#39;, &#39;兩人劍法迅捷&#39;, &#39;練武廳東坐著二人&#39;, &#39;眼見那少年與中年漢子已拆到七十余招&#39;, &#39;便在這時&#39;, &#39;那長須老者滿臉得色&#39;, &#39;這老者姓左&#39;, &#39;無量劍原分東北西三宗&#39;, &#39;西首錦凳上所坐的則是別派人士&#39;, &#39;當下左子穆笑道辛師妹今年派出的四名弟子&#39;, &#39;馬五德臉上微微一紅&#39;, &#39;左子穆心想他若是你弟子&#39;, &#39;那姓段青年微笑道在下單名一譽字&#39;, &#39;馬五德和段譽也是初交&#39;, &#39;左子穆道段兄既然不是馬五哥的好朋友&#39;, &#39;那中年漢子龔光杰巴不得師父有這句話&#39;, &#39;段譽輕揮折扇&#39;, &#39;他這番說什麼你師父我師父的&#39;, &#39;龔光杰大踏步過來&#39;, &#39;段譽道你這位大爺怎地如此狠霸霸的我平生最不愛瞧人打架&#39;]
Total Paragraphs: 34031
Unique Tokens: 3388
</pre></div>
</div>
</div>
</div>
<div class="section" id="line-based-language-model">
<h2>Line-based Language Model<a class="headerlink" href="#line-based-language-model" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">array</span>
<span class="kn">from</span> <span class="nn">keras.preprocessing.text</span> <span class="kn">import</span> <span class="n">Tokenizer</span>
<span class="kn">from</span> <span class="nn">keras.utils</span> <span class="kn">import</span> <span class="n">to_categorical</span><span class="p">,</span> <span class="n">plot_model</span>
<span class="kn">from</span> <span class="nn">keras.preprocessing.sequence</span> <span class="kn">import</span> <span class="n">pad_sequences</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">LSTM</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Embedding</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="text-to-sequences">
<h3>Text to Sequences<a class="headerlink" href="#text-to-sequences" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># prepare data</span>
<span class="n">data</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">paras</span><span class="p">)</span>  <span class="c1"># collapse the entire corpus into one string</span>
<span class="c1"># prepare the tokenizer on the source text</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">(</span>
    <span class="n">oov_token</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">char_level</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>  <span class="c1">## specify the word id for unknown words + char_level tokenizer</span>
<span class="n">tokenizer</span><span class="o">.</span><span class="n">fit_on_texts</span><span class="p">([</span><span class="n">data</span><span class="p">])</span>

<span class="c1"># determine the vocabulary size</span>
<span class="c1">## zero index is reserved in keras as the padding token (+1) and one unknown word id</span>
<span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">word_index</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Vocabulary Size: </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">vocab_size</span><span class="p">)</span>

<span class="c1"># create paragraph-based sequences</span>
<span class="n">sequences</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">):</span>
    <span class="n">encoded</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">texts_to_sequences</span><span class="p">([</span><span class="n">line</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
    <span class="c1">## For each line, after converting words into indexes</span>
    <span class="c1">## prepare sequences for training</span>
    <span class="c1">## given a line, w1,w2,w3,w4</span>
    <span class="c1">## create input sequences:</span>
    <span class="c1">## w1,w2</span>
    <span class="c1">## w1,w2,w3</span>
    <span class="c1">## w1,w2,w3,w4</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">encoded</span><span class="p">)):</span>
        <span class="n">sequence</span> <span class="o">=</span> <span class="n">encoded</span><span class="p">[:</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
        <span class="n">sequences</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Total Sequences: </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">sequences</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Vocabulary Size: 3391
Total Sequences: 222346
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="word-id-to-texts">
<h3>Word ID to Texts<a class="headerlink" href="#word-id-to-texts" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Creating a reverse dictionary</span>
<span class="n">reverse_word_map</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">reversed</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">word_index</span><span class="o">.</span><span class="n">items</span><span class="p">()))</span>
<span class="c1"># Function takes a tokenized sentence and returns the words</span>
<span class="k">def</span> <span class="nf">sequence_to_text</span><span class="p">(</span><span class="n">list_of_indices</span><span class="p">):</span>
    <span class="c1"># Looking up words in dictionary</span>
    <span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="n">reverse_word_map</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">letter</span><span class="p">)</span> <span class="k">for</span> <span class="n">letter</span> <span class="ow">in</span> <span class="n">list_of_indices</span><span class="p">]</span>
    <span class="k">return</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sequences</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[256, 105],
 [256, 105, 506],
 [256, 105, 506, 195],
 [82, 8],
 [82, 8, 34],
 [82, 8, 34, 90],
 [82, 8, 34, 90, 913],
 [82, 8, 34, 90, 913, 1650],
 [437, 129],
 [437, 129, 796]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="nb">print</span><span class="p">(</span><span class="n">sequence_to_text</span><span class="p">(</span><span class="n">s</span><span class="p">))</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">sequences</span><span class="p">[:</span><span class="mi">10</span><span class="p">]]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;青&#39;, &#39;光&#39;]
[&#39;青&#39;, &#39;光&#39;, &#39;閃&#39;]
[&#39;青&#39;, &#39;光&#39;, &#39;閃&#39;, &#39;動&#39;]
[&#39;兩&#39;, &#39;人&#39;]
[&#39;兩&#39;, &#39;人&#39;, &#39;劍&#39;]
[&#39;兩&#39;, &#39;人&#39;, &#39;劍&#39;, &#39;法&#39;]
[&#39;兩&#39;, &#39;人&#39;, &#39;劍&#39;, &#39;法&#39;, &#39;迅&#39;]
[&#39;兩&#39;, &#39;人&#39;, &#39;劍&#39;, &#39;法&#39;, &#39;迅&#39;, &#39;捷&#39;]
[&#39;練&#39;, &#39;武&#39;]
[&#39;練&#39;, &#39;武&#39;, &#39;廳&#39;]
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[None, None, None, None, None, None, None, None, None, None]
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="padding">
<h3>Padding<a class="headerlink" href="#padding" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">max_length</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">seq</span><span class="p">)</span> <span class="k">for</span> <span class="n">seq</span> <span class="ow">in</span> <span class="n">sequences</span><span class="p">])</span>
<span class="n">sequences</span> <span class="o">=</span> <span class="n">pad_sequences</span><span class="p">(</span><span class="n">sequences</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="n">max_length</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;pre&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Max Sequence Length: </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">max_length</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Max Sequence Length: 133
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="train-and-test-sets">
<h3>Train and Test Sets<a class="headerlink" href="#train-and-test-sets" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># split into input and output elements</span>
<span class="n">sequences</span> <span class="o">=</span> <span class="n">array</span><span class="p">(</span><span class="n">sequences</span><span class="p">)</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">sequences</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="n">sequences</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="define-model">
<h3>Define Model<a class="headerlink" href="#define-model" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># define model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">input_length</span><span class="o">=</span><span class="n">max_length</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>  <span class="c1"># LSTM 1</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">100</span><span class="p">))</span>  <span class="c1"># LSTM 2</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
<span class="c1"># compile network</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model: &quot;sequential&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding (Embedding)        (None, 132, 128)          434048    
_________________________________________________________________
lstm (LSTM)                  (None, 132, 100)          91600     
_________________________________________________________________
lstm_1 (LSTM)                (None, 100)               80400     
_________________________________________________________________
dense (Dense)                (None, 100)               10100     
_________________________________________________________________
dense_1 (Dense)              (None, 3391)              342491    
=================================================================
Total params: 958,639
Trainable params: 958,639
Non-trainable params: 0
_________________________________________________________________
None
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="train-model">
<h3>Train Model<a class="headerlink" href="#train-model" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># # fit network</span>
<span class="c1"># model.fit(X, y, batch_size= 256, epochs=500, verbose=1)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="save-model">
<h3>Save Model<a class="headerlink" href="#save-model" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># from pickle import dump</span>
<span class="c1"># # save the model to file</span>
<span class="c1"># model.save(&#39;jing-yong-line-lm-model.h5&#39;)</span>
<span class="c1"># # save the tokenizer</span>
<span class="c1"># dump(tokenizer, open(&#39;jing-yong-line-lm-tokenizer.pkl&#39;, &#39;wb&#39;))</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="load-model">
<h2>Load Model<a class="headerlink" href="#load-model" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pickle</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="s1">&#39;jing-yong-line-lm-model.h5&#39;</span><span class="p">)</span>
<span class="n">pickle_in</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;jing-yong-line-lm-tokenizer.pkl&#39;</span><span class="p">,</span>
                 <span class="s2">&quot;rb&quot;</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">pickle_in</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="generate-sequence">
<h3>Generate Sequence<a class="headerlink" href="#generate-sequence" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># generate a sequence from a language model</span>
<span class="k">def</span> <span class="nf">generate_seq</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">max_length</span><span class="p">,</span> <span class="n">seed_text</span><span class="p">,</span> <span class="n">n_words</span><span class="p">):</span>
	<span class="n">in_text</span> <span class="o">=</span> <span class="n">seed_text</span>
	<span class="c1"># generate a fixed number of words</span>
	<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_words</span><span class="p">):</span>
		<span class="c1"># encode the text as integer</span>
		<span class="n">encoded</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">texts_to_sequences</span><span class="p">([</span><span class="n">in_text</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
		<span class="c1"># pre-pad sequences to a fixed length</span>
		<span class="n">encoded</span> <span class="o">=</span> <span class="n">pad_sequences</span><span class="p">([</span><span class="n">encoded</span><span class="p">],</span> <span class="n">maxlen</span><span class="o">=</span><span class="n">max_length</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;pre&#39;</span><span class="p">)</span>
		<span class="c1"># predict probabilities for each word</span>
		<span class="n">yhat</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_classes</span><span class="p">(</span><span class="n">encoded</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
		<span class="c1"># map predicted word index to word</span>
		<span class="n">out_word</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
		<span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">word_index</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
			<span class="k">if</span> <span class="n">index</span> <span class="o">==</span> <span class="n">yhat</span><span class="p">:</span>
				<span class="n">out_word</span> <span class="o">=</span> <span class="n">word</span>
				<span class="k">break</span>
		<span class="c1"># append to input</span>
		<span class="n">in_text</span> <span class="o">+=</span> <span class="s1">&#39; &#39;</span> <span class="o">+</span> <span class="n">out_word</span>
	<span class="k">return</span> <span class="n">in_text</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># evaluate model</span>
<span class="nb">print</span><span class="p">(</span><span class="n">generate_seq</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">max_length</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;師父&#39;</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
<span class="c1"># print(generate_seq(model, tokenizer, max_length-1, &#39;Jill&#39;, 4))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>師父 師 姊 娘 我 段 正 結 交 視 那 儀 雖 尚 後 裡 當 年 子 師 父 段 譽 頭 子 引 兒 兒 滑 叛 得 不 過 身 子 道 你 你 什 了 身 子 李 延 慶 忽 袱 畔 起 了 我 呢 尚 穆 道 有 段 正 淳 嗎 朝 皇 此 也 羞 著 譚 婆 兒 子 我 沒 給 丐 姊 平 之 負 他 不 讓 徒 主 不 知 道 人 的 好 你 我 早 睛 兩 個 英 雄 母 殿 想 起
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./nlp"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="neural-language-model-primer.html" title="previous page">Neural Language Model: A Start</a>
    <a class='right-next' id="next-link" href="text-gen-lstm-v1.html" title="next page">Text Generation</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Alvin Chen<br/>
        
            &copy; Copyright 2020 Alvin Chen.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="../_static/js/index.js"></script>
    
  </body>
</html>